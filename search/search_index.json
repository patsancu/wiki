{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About me Hi there! I'm Patrick and this is my wiki. Hope you find something useful. If you want to contact me, feel free take a look at my LinkedIn profile","title":"Home"},{"location":"#about-me","text":"Hi there! I'm Patrick and this is my wiki. Hope you find something useful. If you want to contact me, feel free take a look at my LinkedIn profile","title":"About me"},{"location":"Utils/","text":"From ape+cue to several files convert file to flac cuebreakpoints CD1.cue | shntool split -o flac file_name .flac cuebreakpoints sample.cue | shnsplit -o flac sample.flac; #add metadata cuetag *.cue split-track*.flac ;","title":"Utils"},{"location":"Utils/#from-apecue-to-several-files","text":"convert file to flac cuebreakpoints CD1.cue | shntool split -o flac file_name .flac cuebreakpoints sample.cue | shnsplit -o flac sample.flac; #add metadata cuetag *.cue split-track*.flac ;","title":"From ape+cue to several files"},{"location":"OS/Raspberry-Pi/","text":"Enable ssh on startup Source Change default user and password first! $ sudo touch /boot/ssh","title":"Raspberry Pi"},{"location":"OS/Raspberry-Pi/#enable-ssh-on-startup","text":"Source Change default user and password first! $ sudo touch /boot/ssh","title":"Enable ssh on startup"},{"location":"OS/Tips/","text":"Convert video to mp3 From here ffmpeg -i video.mp4 -vn \\ -acodec libmp3lame -ac 2 -ab 160k -ar 48000 \\ audio.mp3 or if you want to use Variable Bitrate Encoding (VBR): ffmpeg -i video.mp4 -vn \\ -acodec libmp3lame -ac 2 -qscale:a 4 -ar 48000 \\ audio.mp3","title":"Tips"},{"location":"OS/Tips/#convert-video-to-mp3","text":"From here ffmpeg -i video.mp4 -vn \\ -acodec libmp3lame -ac 2 -ab 160k -ar 48000 \\ audio.mp3 or if you want to use Variable Bitrate Encoding (VBR): ffmpeg -i video.mp4 -vn \\ -acodec libmp3lame -ac 2 -qscale:a 4 -ar 48000 \\ audio.mp3","title":"Convert video to mp3"},{"location":"OS/Linux-Unix/Admin/","text":"Add user to group # Add user `some_user` to `docker` group sudo usermod -aG docker some_user","title":"Admin"},{"location":"OS/Linux-Unix/Admin/#add-user-to-group","text":"# Add user `some_user` to `docker` group sudo usermod -aG docker some_user","title":"Add user to group"},{"location":"OS/Linux-Unix/Apps/","text":"Curl get curl to set error code to error if it fails curl --fail http://non_existing_domain.com || echo curl failed curl --fail http://example.com echo curl succeeded!","title":"Apps"},{"location":"OS/Linux-Unix/Apps/#curl","text":"get curl to set error code to error if it fails curl --fail http://non_existing_domain.com || echo curl failed curl --fail http://example.com echo curl succeeded!","title":"Curl"},{"location":"OS/Linux-Unix/General/","text":"Systemd vim /etc/systemd/system/service_name.service [Unit] Description = making network connection up After = network.target [Service] # ExecStart can point to any executable file ExecStart = /root/scripts/conup.sh [Install] WantedBy = multi-user.target Create executable script vim /root/scripts/conup.sh; chmod +x /root/scripts/conup.sh; Enable service # systemctl enable connection.service Basic operations # systemctl start connection.service # systemctl stop connection.service Grub Change grub boot order sudo vim /etc/default/grub Change GRUB_DEFAULT to one of [number of entry (zero-based), 'Title'subindex] Examples: 'Advanced options for Ubuntu '3 2 Then, update the grub menu sudo update-grub Check the file /boot/grub/grub.cfg for reference Reinstall grub boot from livecd mount partition where grub was contained (usually OS's partition) sudo tune2fs -L \"partition_name\" /dev/sdXX ( e.g.: /dev/sda6/ ) sudo os-prober sudo grub-install --root-directory=/media/partition_name/ /dev/sda reboot Create passwordless user programmatically # useradd -m -c Samwise the Brave sam -s /bin/bash Creates user with home /home/sam and shell /bin/bash Find # Search all files with .old extension and delete them: find / -name *.old -exec /bin/rm {} \\; # Search all files with size of 100 MB and delete them: find / -size +100M -exec /bin/rm {} \\; # Recursively change the permissions of all directories find . -type d -exec chmod 755 {} \\; Top W writes config changes to .toprc E cycles through memory units in the total memory info Configure stuff Change locale With /usr/bin/tzselect you can check what is the timezone your computer should be using sudo dpkg-reconfigure tzdata If it doesn't work, try the following: With that timezone, paste the timezone to ~/.profile or ~/.bash_profile , depending on your use case. One of those files (it'll probably work with any sourced file at login) should have one line such as: TZ='Europe/London'; export TZ or just execute Insert unicode characters Hold down the shift and control keys while typing the letter u and the hex values of the Unicode character you wish to enter. Example: Hold control and shift and type U1F60F \u200d\ud83d\ude0f Add dictionaries to /usr/share/dict/ $ sudo apt-cache search --names-only swedish $ sudo apt-get install wswedish Mouse - Third button sudo vim /usr/share/X11/xorg.conf.d/middle-mouse-button.conf And paste this Section InputClass Identifier middle button emulation class MatchIsPointer on Option Emulate3Buttons on EndSection or check this wiki ubuntu Webcam List video devices v4l2-ctl --list-formats-ext v4l2-ctl --list-devices Find resolution of webcam lsusb list usb devices, get params of webcam lsusb -s 003:074 -v | egrep \"Width|Height\" down vote accepted I had the same problem and managed to fix it by setting the defaults for both gvfs as well as xdg. check defaults with: Change default app for magnet links This probably will only work with gnome, kde and xfce #Check currently available apps xdg-mime query default x-scheme-handler/magnet gvfs-mime --query x-scheme-handler/magnet # Set new app, providing it's in /usr/share/applications/ xdg-mime default qBittorrent.desktop x-scheme-handler/magnet gvfs-mime --set x-scheme-handler/magnet qBittorrent.desktop Notifications notify-send -u critical The potato finished cooking Get OS version uname -a and $ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 16.04.2 LTS Release: 16.04 Codename: xenial Motion Make folders accessible sudo mkdir -p /var/run/motion; sudo chown -R $USER:$USER /var/run/motion; sudo mkdir -p /etc/motion/; sudo chown -R $USER:$USER /etc/motion/; sudo mkdir -p /var/log/motion/; sudo chown -R $USER:$USER /var/log/motion/; Configuration file /etc/motion/motion.conf Generate random chars tr -c -d '0123456789abcdefghijklmnopqrstuvwxyz' /dev/urandom | dd bs=32 count=1 2 /dev/null; echo Monitor screen locking exit_report(){ echo $(date) Monitoring Terminated. } trap exit_report; exit; 0 lockmon() { adddate() { while IFS= read \u00adr line; do echo $(date) $line | grep boolean | sed 's/ boolean true/Screen Locked/' | sed 's/ boolean false/Screen Unlocked/' done } echo $(date) Monitoring Started. dbus\u00admonitor \u00ad\u00adsession type='signal',interface='org.gnome.ScreenSaver' | adddate } lockmon lock_screen.log How to fix \u2018$MFTMirr does not match $MFT (record 0)\u2019 install ntfsprogs sudo ntfsfix /dev/partitionName","title":"General"},{"location":"OS/Linux-Unix/General/#systemd","text":"vim /etc/systemd/system/service_name.service [Unit] Description = making network connection up After = network.target [Service] # ExecStart can point to any executable file ExecStart = /root/scripts/conup.sh [Install] WantedBy = multi-user.target","title":"Systemd"},{"location":"OS/Linux-Unix/General/#create-executable-script","text":"vim /root/scripts/conup.sh; chmod +x /root/scripts/conup.sh;","title":"Create executable script"},{"location":"OS/Linux-Unix/General/#enable-service","text":"# systemctl enable connection.service","title":"Enable service"},{"location":"OS/Linux-Unix/General/#basic-operations","text":"# systemctl start connection.service # systemctl stop connection.service","title":"Basic operations"},{"location":"OS/Linux-Unix/General/#grub","text":"","title":"Grub"},{"location":"OS/Linux-Unix/General/#change-grub-boot-order","text":"sudo vim /etc/default/grub Change GRUB_DEFAULT to one of [number of entry (zero-based), 'Title'subindex] Examples: 'Advanced options for Ubuntu '3 2 Then, update the grub menu sudo update-grub Check the file /boot/grub/grub.cfg for reference","title":"Change grub boot order"},{"location":"OS/Linux-Unix/General/#reinstall-grub","text":"boot from livecd mount partition where grub was contained (usually OS's partition) sudo tune2fs -L \"partition_name\" /dev/sdXX ( e.g.: /dev/sda6/ ) sudo os-prober sudo grub-install --root-directory=/media/partition_name/ /dev/sda reboot","title":"Reinstall grub"},{"location":"OS/Linux-Unix/General/#create-passwordless-user-programmatically","text":"# useradd -m -c Samwise the Brave sam -s /bin/bash Creates user with home /home/sam and shell /bin/bash","title":"Create passwordless user programmatically"},{"location":"OS/Linux-Unix/General/#find","text":"# Search all files with .old extension and delete them: find / -name *.old -exec /bin/rm {} \\; # Search all files with size of 100 MB and delete them: find / -size +100M -exec /bin/rm {} \\; # Recursively change the permissions of all directories find . -type d -exec chmod 755 {} \\;","title":"Find"},{"location":"OS/Linux-Unix/General/#top","text":"W writes config changes to .toprc E cycles through memory units in the total memory info","title":"Top"},{"location":"OS/Linux-Unix/General/#configure-stuff","text":"","title":"Configure stuff"},{"location":"OS/Linux-Unix/General/#change-locale","text":"With /usr/bin/tzselect you can check what is the timezone your computer should be using sudo dpkg-reconfigure tzdata If it doesn't work, try the following: With that timezone, paste the timezone to ~/.profile or ~/.bash_profile , depending on your use case. One of those files (it'll probably work with any sourced file at login) should have one line such as: TZ='Europe/London'; export TZ or just execute","title":"Change locale"},{"location":"OS/Linux-Unix/General/#insert-unicode-characters","text":"Hold down the shift and control keys while typing the letter u and the hex values of the Unicode character you wish to enter. Example: Hold control and shift and type U1F60F \u200d\ud83d\ude0f","title":"Insert unicode characters"},{"location":"OS/Linux-Unix/General/#add-dictionaries-to-usrsharedict","text":"$ sudo apt-cache search --names-only swedish $ sudo apt-get install wswedish","title":"Add dictionaries to /usr/share/dict/"},{"location":"OS/Linux-Unix/General/#mouse-third-button","text":"sudo vim /usr/share/X11/xorg.conf.d/middle-mouse-button.conf And paste this Section InputClass Identifier middle button emulation class MatchIsPointer on Option Emulate3Buttons on EndSection or check this wiki ubuntu","title":"Mouse - Third button"},{"location":"OS/Linux-Unix/General/#webcam","text":"","title":"Webcam"},{"location":"OS/Linux-Unix/General/#list-video-devices","text":"v4l2-ctl --list-formats-ext v4l2-ctl --list-devices","title":"List video devices"},{"location":"OS/Linux-Unix/General/#find-resolution-of-webcam","text":"lsusb list usb devices, get params of webcam lsusb -s 003:074 -v | egrep \"Width|Height\" down vote accepted I had the same problem and managed to fix it by setting the defaults for both gvfs as well as xdg. check defaults with:","title":"Find resolution of webcam"},{"location":"OS/Linux-Unix/General/#change-default-app-for-magnet-links","text":"This probably will only work with gnome, kde and xfce #Check currently available apps xdg-mime query default x-scheme-handler/magnet gvfs-mime --query x-scheme-handler/magnet # Set new app, providing it's in /usr/share/applications/ xdg-mime default qBittorrent.desktop x-scheme-handler/magnet gvfs-mime --set x-scheme-handler/magnet qBittorrent.desktop","title":"Change default app for magnet links"},{"location":"OS/Linux-Unix/General/#notifications","text":"notify-send -u critical The potato finished cooking","title":"Notifications"},{"location":"OS/Linux-Unix/General/#get-os-version","text":"uname -a and $ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 16.04.2 LTS Release: 16.04 Codename: xenial","title":"Get OS version"},{"location":"OS/Linux-Unix/General/#motion","text":"","title":"Motion"},{"location":"OS/Linux-Unix/General/#make-folders-accessible","text":"sudo mkdir -p /var/run/motion; sudo chown -R $USER:$USER /var/run/motion; sudo mkdir -p /etc/motion/; sudo chown -R $USER:$USER /etc/motion/; sudo mkdir -p /var/log/motion/; sudo chown -R $USER:$USER /var/log/motion/;","title":"Make folders accessible"},{"location":"OS/Linux-Unix/General/#configuration-file","text":"/etc/motion/motion.conf","title":"Configuration file"},{"location":"OS/Linux-Unix/General/#generate-random-chars","text":"tr -c -d '0123456789abcdefghijklmnopqrstuvwxyz' /dev/urandom | dd bs=32 count=1 2 /dev/null; echo","title":"Generate random chars"},{"location":"OS/Linux-Unix/General/#monitor-screen-locking","text":"exit_report(){ echo $(date) Monitoring Terminated. } trap exit_report; exit; 0 lockmon() { adddate() { while IFS= read \u00adr line; do echo $(date) $line | grep boolean | sed 's/ boolean true/Screen Locked/' | sed 's/ boolean false/Screen Unlocked/' done } echo $(date) Monitoring Started. dbus\u00admonitor \u00ad\u00adsession type='signal',interface='org.gnome.ScreenSaver' | adddate } lockmon lock_screen.log","title":"Monitor screen locking"},{"location":"OS/Linux-Unix/General/#how-to-fix-mftmirr-does-not-match-mft-record-0","text":"install ntfsprogs sudo ntfsfix /dev/partitionName","title":"How to fix \u2018$MFTMirr does not match $MFT (record 0)\u2019"},{"location":"OS/Linux-Unix/Gnome/","text":"Set monday as first day of week in Gnome Edit the file ~/.xsessionrc (or bashrc or whatever) to contain the line \"export LC_TIME=en_GB.utf8\" Gnome settings Change screenshot directory gsettings set org.gnome.gnome-screenshot auto-save-directory file:///home/$USER/Pictures/Screenshots/ Assign/unassign keyboard's sleep button Assign gsettings set org.gnome.settings-daemon.plugins.power button-suspend nothing Unassign gsettings set org.gnome.settings-daemon.plugins.power button-suspend suspend Custom launchers The applications launchers Gnome knows about are .desktop files in /usr/share/applications, and ~/.local/share/applications . You can create custom launchers for whatever is in your home folder, by either manually creating and editing a custom .desktop file, or by using Alacarte, the old Gnome menu editor. The Gnome desktop file documentation can be of help: https://developer.gnome.org/integration-guide/stable/desktop-files.html.en The custom launcher is just a text file, named, for example, EclipseEE.desktop, with the following content: [Desktop Entry] Name=Eclipse EE Exec=/home/mrPeterson/path_to_executable StartupNotify=true Terminal=false Type=Application Icon=/optional/path/to/icon.png Disable annoying evince thumbnailer From here With dconf, change the property here: org.gnome.desktop.thumbnailers","title":"Gnome"},{"location":"OS/Linux-Unix/Gnome/#set-monday-as-first-day-of-week-in-gnome","text":"Edit the file ~/.xsessionrc (or bashrc or whatever) to contain the line \"export LC_TIME=en_GB.utf8\"","title":"Set monday as first day of week in Gnome"},{"location":"OS/Linux-Unix/Gnome/#gnome-settings","text":"","title":"Gnome settings"},{"location":"OS/Linux-Unix/Gnome/#change-screenshot-directory","text":"gsettings set org.gnome.gnome-screenshot auto-save-directory file:///home/$USER/Pictures/Screenshots/","title":"Change screenshot directory"},{"location":"OS/Linux-Unix/Gnome/#assignunassign-keyboards-sleep-button","text":"","title":"Assign/unassign keyboard's sleep button"},{"location":"OS/Linux-Unix/Gnome/#assign","text":"gsettings set org.gnome.settings-daemon.plugins.power button-suspend nothing","title":"Assign"},{"location":"OS/Linux-Unix/Gnome/#unassign","text":"gsettings set org.gnome.settings-daemon.plugins.power button-suspend suspend","title":"Unassign"},{"location":"OS/Linux-Unix/Gnome/#custom-launchers","text":"The applications launchers Gnome knows about are .desktop files in /usr/share/applications, and ~/.local/share/applications . You can create custom launchers for whatever is in your home folder, by either manually creating and editing a custom .desktop file, or by using Alacarte, the old Gnome menu editor. The Gnome desktop file documentation can be of help: https://developer.gnome.org/integration-guide/stable/desktop-files.html.en The custom launcher is just a text file, named, for example, EclipseEE.desktop, with the following content: [Desktop Entry] Name=Eclipse EE Exec=/home/mrPeterson/path_to_executable StartupNotify=true Terminal=false Type=Application Icon=/optional/path/to/icon.png","title":"Custom launchers"},{"location":"OS/Linux-Unix/Gnome/#disable-annoying-evince-thumbnailer","text":"From here With dconf, change the property here: org.gnome.desktop.thumbnailers","title":"Disable annoying evince thumbnailer"},{"location":"OS/Linux-Unix/Monitor-Linux-Performance/","text":"vmstat Linux VmStat command used to display statistics of virtual memory, kernerl threads, disks, system processes, I/O blocks, interrupts, CPU activity and much more. By default vmstat command is not available under Linux systems you need to install a package called sysstat that includes a vmstat program. The common usage of command format is. lsof Lsof command used in many Linux/Unix like system that is used to display list of all the open files and the processes. The open files included are disk files, network sockets, pipes, devices and processes. One of the main reason for using this command is when a disk cannot be unmounted and displays the error that files are being used or opened. With this commmand you can easily identify which files are in use. The most common format for this command is: lsof Tcpdump Tcpdump is one of the most widely used command- line network packet analyzer or packets sniffer program that is used capture or filter TCP/IP packets that received or transferred on a specific interface over a network. It option to save captured packages in a file for later analysis. tcpdump is almost available in all major Linux distributions. tcpdump -i eth0 Netstat Netstat is a command line tool for monitoring incoming and outgoing network packets statistics as well as interface statistics. It is very useful tool for every system administrator to monitor network performance and troubleshoot network related problems. netstat -a | more Htop \u2013 Linux Process Monitoring Htop is a much advanced interactive and real time Linux process monitoring tool. This is much similar to Linux top command but it has some rich features like user friendly interface to manage process, shortcut keys, vertical and horizontal view of the processes and much more. Iotop \u2013 Monitor Linux Disk I/O Iotop is also much similar to top command and Htop program, but it has accounting function to monitor and display real time Disk I/O and processes. This tool is much useful for finding the exact process and high used disk read/writes of the processes. Iostat \u2013 Input/Output Statistics IoStat is simple tool that will collect and show system input and output storage device statistics. This tool is often used to trace storage device performance issues including devices, local disks, remote disks such as NFS. IPTraf \u2013 Real Time IP LAN Monitoring IPTraf is an open source console- based real time network (IP LAN) monitoring utility for Linux. It collects a variety of information such as IP traffic monitor that passes over the network, including TCP flag information, ICMP details, TCP/UDP traffic breakdowns, TCP connection packet and byne counts. It also gathers information of general and detaled interface statistics of TCP, UDP, IP, ICMP, non-IP, IP checksum errors, interface activity etc. Psacct or Acct \u2013 Monitor User Activity psacct or acct tools are very useful for monitoring each users activity on the system. Both daemons runs in the background and keeps a close watch on the overall activity of each user on the system and also what resources are being consumed by them. These tools are very useful for system administrators to track each users activity like what they are doing, what commands they issued, how much resources are used by them, how long they are active on the system etc. Monit \u2013 Linux Process and Services Monitoring Monit is a free open source and web based process supervision utility that automatically monitors and managers system processes, programs, files, directories, permissions, checksums and filesystems. It monitors services like Apache, MySQL, Mail, FTP, ProFTP, Nginx, SSH and so on. The system status can be viewed from the command line or using it own web interface. NetHogs \u2013 Monitor Per Process Network Bandwidth NetHogs is an open source nice small program (similar to Linux top command) that keeps a tab on each process network activity on your system. It also keeps a track of real time network traffic bandwidth used by each program or application. iftop \u2013 Network Bandwidth Monitoring iftop is another terminal-based free open source system monitoring utility that displays a frequently updated list of network bandwidth utilization (source and destination hosts) that passing through the network interface on your system. iftop is considered for network usage, what \u2018top\u2018 does for CPU usage. iftop is a \u2018top\u2018 family tool that monitor a selected interface and displays a current bandwidth usage betwee Monitorix \u2013 System and Network Monitoring Monitorix is a free lightweight utility that is designed to run and monitor system and network resources as many as possible in Linux/Unix servers. It has a built in HTTP web server that regularly collects system and network information and display them in graphs. It Monitors system load average and usage, memory allocation, disk driver health, system services, network ports, mail statistics SArpwatch \u2013 Ethernet Activity Monitor Arpwatch is a kind of program that is designed to monitor Address Resolution (MAC and IP address changes) of Ethernet network traffic on a Linux network. It continuously keeps watch on Ethernet traffic and produces a log of IP and MAC address pair changes along with a timestamps on a network. It also has a feature to send an email alerts to administrator, when a pairing added or changes. It is very useful in detecting ARP spoofing on a network. Suricata \u2013 Network Security Monitoring Suricata is an high performance open source Network Security and Intrusion Detection and Prevention Monitoring System for Linux, FreeBSD and Windows.It was designed and owned by a non- profit foundation OISF (Open Information Security Foundation).","title":"Monitor Linux Performance"},{"location":"OS/Linux-Unix/Monitor-Linux-Performance/#vmstat","text":"Linux VmStat command used to display statistics of virtual memory, kernerl threads, disks, system processes, I/O blocks, interrupts, CPU activity and much more. By default vmstat command is not available under Linux systems you need to install a package called sysstat that includes a vmstat program. The common usage of command format is.","title":"vmstat"},{"location":"OS/Linux-Unix/Monitor-Linux-Performance/#lsof","text":"Lsof command used in many Linux/Unix like system that is used to display list of all the open files and the processes. The open files included are disk files, network sockets, pipes, devices and processes. One of the main reason for using this command is when a disk cannot be unmounted and displays the error that files are being used or opened. With this commmand you can easily identify which files are in use. The most common format for this command is: lsof","title":"lsof"},{"location":"OS/Linux-Unix/Monitor-Linux-Performance/#tcpdump","text":"Tcpdump is one of the most widely used command- line network packet analyzer or packets sniffer program that is used capture or filter TCP/IP packets that received or transferred on a specific interface over a network. It option to save captured packages in a file for later analysis. tcpdump is almost available in all major Linux distributions. tcpdump -i eth0","title":"Tcpdump"},{"location":"OS/Linux-Unix/Monitor-Linux-Performance/#netstat","text":"Netstat is a command line tool for monitoring incoming and outgoing network packets statistics as well as interface statistics. It is very useful tool for every system administrator to monitor network performance and troubleshoot network related problems. netstat -a | more","title":"Netstat"},{"location":"OS/Linux-Unix/Monitor-Linux-Performance/#htop-linux-process-monitoring","text":"Htop is a much advanced interactive and real time Linux process monitoring tool. This is much similar to Linux top command but it has some rich features like user friendly interface to manage process, shortcut keys, vertical and horizontal view of the processes and much more.","title":"Htop \u2013 Linux Process Monitoring"},{"location":"OS/Linux-Unix/Monitor-Linux-Performance/#iotop-monitor-linux-disk-io","text":"Iotop is also much similar to top command and Htop program, but it has accounting function to monitor and display real time Disk I/O and processes. This tool is much useful for finding the exact process and high used disk read/writes of the processes.","title":"Iotop \u2013 Monitor Linux Disk I/O"},{"location":"OS/Linux-Unix/Monitor-Linux-Performance/#iostat-inputoutput-statistics","text":"IoStat is simple tool that will collect and show system input and output storage device statistics. This tool is often used to trace storage device performance issues including devices, local disks, remote disks such as NFS.","title":"Iostat \u2013 Input/Output Statistics"},{"location":"OS/Linux-Unix/Monitor-Linux-Performance/#iptraf-real-time-ip-lan-monitoring","text":"IPTraf is an open source console- based real time network (IP LAN) monitoring utility for Linux. It collects a variety of information such as IP traffic monitor that passes over the network, including TCP flag information, ICMP details, TCP/UDP traffic breakdowns, TCP connection packet and byne counts. It also gathers information of general and detaled interface statistics of TCP, UDP, IP, ICMP, non-IP, IP checksum errors, interface activity etc.","title":"IPTraf \u2013 Real Time IP LAN Monitoring"},{"location":"OS/Linux-Unix/Monitor-Linux-Performance/#psacct-or-acct-monitor-user-activity","text":"psacct or acct tools are very useful for monitoring each users activity on the system. Both daemons runs in the background and keeps a close watch on the overall activity of each user on the system and also what resources are being consumed by them. These tools are very useful for system administrators to track each users activity like what they are doing, what commands they issued, how much resources are used by them, how long they are active on the system etc.","title":"Psacct or Acct \u2013 Monitor User Activity"},{"location":"OS/Linux-Unix/Monitor-Linux-Performance/#monit-linux-process-and-services-monitoring","text":"Monit is a free open source and web based process supervision utility that automatically monitors and managers system processes, programs, files, directories, permissions, checksums and filesystems. It monitors services like Apache, MySQL, Mail, FTP, ProFTP, Nginx, SSH and so on. The system status can be viewed from the command line or using it own web interface.","title":"Monit \u2013 Linux Process and Services Monitoring"},{"location":"OS/Linux-Unix/Monitor-Linux-Performance/#nethogs-monitor-per-process-network-bandwidth","text":"NetHogs is an open source nice small program (similar to Linux top command) that keeps a tab on each process network activity on your system. It also keeps a track of real time network traffic bandwidth used by each program or application.","title":"NetHogs \u2013 Monitor Per Process Network Bandwidth"},{"location":"OS/Linux-Unix/Monitor-Linux-Performance/#iftop-network-bandwidth-monitoring","text":"iftop is another terminal-based free open source system monitoring utility that displays a frequently updated list of network bandwidth utilization (source and destination hosts) that passing through the network interface on your system. iftop is considered for network usage, what \u2018top\u2018 does for CPU usage. iftop is a \u2018top\u2018 family tool that monitor a selected interface and displays a current bandwidth usage betwee","title":"iftop \u2013 Network Bandwidth Monitoring"},{"location":"OS/Linux-Unix/Monitor-Linux-Performance/#monitorix-system-and-network-monitoring","text":"Monitorix is a free lightweight utility that is designed to run and monitor system and network resources as many as possible in Linux/Unix servers. It has a built in HTTP web server that regularly collects system and network information and display them in graphs. It Monitors system load average and usage, memory allocation, disk driver health, system services, network ports, mail statistics","title":"Monitorix \u2013 System and Network Monitoring"},{"location":"OS/Linux-Unix/Monitor-Linux-Performance/#sarpwatch-ethernet-activity-monitor","text":"Arpwatch is a kind of program that is designed to monitor Address Resolution (MAC and IP address changes) of Ethernet network traffic on a Linux network. It continuously keeps watch on Ethernet traffic and produces a log of IP and MAC address pair changes along with a timestamps on a network. It also has a feature to send an email alerts to administrator, when a pairing added or changes. It is very useful in detecting ARP spoofing on a network.","title":"SArpwatch \u2013 Ethernet Activity Monitor"},{"location":"OS/Linux-Unix/Monitor-Linux-Performance/#suricata-network-security-monitoring","text":"Suricata is an high performance open source Network Security and Intrusion Detection and Prevention Monitoring System for Linux, FreeBSD and Windows.It was designed and owned by a non- profit foundation OISF (Open Information Security Foundation).","title":"Suricata \u2013 Network Security Monitoring"},{"location":"OS/Linux-Unix/Ubuntu/","text":"Show notification window zenity --error --text= Hellow --title= Patata --timeout=2 Rebuild font cache $ fc-cache -f -v Update alternative Set another path to bin for program sudo update-alternatives --config java Insert unicode char Press Shift+Control+u then the unicode character's code. e.g. Shift+Control+u then 01b8 to get \u01b8","title":"Ubuntu"},{"location":"OS/Linux-Unix/Ubuntu/#show-notification-window","text":"zenity --error --text= Hellow --title= Patata --timeout=2","title":"Show notification window"},{"location":"OS/Linux-Unix/Ubuntu/#rebuild-font-cache","text":"$ fc-cache -f -v","title":"Rebuild font cache"},{"location":"OS/Linux-Unix/Ubuntu/#update-alternative","text":"Set another path to bin for program sudo update-alternatives --config java","title":"Update alternative"},{"location":"OS/Linux-Unix/Ubuntu/#insert-unicode-char","text":"Press Shift+Control+u then the unicode character's code. e.g. Shift+Control+u then 01b8 to get \u01b8","title":"Insert unicode char"},{"location":"OS/Linux-Unix/problems/","text":"Home and end keys not working as expected From here . Insert/uncomment this \\e[1~ : beginning-of-line \\e[4~ : end-of-line in the /etc/inputrc file","title":"Problems"},{"location":"OS/Linux-Unix/problems/#home-and-end-keys-not-working-as-expected","text":"From here . Insert/uncomment this \\e[1~ : beginning-of-line \\e[4~ : end-of-line in the /etc/inputrc file","title":"Home and end keys not working as expected"},{"location":"OS/MacOS/MacOS-Apps/","text":"","title":"MacOS Apps"},{"location":"OS/MacOS/macOS-config/","text":"Mac OS X: ValueError: unknown locale: UTF-8 in Python If you have faced the error on MacOS X, here's the quick fix - add these lines to your ~/.bash_profile: $ export LC_ALL=en_US.UTF-8 $ export LANG=en_US.UTF-8 Git completion download https://raw.githubusercontent.com/git/git/master/contrib/completion/git-completion.bash add source ~/git-completion.bash to ~/.bashrc Basic stuff that should be included, but it's not $ brew install coreutils","title":"macOS config"},{"location":"OS/MacOS/macOS-config/#mac-os-x-valueerror-unknown-locale-utf-8-in-python","text":"If you have faced the error on MacOS X, here's the quick fix - add these lines to your ~/.bash_profile: $ export LC_ALL=en_US.UTF-8 $ export LANG=en_US.UTF-8","title":"Mac OS X: ValueError: unknown locale: UTF-8 in Python"},{"location":"OS/MacOS/macOS-config/#git-completion","text":"download https://raw.githubusercontent.com/git/git/master/contrib/completion/git-completion.bash add source ~/git-completion.bash to ~/.bashrc","title":"Git completion"},{"location":"OS/MacOS/macOS-config/#basic-stuff-that-should-be-included-but-its-not","text":"$ brew install coreutils","title":"Basic stuff that should be included, but it's not"},{"location":"OS/MacOS/macOS/","text":"Restart ssh daemon sudo launchctl stop com.openssh.sshd sudo launchctl start com.openssh.sshd How to Refresh Control Strip killall ControlStrip Refresh touch bar pkill \"Touch Bar agent\" Generate random string openssl rand -base64 6","title":"macOS"},{"location":"OS/MacOS/macOS/#restart-ssh-daemon","text":"sudo launchctl stop com.openssh.sshd sudo launchctl start com.openssh.sshd","title":"Restart ssh daemon"},{"location":"OS/MacOS/macOS/#how-to-refresh-control-strip","text":"killall ControlStrip","title":"How to Refresh Control Strip"},{"location":"OS/MacOS/macOS/#refresh-touch-bar","text":"pkill \"Touch Bar agent\"","title":"Refresh touch bar"},{"location":"OS/MacOS/macOS/#generate-random-string","text":"openssl rand -base64 6","title":"Generate random string"},{"location":"OS/Windows/Powershell/","text":"Find which process is using a specific port PS C:\\Users\\MyUser $port=8080 PS C:\\Users\\MyUser Get-Process -Id (Get-NetTCPConnection -LocalPort $port).OwningProcess Handles NPM(K) PM(K) WS(K) CPU(s) Id SI ProcessName ------- ------ ----- ----- ------ -- -- ----------- 819 61 1005000 577488 58.92 23076 1 java","title":"Powershell"},{"location":"OS/Windows/Powershell/#find-which-process-is-using-a-specific-port","text":"PS C:\\Users\\MyUser $port=8080 PS C:\\Users\\MyUser Get-Process -Id (Get-NetTCPConnection -LocalPort $port).OwningProcess Handles NPM(K) PM(K) WS(K) CPU(s) Id SI ProcessName ------- ------ ----- ----- ------ -- -- ----------- 819 61 1005000 577488 58.92 23076 1 java","title":"Find which process is using a specific port"},{"location":"OS/encryption-and-hashing/GPG-PGP/","text":"Generate keys $ gpg --gen-key Encryption $ gpg --encrypt --sign --armor -r recipient_email -r my@email.com file_to_encrypt Decrypt $ gpg --output path/to/decrypted/file file_to_encrypt.asc Create subkey Backup files $ umask 077; tar -cf $HOME/gnupg-backup.tar -C $HOME .gnupg Find key and edit it gpg --list-keys yourname gpg --edit-key gpg addkey Choose the \"RSA (sign only)\" entropy stuff gpg save","title":"GPG PGP"},{"location":"OS/encryption-and-hashing/GPG-PGP/#generate-keys","text":"$ gpg --gen-key","title":"Generate keys"},{"location":"OS/encryption-and-hashing/GPG-PGP/#encryption","text":"$ gpg --encrypt --sign --armor -r recipient_email -r my@email.com file_to_encrypt","title":"Encryption"},{"location":"OS/encryption-and-hashing/GPG-PGP/#decrypt","text":"$ gpg --output path/to/decrypted/file file_to_encrypt.asc","title":"Decrypt"},{"location":"OS/encryption-and-hashing/GPG-PGP/#create-subkey","text":"","title":"Create subkey"},{"location":"OS/encryption-and-hashing/GPG-PGP/#backup-files","text":"$ umask 077; tar -cf $HOME/gnupg-backup.tar -C $HOME .gnupg","title":"Backup files"},{"location":"OS/encryption-and-hashing/GPG-PGP/#find-key-and-edit-it","text":"gpg --list-keys yourname gpg --edit-key gpg addkey","title":"Find key and edit it"},{"location":"OS/encryption-and-hashing/GPG-PGP/#choose-the-rsa-sign-only","text":"","title":"Choose the \"RSA (sign only)\""},{"location":"OS/encryption-and-hashing/GPG-PGP/#entropy-stuff","text":"gpg save","title":"entropy stuff"},{"location":"OS/encryption-and-hashing/sha/","text":"Checksum sha256 example $ cat p.txt 3c06434c09bb354df6c3f8ec12fbea253a89c7d694e888009841a74d4e1c271a p.json $ sha256sum -c p.txt p.json: OK","title":"Sha"},{"location":"OS/encryption-and-hashing/sha/#checksum","text":"","title":"Checksum"},{"location":"OS/encryption-and-hashing/sha/#sha256-example","text":"$ cat p.txt 3c06434c09bb354df6c3f8ec12fbea253a89c7d694e888009841a74d4e1c271a p.json $ sha256sum -c p.txt p.json: OK","title":"sha256 example"},{"location":"Ops/Encrypt-a-partition-with-DM-Crypt-LUKS/","text":"Encrypt partition $ sudo cryptsetup -y -v luksFormat /dev/xvdc WARNING! ======== This will overwrite data on /dev/xvdc irrevocably. Are you sure? (Type uppercase yes): YES Enter passphrase: Verify passphrase: Command successful. Create mapping cryptsetup luksOpen /dev/xvdc backup2 Format partition pv -tpreb /dev/zero | dd of=/dev/mapper/backup2 bs=128M mkfs.ext4 /dev/mapper/backup2 Unmount umount /backup2 cryptsetup luksClose backup2 Mount cryptsetup luksOpen /dev/xvdc backup2 mount /dev/mapper/backup2 /backup2","title":"Encrypt a partition with DM Crypt LUKS"},{"location":"Ops/Encrypt-a-partition-with-DM-Crypt-LUKS/#encrypt-partition","text":"$ sudo cryptsetup -y -v luksFormat /dev/xvdc WARNING! ======== This will overwrite data on /dev/xvdc irrevocably. Are you sure? (Type uppercase yes): YES Enter passphrase: Verify passphrase: Command successful.","title":"Encrypt partition"},{"location":"Ops/Encrypt-a-partition-with-DM-Crypt-LUKS/#create-mapping","text":"cryptsetup luksOpen /dev/xvdc backup2","title":"Create mapping"},{"location":"Ops/Encrypt-a-partition-with-DM-Crypt-LUKS/#format-partition","text":"pv -tpreb /dev/zero | dd of=/dev/mapper/backup2 bs=128M mkfs.ext4 /dev/mapper/backup2","title":"Format partition"},{"location":"Ops/Encrypt-a-partition-with-DM-Crypt-LUKS/#unmount","text":"umount /backup2 cryptsetup luksClose backup2","title":"Unmount"},{"location":"Ops/Encrypt-a-partition-with-DM-Crypt-LUKS/#mount","text":"cryptsetup luksOpen /dev/xvdc backup2 mount /dev/mapper/backup2 /backup2","title":"Mount"},{"location":"Ops/Mount-a-remote-file-system-through-ssh-Using-sshfs/","text":"Install sudo apt-get install -y sshfs make sure the following condition is met. In the local system, type (as root) Should return nothing # sudo modprobe fuse create the mount point $ sudo mkdir /mnt/remote $ sudo chown [user-name]:[group-name] /mnt/remote/ Add yourself to the fuse group adduser [your-user] fuse switch to your user and mount the remote filesystem. sshfs remote-user@remote.server:/remote/directory /mnt/remote/ If you want to mount a directory other than the home directory, you can specify it after the colon. Actually, a generic sshfs command looks like this: $ sshfs [user@]host:[dir] mountpoint [options] Unmount Your Directory Try: sudo umount /mnt/remote or fusermount -u mountpoint","title":"Mount a remote file system through ssh Using sshfs"},{"location":"Ops/Mount-a-remote-file-system-through-ssh-Using-sshfs/#install","text":"sudo apt-get install -y sshfs","title":"Install"},{"location":"Ops/Mount-a-remote-file-system-through-ssh-Using-sshfs/#make-sure-the-following-condition-is-met-in-the-local-system-type-as-root","text":"Should return nothing # sudo modprobe fuse","title":"make sure the following condition is met. In the local system, type (as root)"},{"location":"Ops/Mount-a-remote-file-system-through-ssh-Using-sshfs/#create-the-mount-point","text":"$ sudo mkdir /mnt/remote $ sudo chown [user-name]:[group-name] /mnt/remote/","title":"create the mount point"},{"location":"Ops/Mount-a-remote-file-system-through-ssh-Using-sshfs/#add-yourself-to-the-fuse-group","text":"adduser [your-user] fuse","title":"Add yourself to the fuse group"},{"location":"Ops/Mount-a-remote-file-system-through-ssh-Using-sshfs/#switch-to-your-user-and-mount-the-remote-filesystem","text":"sshfs remote-user@remote.server:/remote/directory /mnt/remote/","title":"switch to your user and mount the remote filesystem."},{"location":"Ops/Mount-a-remote-file-system-through-ssh-Using-sshfs/#if-you-want-to-mount-a-directory-other-than-the-home-directory-you-can-specify-it-after-the-colon-actually-a-generic-sshfs-command-looks-like-this","text":"$ sshfs [user@]host:[dir] mountpoint [options]","title":"If you want to mount a directory other than the home directory, you can specify it after the colon. Actually, a generic sshfs command looks like this:"},{"location":"Ops/Mount-a-remote-file-system-through-ssh-Using-sshfs/#unmount-your-directory","text":"Try: sudo umount /mnt/remote or fusermount -u mountpoint","title":"Unmount Your Directory"},{"location":"Ops/Network-stuff/","text":"Set static IP Edit the following file /etc/dhcpcd.conf with the following contents (adapted of course) interface eth0 static ip_address=192.168.0.10/24 static routers=192.168.0.1 static domain_name_servers=192.168.0.1 interface wlan0 static ip_address=192.168.0.200/24 static routers=192.168.0.1 static domain_name_servers=192.168.0.1 Get listening ports without netstat ss -aut Scan ip range sudo nmap -sP 192.168.*.* Forward packets echo 1 /proc/sys/net/ipv4/ip_forward OpenVPN automatic login Create file with username in the first line and password in the second, i.e. auth.txt Change the line auth-user-pass to auth-user-pass auth.txt in the .ovpn file * (Optional) Change the line in all the ovpn files with: sed -i 's/auth-user-pass/# 1\\n 1 auth.txt/' vpn_file.ovpn","title":"Network stuff"},{"location":"Ops/Network-stuff/#set-static-ip","text":"Edit the following file /etc/dhcpcd.conf with the following contents (adapted of course) interface eth0 static ip_address=192.168.0.10/24 static routers=192.168.0.1 static domain_name_servers=192.168.0.1 interface wlan0 static ip_address=192.168.0.200/24 static routers=192.168.0.1 static domain_name_servers=192.168.0.1","title":"Set static IP"},{"location":"Ops/Network-stuff/#get-listening-ports-without-netstat","text":"ss -aut","title":"Get listening ports without netstat"},{"location":"Ops/Network-stuff/#scan-ip-range","text":"sudo nmap -sP 192.168.*.*","title":"Scan ip range"},{"location":"Ops/Network-stuff/#forward-packets","text":"echo 1 /proc/sys/net/ipv4/ip_forward","title":"Forward packets"},{"location":"Ops/Network-stuff/#openvpn-automatic-login","text":"Create file with username in the first line and password in the second, i.e. auth.txt Change the line auth-user-pass to auth-user-pass auth.txt in the .ovpn file * (Optional) Change the line in all the ovpn files with: sed -i 's/auth-user-pass/# 1\\n 1 auth.txt/' vpn_file.ovpn","title":"OpenVPN automatic login"},{"location":"Ops/New-environment-from-scratch/","text":"~/.bash_aliases alias ll='ls -l --color' alias instalar='sudo apt-get install -y' Packages python-pip vim postgresql Python sudo -H pip install virtualenv virtualenvwrapper add source /usr/local/bin/virtualenvwrapper.sh to ~/.bashrc tig Useful git tool","title":"New environment from scratch"},{"location":"Ops/New-environment-from-scratch/#bash_aliases","text":"alias ll='ls -l --color' alias instalar='sudo apt-get install -y'","title":"~/.bash_aliases"},{"location":"Ops/New-environment-from-scratch/#packages","text":"python-pip vim postgresql","title":"Packages"},{"location":"Ops/New-environment-from-scratch/#python","text":"sudo -H pip install virtualenv virtualenvwrapper add source /usr/local/bin/virtualenvwrapper.sh to ~/.bashrc","title":"Python"},{"location":"Ops/New-environment-from-scratch/#tig","text":"Useful git tool","title":"tig"},{"location":"Ops/Powershell/","text":"Get process using port get-Process -Id (Get-NetTCPConnection -LocalPort 8080).OwningProcess","title":"Powershell"},{"location":"Ops/Powershell/#get-process-using-port","text":"get-Process -Id (Get-NetTCPConnection -LocalPort 8080).OwningProcess","title":"Get process using port"},{"location":"Ops/SSH/","text":"Basics Create a new SSH Key ssh-keygen -t rsa -C your-email-address Be careful that you don't over-write your existing key for your personal account. Instead, when prompted, save the file as id_rsa_key. In my case, I've saved the file to ~/.ssh/id_rsa_other_key SSH config Taken From here Add aliases edit ~/.ssh/config and put this contents of $HOME/.ssh/config Host dev HostName dev.example.com Port 22000 User fooey With this setup, simply ssh dev and the rest will go fine Aliases with redirection and more Instead of ssh -f -N -L 9906:127.0.0.1:3306 coolio@database.example.com you can add an entry to ~/.ssh/config as the following one: Host tunnel HostName database.example.com IdentityFile ~/.ssh/path_to_PRIVATE_key LocalForward 9906 127.0.0.1:3306 User coolio And just ssh -f -N tunnel Which will make it easier to manage Check key fingerprint SHA-256 ssh-keygen -lf ~/.ssh/id_rsa.pub 1024 SHA256:19n6fkdz0qqmowiBy6XEaA87EuG/jgWUr44ZSBhJl6Y (DSA) MD5 ssh-keygen -E md5 -lf ~/.ssh/id_rsa.pub 2048 MD5:4d:5b:97:19:8c:fe:06:f0:29:e7:f5:96:77:cb:3c:71 (DSA) Passwordless login to machine via SSH ssh-keygen -t rsa (Optional) ssh b@B mkdir -p ~/.ssh cat ~/.ssh/id_rsa.pub | ssh b@B 'cat ~/.ssh/authorized_keys' ssh b@B (should not ask for pw anymore) where B is the host and b is the user Execute graphical command in remote computer ssh user@host DISPLAY=:0 nohup vlc /path/to/media/movie.mp4 Disable SSH password authentication edit /etc/ssh/sshd_config with contents ChallengeResponseAuthentication no PasswordAuthentication no UsePAM no Restart daemon # /etc/init.d/sshd restart Add private key ssh-add public_key_folder/public_key_file Identity added: public_key_folder/public_key_file (public_key_folder/public_key_file) SSH Config File instructions","title":"SSH"},{"location":"Ops/SSH/#basics","text":"","title":"Basics"},{"location":"Ops/SSH/#create-a-new-ssh-key","text":"ssh-keygen -t rsa -C your-email-address Be careful that you don't over-write your existing key for your personal account. Instead, when prompted, save the file as id_rsa_key. In my case, I've saved the file to ~/.ssh/id_rsa_other_key","title":"Create a new SSH Key"},{"location":"Ops/SSH/#ssh-config","text":"Taken From here","title":"SSH config"},{"location":"Ops/SSH/#add-aliases","text":"edit ~/.ssh/config and put this contents of $HOME/.ssh/config Host dev HostName dev.example.com Port 22000 User fooey With this setup, simply ssh dev and the rest will go fine","title":"Add aliases"},{"location":"Ops/SSH/#aliases-with-redirection-and-more","text":"Instead of ssh -f -N -L 9906:127.0.0.1:3306 coolio@database.example.com you can add an entry to ~/.ssh/config as the following one: Host tunnel HostName database.example.com IdentityFile ~/.ssh/path_to_PRIVATE_key LocalForward 9906 127.0.0.1:3306 User coolio And just ssh -f -N tunnel Which will make it easier to manage","title":"Aliases with redirection and more"},{"location":"Ops/SSH/#check-key-fingerprint","text":"","title":"Check key fingerprint"},{"location":"Ops/SSH/#sha-256","text":"ssh-keygen -lf ~/.ssh/id_rsa.pub 1024 SHA256:19n6fkdz0qqmowiBy6XEaA87EuG/jgWUr44ZSBhJl6Y (DSA)","title":"SHA-256"},{"location":"Ops/SSH/#md5","text":"ssh-keygen -E md5 -lf ~/.ssh/id_rsa.pub 2048 MD5:4d:5b:97:19:8c:fe:06:f0:29:e7:f5:96:77:cb:3c:71 (DSA)","title":"MD5"},{"location":"Ops/SSH/#passwordless-login-to-machine-via-ssh","text":"ssh-keygen -t rsa (Optional) ssh b@B mkdir -p ~/.ssh cat ~/.ssh/id_rsa.pub | ssh b@B 'cat ~/.ssh/authorized_keys' ssh b@B (should not ask for pw anymore) where B is the host and b is the user","title":"Passwordless login to machine via SSH"},{"location":"Ops/SSH/#execute-graphical-command-in-remote-computer","text":"ssh user@host DISPLAY=:0 nohup vlc /path/to/media/movie.mp4","title":"Execute graphical command in remote computer"},{"location":"Ops/SSH/#disable-ssh-password-authentication","text":"edit /etc/ssh/sshd_config with contents ChallengeResponseAuthentication no PasswordAuthentication no UsePAM no Restart daemon # /etc/init.d/sshd restart","title":"Disable SSH password authentication"},{"location":"Ops/SSH/#add-private-key","text":"ssh-add public_key_folder/public_key_file Identity added: public_key_folder/public_key_file (public_key_folder/public_key_file)","title":"Add private key"},{"location":"Ops/SSH/#ssh-config-file","text":"instructions","title":"SSH Config File"},{"location":"Ops/AWS/Cli-Config/","text":"Install aws cli sudo -H pip install awscli Add new profile named new_profile_name aws configure --profile new_profile_name","title":"Cli Config"},{"location":"Ops/AWS/Cli-Config/#install-aws-cli","text":"sudo -H pip install awscli","title":"Install aws cli"},{"location":"Ops/AWS/Cli-Config/#add-new-profile-named-new_profile_name","text":"aws configure --profile new_profile_name","title":"Add new profile named new_profile_name"},{"location":"Ops/AWS/EC2/","text":"Get list of info aobut EBS volumes aws ec2 describe-volumes --profile profile-name Get public dns name for machines in us-east-1 region aws ec2 --region us-east-1 describe-instances --query 'Reservations[*].Instances[*].[PublicDnsName]' | grep -v \\[\\|\\] | tr -d ' ' | tr -d ' '","title":"EC2"},{"location":"Ops/AWS/EC2/#get-list-of-info-aobut-ebs-volumes","text":"aws ec2 describe-volumes --profile profile-name","title":"Get list of info aobut EBS volumes"},{"location":"Ops/AWS/EC2/#get-public-dns-name-for-machines-in-us-east-1-region","text":"aws ec2 --region us-east-1 describe-instances --query 'Reservations[*].Instances[*].[PublicDnsName]' | grep -v \\[\\|\\] | tr -d ' ' | tr -d ' '","title":"Get public dns name for machines in us-east-1 region"},{"location":"Ops/AWS/ECS/","text":"Retag image in ECR with the AWS CLI Check it here Use the batch-get-image command to get the image manifest for the image to retag and write it to an environment variable. In this example, the manifest for an image with the tag, latest, in the repository, amazonlinux, is written to the environment variable, MANIFEST. MANIFEST=$(aws ecr batch-get-image --repository-name amazonlinux --image-ids imageTag=latest --query images[].imageManifest --output text) Use the --image-tag option of the put-image command to put the image manifest to Amazon ECR with a new tag. In this example, the image is tagged as 2017.03. Note If the --image-tag option is not available in your version of the AWS CLI, upgrade to the latest version. For more information, see Installing the AWS Command Line Interface in the AWS Command Line Interface User Guide. aws ecr put-image --repository-name amazonlinux --image-tag 2017.03 --image-manifest $MANIFEST Verify that your new image tag is attached to your image. In the output below, the image has the tags latest and 2017.03. aws ecr describe-images --repository-name amazonlinux","title":"ECS"},{"location":"Ops/AWS/ECS/#retag-image-in-ecr-with-the-aws-cli","text":"Check it here Use the batch-get-image command to get the image manifest for the image to retag and write it to an environment variable. In this example, the manifest for an image with the tag, latest, in the repository, amazonlinux, is written to the environment variable, MANIFEST. MANIFEST=$(aws ecr batch-get-image --repository-name amazonlinux --image-ids imageTag=latest --query images[].imageManifest --output text) Use the --image-tag option of the put-image command to put the image manifest to Amazon ECR with a new tag. In this example, the image is tagged as 2017.03. Note If the --image-tag option is not available in your version of the AWS CLI, upgrade to the latest version. For more information, see Installing the AWS Command Line Interface in the AWS Command Line Interface User Guide. aws ecr put-image --repository-name amazonlinux --image-tag 2017.03 --image-manifest $MANIFEST Verify that your new image tag is attached to your image. In the output below, the image has the tags latest and 2017.03. aws ecr describe-images --repository-name amazonlinux","title":"Retag image in ECR with the AWS CLI"},{"location":"Ops/AWS/General/","text":"AWS endpoints List of AWS endpoints for service Block s3 For some reason, it blocks requests from aws java sdk, but not for the ones made from aws cli. block the following host (it works with /etc/hosts, but it's NOT SAFE ): SOME_BUCKET_NAME.s3.amazonaws.com","title":"General"},{"location":"Ops/AWS/General/#aws-endpoints","text":"List of AWS endpoints for service","title":"AWS endpoints"},{"location":"Ops/AWS/General/#block-s3","text":"For some reason, it blocks requests from aws java sdk, but not for the ones made from aws cli. block the following host (it works with /etc/hosts, but it's NOT SAFE ): SOME_BUCKET_NAME.s3.amazonaws.com","title":"Block s3"},{"location":"Ops/AWS/Kinesis/","text":"Python AWS CLI Warning Before using check that you have properly set the AWS_PROFILE env variable to some profile existing in ~/.aws/credentials , or comfortable using the aws default profile as $ export AWS_PROFILE=analytics-storm Get kinesis decoded data aws kinesis get-records --shard-iterator some_shard_hash --profile some-profile | jq \".Records [] .Data\" | tr -d ' \"' | base64 -d $ aws kinesis describe-stream --stream-name stream_name --profile user2 { StreamDescription : { RetentionPeriodHours : 24, StreamName : stream_name , Shards : [ { ShardId : shardId-000000000000 , HashKeyRange : { EndingHashKey : whateverhashkey , StartingHashKey : 0 }, SequenceNumberRange : { StartingSequenceNumber : whateversequencenumber } }, { ShardId : shardId-000000000001 , HashKeyRange : { EndingHashKey : whateverhashke , StartingHashKey : whatevernumber }, SequenceNumberRange : { StartingSequenceNumber : somenumber } } ], StreamARN : arn:aws:kinesis:region:accountNumber:stream/stream_name , EnhancedMonitoring : [ { ShardLevelMetrics : [] } ], StreamStatus : ACTIVE } } $ aws kinesis get-shard-iterator --stream-name tvmetrix --shard-id shardId-000000000001 --shard-iterator-type LATEST { ShardIterator : whateversharditeratorwithnumberslettersandslashes } get shard iterator for specific date (take into account the retention policy for your kinesis service) $ aws kinesis get-shard-iterator --stream-name tvmetrix --shard-id shardId-000000000001 --shard-iterator-type AT_TIMESTAMP --timestamp 2017-05-25 08:00:00 shardId is one appearing in the describe-stream command above for more info about shard-iterator-type http://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html#API_GetShardIterator_RequestSyntax $ aws kinesis get-records --shard-iterator whateversharditeratorwithnumberslettersandslashes --limit 1 --profile user2 { Records : [ { Data : some_encoded_data , PartitionKey : some_numbers , ApproximateArrivalTimestamp : 1490964900.808, SequenceNumber : some_very_long_number } ], NextShardIterator : some_sequence_of_letters_and_numbers_and_slashes , MillisBehindLatest : 0 }","title":"Kinesis"},{"location":"Ops/AWS/Kinesis/#aws-cli","text":"Warning Before using check that you have properly set the AWS_PROFILE env variable to some profile existing in ~/.aws/credentials , or comfortable using the aws default profile as $ export AWS_PROFILE=analytics-storm","title":"AWS CLI"},{"location":"Ops/AWS/Kinesis/#get-kinesis-decoded-data","text":"aws kinesis get-records --shard-iterator some_shard_hash --profile some-profile | jq \".Records [] .Data\" | tr -d ' \"' | base64 -d $ aws kinesis describe-stream --stream-name stream_name --profile user2 { StreamDescription : { RetentionPeriodHours : 24, StreamName : stream_name , Shards : [ { ShardId : shardId-000000000000 , HashKeyRange : { EndingHashKey : whateverhashkey , StartingHashKey : 0 }, SequenceNumberRange : { StartingSequenceNumber : whateversequencenumber } }, { ShardId : shardId-000000000001 , HashKeyRange : { EndingHashKey : whateverhashke , StartingHashKey : whatevernumber }, SequenceNumberRange : { StartingSequenceNumber : somenumber } } ], StreamARN : arn:aws:kinesis:region:accountNumber:stream/stream_name , EnhancedMonitoring : [ { ShardLevelMetrics : [] } ], StreamStatus : ACTIVE } } $ aws kinesis get-shard-iterator --stream-name tvmetrix --shard-id shardId-000000000001 --shard-iterator-type LATEST { ShardIterator : whateversharditeratorwithnumberslettersandslashes } get shard iterator for specific date (take into account the retention policy for your kinesis service) $ aws kinesis get-shard-iterator --stream-name tvmetrix --shard-id shardId-000000000001 --shard-iterator-type AT_TIMESTAMP --timestamp 2017-05-25 08:00:00 shardId is one appearing in the describe-stream command above for more info about shard-iterator-type http://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html#API_GetShardIterator_RequestSyntax $ aws kinesis get-records --shard-iterator whateversharditeratorwithnumberslettersandslashes --limit 1 --profile user2 { Records : [ { Data : some_encoded_data , PartitionKey : some_numbers , ApproximateArrivalTimestamp : 1490964900.808, SequenceNumber : some_very_long_number } ], NextShardIterator : some_sequence_of_letters_and_numbers_and_slashes , MillisBehindLatest : 0 }","title":"Get kinesis decoded data"},{"location":"Ops/AWS/Redshift/","text":"Check the postgresql wiki page out: Check out redshift developer's guide [List databases] (https://gist.github.com/patsancu/50ea9416c0c7ba5746d045e9b047955d) Load data into redsfhit from s3 Data can be loaded recursively. If there's a folder with this structure a/ b/ p.json.gz c/ q.json.gz r.json.gz Calling the copy sentence with the folder a as source will copy all files under the folder recursively copy schema.table_name from 's3://bucket-name/some_folder/some_file.json.gz' -- from 's3://bucket-name/a' with credentials 'aws_access_key_id=some_access_key;ws_secret_access_key=supersupersecretkey' [gzip] format as json 'auto' [region 'us-east-1'] -- If the Amazon S3 buckets that hold the data files do not reside in the same region as your cluster, you must use the REGION parameter to specify the region in which the data is located. Escape strings with Escape Remove the format as csv thing copy analyticsmodel.playback from :sql:source with credentials :sql:redshift-credentials delimiter '~' ignoreheader as 1 [escape] [truncatecolumns Truncates data in columns to the appropriate number of characters it has been specified] Load into redshift with custom field ordering You can specify a comma-separated list of column names to load source data fields into specific target columns. Docs copy schema.table (column_a, column_b, column_c, column_d, column_e, colummn_f) from 's3://some_file.csv' with credentials 'aws_access_key_id=some_access_key;ws_secret_access_key=supersupersecretkey' format as csv ignoreheader as 1 TRUNCATECOLUMNS Check errors select * from stl_load_errors order by starttime desc; Check info about permanent tables The STV_TBL_PERM table contains information about the permanent tables in Amazon Redshift. More info here select * FROM stv_tbl_perm ; Size info about tables First method select database , schema || '.' || table , size as size in Mb , tbl_rows as rows from svv_table_info Second method The query below's info is not exhaustive nor complete SELECT TRIM(pgdb.datname) AS DATABASE, TRIM(pgn.nspname) AS SCHEMA, TRIM(a.name) AS TABLE, b.mbytes, a.rows FROM (SELECT db_id, id, name, SUM(ROWS) AS ROWS FROM stv_tbl_perm a GROUP BY db_id, id, name) AS a JOIN pg_class AS pgc ON pgc.oid = a.id JOIN pg_namespace AS pgn ON pgn.oid = pgc.relnamespace JOIN pg_database AS pgdb ON pgdb.oid = a.db_id JOIN (SELECT tbl, COUNT(*) AS mbytes FROM stv_blocklist GROUP BY tbl) b ON a.id = b.tbl ORDER BY a.db_id, a.name; Generate date series Generate series using any table as a dummy table. create table fechas as select ( date('2017-06-30') + row_number() over (order by true) )::date as fecha from ibc.playback limit 40 Warning . The date_series function thing doesn't work that well on redshift when doing joins and stuff like that. For more info, check redshift's developer guide. WITH date_series_bounds AS ( SELECT date('2012-12-21') as start, date('2013-08-23') as end ), date_series AS ( select date(days.start + days.interval) from ( select bounds.start, generate_series(0, bounds.end - bounds.start) AS interval from date_series_bounds bounds ) as days ) select * from date_series or select current_date - (n*30 || ' minutes')::interval from generate_series (0, 100*5-1) n or select substr(to_date('2017-06-22', 'YYYY-MM-DD') + (n || ' days')::interval, 1,10) from generate_series (0, 6) n List schemas select * from information_schema.schemata Create schema CREATE SCHEMA IF NOT EXISTS schema_name Check data load select * from STL_FILE_SCAN where name like '%screentime%' order by curtime desc","title":"Redshift"},{"location":"Ops/AWS/Redshift/#load-data-into-redsfhit-from-s3","text":"Data can be loaded recursively. If there's a folder with this structure a/ b/ p.json.gz c/ q.json.gz r.json.gz Calling the copy sentence with the folder a as source will copy all files under the folder recursively copy schema.table_name from 's3://bucket-name/some_folder/some_file.json.gz' -- from 's3://bucket-name/a' with credentials 'aws_access_key_id=some_access_key;ws_secret_access_key=supersupersecretkey' [gzip] format as json 'auto' [region 'us-east-1'] -- If the Amazon S3 buckets that hold the data files do not reside in the same region as your cluster, you must use the REGION parameter to specify the region in which the data is located.","title":"Load data into redsfhit from s3"},{"location":"Ops/AWS/Redshift/#escape-strings-with-escape","text":"Remove the format as csv thing copy analyticsmodel.playback from :sql:source with credentials :sql:redshift-credentials delimiter '~' ignoreheader as 1 [escape] [truncatecolumns Truncates data in columns to the appropriate number of characters it has been specified]","title":"Escape strings with Escape"},{"location":"Ops/AWS/Redshift/#load-into-redshift-with-custom-field-ordering","text":"You can specify a comma-separated list of column names to load source data fields into specific target columns. Docs copy schema.table (column_a, column_b, column_c, column_d, column_e, colummn_f) from 's3://some_file.csv' with credentials 'aws_access_key_id=some_access_key;ws_secret_access_key=supersupersecretkey' format as csv ignoreheader as 1 TRUNCATECOLUMNS","title":"Load into redshift with custom field ordering"},{"location":"Ops/AWS/Redshift/#check-errors","text":"select * from stl_load_errors order by starttime desc;","title":"Check errors"},{"location":"Ops/AWS/Redshift/#check-info-about-permanent-tables","text":"The STV_TBL_PERM table contains information about the permanent tables in Amazon Redshift. More info here select * FROM stv_tbl_perm ;","title":"Check info about permanent tables"},{"location":"Ops/AWS/Redshift/#size-info-about-tables","text":"","title":"Size info about tables"},{"location":"Ops/AWS/Redshift/#first-method","text":"select database , schema || '.' || table , size as size in Mb , tbl_rows as rows from svv_table_info","title":"First method"},{"location":"Ops/AWS/Redshift/#second-method","text":"The query below's info is not exhaustive nor complete SELECT TRIM(pgdb.datname) AS DATABASE, TRIM(pgn.nspname) AS SCHEMA, TRIM(a.name) AS TABLE, b.mbytes, a.rows FROM (SELECT db_id, id, name, SUM(ROWS) AS ROWS FROM stv_tbl_perm a GROUP BY db_id, id, name) AS a JOIN pg_class AS pgc ON pgc.oid = a.id JOIN pg_namespace AS pgn ON pgn.oid = pgc.relnamespace JOIN pg_database AS pgdb ON pgdb.oid = a.db_id JOIN (SELECT tbl, COUNT(*) AS mbytes FROM stv_blocklist GROUP BY tbl) b ON a.id = b.tbl ORDER BY a.db_id, a.name;","title":"Second method"},{"location":"Ops/AWS/Redshift/#generate-date-series","text":"Generate series using any table as a dummy table. create table fechas as select ( date('2017-06-30') + row_number() over (order by true) )::date as fecha from ibc.playback limit 40 Warning . The date_series function thing doesn't work that well on redshift when doing joins and stuff like that. For more info, check redshift's developer guide. WITH date_series_bounds AS ( SELECT date('2012-12-21') as start, date('2013-08-23') as end ), date_series AS ( select date(days.start + days.interval) from ( select bounds.start, generate_series(0, bounds.end - bounds.start) AS interval from date_series_bounds bounds ) as days ) select * from date_series or select current_date - (n*30 || ' minutes')::interval from generate_series (0, 100*5-1) n or select substr(to_date('2017-06-22', 'YYYY-MM-DD') + (n || ' days')::interval, 1,10) from generate_series (0, 6) n","title":"Generate date series"},{"location":"Ops/AWS/Redshift/#list-schemas","text":"select * from information_schema.schemata","title":"List schemas"},{"location":"Ops/AWS/Redshift/#create-schema","text":"CREATE SCHEMA IF NOT EXISTS schema_name","title":"Create schema"},{"location":"Ops/AWS/Redshift/#check-data-load","text":"select * from STL_FILE_SCAN where name like '%screentime%' order by curtime desc","title":"Check data load"},{"location":"Ops/AWS/S3/","text":"Python Get s3 data, having initial date and number of days to gather If there's a set of folders named after dates, this works fine Sync folders $ aws s3 sync s3://bucketname1/path/to/folder/2017-04-05 s3://bucketname1/path/to/folder/2017-04-05","title":"S3"},{"location":"Ops/AWS/S3/#get-s3-data-having-initial-date-and-number-of-days-to-gather","text":"If there's a set of folders named after dates, this works fine","title":"Get s3 data, having initial date and number of days to gather"},{"location":"Ops/AWS/S3/#sync-folders","text":"$ aws s3 sync s3://bucketname1/path/to/folder/2017-04-05 s3://bucketname1/path/to/folder/2017-04-05","title":"Sync folders"},{"location":"Ops/Docker/Docker-Machine/","text":"Needed config Install and configure a user to use aws cli Create AIM More info here Create aws machine creates a instance (default t2.micro) docker-machine create --driver amazonec2 --amazonec2-region us-east-1 machine_name Get env vars to connect the Docker Client to the Docker Engine docker-machine env MACHINE_NAME Log into the machine docker-machine ssh machine_name or, get the path to the ssh key and log with it: MACHINE_USERNAME=ubuntu; IP_ADDRESS=$(docker-machine inspect --format='{{prettyjson .Driver.IPAddress}}' docker-machine-01 | tr -d ' '); SSH_DOCKER_MACHINE_KEYPATH=$(docker-machine inspect --format='{{prettyjson .Driver.SSHKeyPath}}' docker-machine-01 | tr -d ' '); ssh -i $SSH_DOCKER_MACHINE_KEYPATH $MACHINE_USERNAME@$IP_ADDRESS Get instance id docker-machine inspect --format='{{prettyjson .Driver.InstanceId}}' machine_name","title":"Docker Machine"},{"location":"Ops/Docker/Docker-Machine/#needed-config","text":"Install and configure a user to use aws cli Create AIM More info here","title":"Needed config"},{"location":"Ops/Docker/Docker-Machine/#create-aws-machine","text":"creates a instance (default t2.micro) docker-machine create --driver amazonec2 --amazonec2-region us-east-1 machine_name","title":"Create aws machine"},{"location":"Ops/Docker/Docker-Machine/#get-env-vars-to-connect-the-docker-client-to-the-docker-engine","text":"docker-machine env MACHINE_NAME","title":"Get env vars to connect the Docker Client to the Docker Engine"},{"location":"Ops/Docker/Docker-Machine/#log-into-the-machine","text":"docker-machine ssh machine_name or, get the path to the ssh key and log with it: MACHINE_USERNAME=ubuntu; IP_ADDRESS=$(docker-machine inspect --format='{{prettyjson .Driver.IPAddress}}' docker-machine-01 | tr -d ' '); SSH_DOCKER_MACHINE_KEYPATH=$(docker-machine inspect --format='{{prettyjson .Driver.SSHKeyPath}}' docker-machine-01 | tr -d ' '); ssh -i $SSH_DOCKER_MACHINE_KEYPATH $MACHINE_USERNAME@$IP_ADDRESS","title":"Log into the machine"},{"location":"Ops/Docker/Docker-Machine/#get-instance-id","text":"docker-machine inspect --format='{{prettyjson .Driver.InstanceId}}' machine_name","title":"Get instance id"},{"location":"Ops/Docker/Docker/","text":"Delete exited containers docker rm -v $(docker ps -a -q -f status=exited) Remove dangling images $ docker rmi $(docker images -f dangling=true -q) Create user Simple way (alpine) RUN addgroup groupname adduser -s /bin/bash -D -G groupname username Complex way # User config ENV UID= 1000 \\ UNAME= developer \\ GID= 1000 \\ GNAME= developer \\ SHELL= /bin/bash \\ UHOME=/home/developer # User creation stuff RUN apk --no-cache add sudo \\ mkdir -p ${UHOME} \\ chown ${UID} : ${GID} ${UHOME} \\ echo ${UNAME}:x:${UID}:${GID}:${UNAME},,,:${UHOME}:${SHELL} \\ /etc/passwd \\ echo ${UNAME}::17032:0:99999:7::: /etc/shadow \\ echo ${UNAME} ALL=(ALL) NOPASSWD: ALL /etc/sudoers.d/${UNAME} \\ chmod 0440 /etc/sudoers.d/${UNAME} \\ echo ${GNAME}:x:${GID}:${UNAME} \\ /etc/group USER developer WORKDIR $UHOME ENV ANT_HOME $UHOME/process-tools/bin Private registry Run private docker registry. Only works in local, because there are no installed certs. Forwards container port 5000 to localhost's 8888 docker run -d -p 8888:5000 registry:2 Docker commit Commit a new image with name commit, tag test, author Joe Bloggs, comment. docker commit -a Joe Bloggs -m Comment RUNNING_IMAGE_ID commit:test Commit a new image with name svendowideit/testimage, tag version4, with changes: a CMD command and an EXPOSE one. docker commit --change='CMD [ apachectl , -DFOREGROUND ]' -c EXPOSE 80 c3f279d17e0a svendowideit/testimage:version4 Get docker container's OS Info here DO NOT USE uname -a uname will tell you the kernel that's running, which is the host OS kernel (containers, unlike VM's, share the same kernel). Not perfect, but still... ### ubuntu lsb_release -sirc ## centos cat /etc/issue ### others cat /etc/os-release","title":"Docker"},{"location":"Ops/Docker/Docker/#delete-exited-containers","text":"docker rm -v $(docker ps -a -q -f status=exited)","title":"Delete exited containers"},{"location":"Ops/Docker/Docker/#remove-dangling-images","text":"$ docker rmi $(docker images -f dangling=true -q)","title":"Remove dangling images"},{"location":"Ops/Docker/Docker/#create-user","text":"","title":"Create user"},{"location":"Ops/Docker/Docker/#simple-way-alpine","text":"RUN addgroup groupname adduser -s /bin/bash -D -G groupname username","title":"Simple way (alpine)"},{"location":"Ops/Docker/Docker/#complex-way","text":"# User config ENV UID= 1000 \\ UNAME= developer \\ GID= 1000 \\ GNAME= developer \\ SHELL= /bin/bash \\ UHOME=/home/developer # User creation stuff RUN apk --no-cache add sudo \\ mkdir -p ${UHOME} \\ chown ${UID} : ${GID} ${UHOME} \\ echo ${UNAME}:x:${UID}:${GID}:${UNAME},,,:${UHOME}:${SHELL} \\ /etc/passwd \\ echo ${UNAME}::17032:0:99999:7::: /etc/shadow \\ echo ${UNAME} ALL=(ALL) NOPASSWD: ALL /etc/sudoers.d/${UNAME} \\ chmod 0440 /etc/sudoers.d/${UNAME} \\ echo ${GNAME}:x:${GID}:${UNAME} \\ /etc/group USER developer WORKDIR $UHOME ENV ANT_HOME $UHOME/process-tools/bin","title":"Complex way"},{"location":"Ops/Docker/Docker/#private-registry","text":"Run private docker registry. Only works in local, because there are no installed certs. Forwards container port 5000 to localhost's 8888 docker run -d -p 8888:5000 registry:2","title":"Private registry"},{"location":"Ops/Docker/Docker/#docker-commit","text":"Commit a new image with name commit, tag test, author Joe Bloggs, comment. docker commit -a Joe Bloggs -m Comment RUNNING_IMAGE_ID commit:test Commit a new image with name svendowideit/testimage, tag version4, with changes: a CMD command and an EXPOSE one. docker commit --change='CMD [ apachectl , -DFOREGROUND ]' -c EXPOSE 80 c3f279d17e0a svendowideit/testimage:version4","title":"Docker commit"},{"location":"Ops/Docker/Docker/#get-docker-containers-os","text":"Info here DO NOT USE uname -a uname will tell you the kernel that's running, which is the host OS kernel (containers, unlike VM's, share the same kernel).","title":"Get docker container's OS"},{"location":"Ops/Docker/Docker/#not-perfect-but-still","text":"### ubuntu lsb_release -sirc ## centos cat /etc/issue ### others cat /etc/os-release","title":"Not perfect, but still..."},{"location":"Ops/Kubernetes/Kubernetes/","text":"Config Different configs If one wants to specify a config other than the default,you may want to run kubectl with the --kubeconfig option kubectl --kubeconfig ~/.kube/miniconfig get nodes The default being the one stored in ~/.kube/config Change default namespace Edit ~/.kube/config/ and change contexts.context.namespace Changing namespace programmatically You can permanently save the namespace for all subsequent kubectl commands in that context. kubectl config set-context $(kubectl config current-context) --namespace= insert-namespace-name-here Create deployment from some container, exposing port 8080 See Generators section @https://kubernetes.io/docs/user-guide/kubectl-conventions/ kubectl run extractor --image=miradatv/iris-analytics-information-extractor --port=8080 --generator=run-deployment/v1 Get \"extractor\" deployment yaml config file kubectl get deploy extractor -o yaml Expose deployment as a service kubectl expose deployment extractor --type=NodePort Get \"extractor\" service yaml config file kubectl get svc extractor -o yaml Curl the api More info APISERVER=$(kubectl config view | grep server | cut -f 2- -d : | tr -d ) TOKEN=$(kubectl describe secret $(kubectl get secrets | grep default | cut -f1 -d ' ') | grep -E '^token' | cut -f2 -d':' | tr -d '\\t') curl $APISERVER/api --header Authorization: Bearer $TOKEN --insecure Check what API endpoints the kubectl command is using v param is configurable $ ./kubectl get pods -v=6 [...] GET https://subdomain.domain.com/api/v1/namespaces/default/pods [...] Enable autocompletion From cheatsheet $ source (kubectl completion bash) # setup autocomplete in bash, bash-completion package should be installed first. $ source (kubectl completion zsh) # setup autocomplete in zsh Execute app on pod kubectl exec -ti drill-alluxio-0 -c drill -- command_path_in_remote_machine -u jdbc:drill:drillbit=localhost;user=ps Actions Get most of the info kubectl get po,svc,rc,rs,pvc --all-namespaces; echo PV--No namespace for them ; kubectl get pv Get cronjob's yaml # kubectl get cronjob reports-daily -n tvmetrix -o yam Live-edit cronjob # kubectl edit cronjob reports-daily -n tvmetrix Get logs $ kubectl logs --tail=1000 -f -n monitoring podname prometheus Get list of pods $ kubectl get pods Get list of nodes $ kubectl get nodes Get info about specific pod $ kubectl describe pod storm-nimbus Kubectl remote command execution examples Read line 166 from json gzipped file available in an alluxio mount at /some/path/to folder kubectl exec -ti alluxio-master-0 -- bash -c 'alluxio fs cat /some/path/to/file.json.gz | gzip -d' | sed -n -e 166p | jq '.'","title":"Kubernetes"},{"location":"Ops/Kubernetes/Kubernetes/#config","text":"","title":"Config"},{"location":"Ops/Kubernetes/Kubernetes/#different-configs","text":"If one wants to specify a config other than the default,you may want to run kubectl with the --kubeconfig option kubectl --kubeconfig ~/.kube/miniconfig get nodes The default being the one stored in ~/.kube/config","title":"Different configs"},{"location":"Ops/Kubernetes/Kubernetes/#change-default-namespace","text":"Edit ~/.kube/config/ and change contexts.context.namespace","title":"Change default namespace"},{"location":"Ops/Kubernetes/Kubernetes/#changing-namespace-programmatically","text":"You can permanently save the namespace for all subsequent kubectl commands in that context. kubectl config set-context $(kubectl config current-context) --namespace= insert-namespace-name-here","title":"Changing namespace programmatically"},{"location":"Ops/Kubernetes/Kubernetes/#create-deployment-from-some-container-exposing-port-8080","text":"","title":"Create deployment from some container, exposing port 8080"},{"location":"Ops/Kubernetes/Kubernetes/#see-generators-section-httpskubernetesiodocsuser-guidekubectl-conventions","text":"kubectl run extractor --image=miradatv/iris-analytics-information-extractor --port=8080 --generator=run-deployment/v1","title":"See Generators section @https://kubernetes.io/docs/user-guide/kubectl-conventions/"},{"location":"Ops/Kubernetes/Kubernetes/#get-extractor-deployment-yaml-config-file","text":"kubectl get deploy extractor -o yaml","title":"Get \"extractor\" deployment yaml config file"},{"location":"Ops/Kubernetes/Kubernetes/#expose-deployment-as-a-service","text":"kubectl expose deployment extractor --type=NodePort","title":"Expose deployment as a service"},{"location":"Ops/Kubernetes/Kubernetes/#get-extractor-service-yaml-config-file","text":"kubectl get svc extractor -o yaml","title":"Get \"extractor\" service yaml config file"},{"location":"Ops/Kubernetes/Kubernetes/#curl-the-api","text":"More info APISERVER=$(kubectl config view | grep server | cut -f 2- -d : | tr -d ) TOKEN=$(kubectl describe secret $(kubectl get secrets | grep default | cut -f1 -d ' ') | grep -E '^token' | cut -f2 -d':' | tr -d '\\t') curl $APISERVER/api --header Authorization: Bearer $TOKEN --insecure","title":"Curl the api"},{"location":"Ops/Kubernetes/Kubernetes/#check-what-api-endpoints-the-kubectl-command-is-using","text":"v param is configurable $ ./kubectl get pods -v=6 [...] GET https://subdomain.domain.com/api/v1/namespaces/default/pods [...]","title":"Check what API endpoints the kubectl command is using"},{"location":"Ops/Kubernetes/Kubernetes/#enable-autocompletion","text":"From cheatsheet $ source (kubectl completion bash) # setup autocomplete in bash, bash-completion package should be installed first. $ source (kubectl completion zsh) # setup autocomplete in zsh","title":"Enable autocompletion"},{"location":"Ops/Kubernetes/Kubernetes/#execute-app-on-pod","text":"kubectl exec -ti drill-alluxio-0 -c drill -- command_path_in_remote_machine -u jdbc:drill:drillbit=localhost;user=ps","title":"Execute app on pod"},{"location":"Ops/Kubernetes/Kubernetes/#actions","text":"","title":"Actions"},{"location":"Ops/Kubernetes/Kubernetes/#get-most-of-the-info","text":"kubectl get po,svc,rc,rs,pvc --all-namespaces; echo PV--No namespace for them ; kubectl get pv","title":"Get most of the info"},{"location":"Ops/Kubernetes/Kubernetes/#get-cronjobs-yaml","text":"# kubectl get cronjob reports-daily -n tvmetrix -o yam","title":"Get cronjob's yaml"},{"location":"Ops/Kubernetes/Kubernetes/#live-edit-cronjob","text":"# kubectl edit cronjob reports-daily -n tvmetrix","title":"Live-edit cronjob"},{"location":"Ops/Kubernetes/Kubernetes/#get-logs","text":"$ kubectl logs --tail=1000 -f -n monitoring podname prometheus","title":"Get logs"},{"location":"Ops/Kubernetes/Kubernetes/#get-list-of-pods","text":"$ kubectl get pods","title":"Get list of pods"},{"location":"Ops/Kubernetes/Kubernetes/#get-list-of-nodes","text":"$ kubectl get nodes","title":"Get list of nodes"},{"location":"Ops/Kubernetes/Kubernetes/#get-info-about-specific-pod","text":"$ kubectl describe pod storm-nimbus","title":"Get info about specific pod"},{"location":"Ops/Kubernetes/Kubernetes/#kubectl-remote-command-execution-examples","text":"","title":"Kubectl remote command execution examples"},{"location":"Ops/Kubernetes/Kubernetes/#read-line-166-from-json-gzipped-file-available-in-an-alluxio-mount-at-somepathto-folder","text":"kubectl exec -ti alluxio-master-0 -- bash -c 'alluxio fs cat /some/path/to/file.json.gz | gzip -d' | sed -n -e 166p | jq '.'","title":"Read line 166 from json gzipped file available in an alluxio mount at /some/path/to folder"},{"location":"Ops/Kubernetes/Minikube/","text":"Mount local folder mount-dir to minikube's cluster \"channels-folder\" folder minikube mount mount-dir:/channels-folder unset docker minikube stuff eval $(minikube docker-env -u) set docker minikube stuff eval $(minikube docker-env)","title":"Minikube"},{"location":"Ops/Kubernetes/Minikube/#mount-local-folder-mount-dir-to-minikubes-cluster-channels-folder-folder","text":"minikube mount mount-dir:/channels-folder","title":"Mount local folder mount-dir to minikube's cluster \"channels-folder\" folder"},{"location":"Ops/Kubernetes/Minikube/#unset-docker-minikube-stuff","text":"eval $(minikube docker-env -u)","title":"unset docker minikube stuff"},{"location":"Ops/Kubernetes/Minikube/#set-docker-minikube-stuff","text":"eval $(minikube docker-env)","title":"set docker minikube stuff"},{"location":"Ops/Shell/Script-building/","text":"Simple stop echo Press enter to continue ; read noing Colorize cat output of source files $ pip install Pygments http://pygments.org/ with pygmentize -g filename Yes no answer testFile=/home/patrick/dev/master.properties sampleService='iris-cms-metadata-management-service' if [ ! -f $testFile ]; then tput setaf 2 echo test properties file $testFile is missing tput sgr0else tput setaf 1; echo Will delete all data from the CMS db. ; tput sgr0 ; read -r -p Are you sure? [y/N] response case $response in [yY][eE][sS]|[yY]) cd $sampleService; gradle dropDatabase -Parchaius.url=file:$testFile ; cd -; ;; *) echo OK, no harm done ; ;; esac fi Argument parsing vflag=off filename= while getopts vf: opt do case $opt in v) vflag=on;; f) filename= $OPTARG ;; \\?) # unknown flag echo 2 \\ usage: $0 [-v] [-f filename] [file ...] exit 1;; esac done shift `expr $OPTIND - 1` Arrays distro=( redhat debian gentoo ) echo ${distro[2]} # will print gentoo echo ${#distro[@]} # will print array length: 3 Get parent folder from script DIR= $( cd $( dirname ${BASH_SOURCE[0]} ) pwd ) Split colon delimited value From here ### this sets the internal field separator variable IFS= : s='Strings:With:Four:Words' IFS= : read -r var1 var2 var3 var4 $s echo [$var1] [$var2] [$var3 [$var4] [Strings] [With] [Four [Words] Select specific lines with sed select line 10 up to line 33 sed -n '10,33p' file.txt select 1st line and 3rd line sed -n '1p;3p' file.txt","title":"Script building"},{"location":"Ops/Shell/Script-building/#simple-stop","text":"echo Press enter to continue ; read noing","title":"Simple stop"},{"location":"Ops/Shell/Script-building/#colorize-cat-output-of-source-files","text":"$ pip install Pygments http://pygments.org/ with pygmentize -g filename","title":"Colorize cat output of source files"},{"location":"Ops/Shell/Script-building/#yes-no-answer","text":"testFile=/home/patrick/dev/master.properties sampleService='iris-cms-metadata-management-service' if [ ! -f $testFile ]; then tput setaf 2 echo test properties file $testFile is missing tput sgr0else tput setaf 1; echo Will delete all data from the CMS db. ; tput sgr0 ; read -r -p Are you sure? [y/N] response case $response in [yY][eE][sS]|[yY]) cd $sampleService; gradle dropDatabase -Parchaius.url=file:$testFile ; cd -; ;; *) echo OK, no harm done ; ;; esac fi","title":"Yes no answer"},{"location":"Ops/Shell/Script-building/#argument-parsing","text":"vflag=off filename= while getopts vf: opt do case $opt in v) vflag=on;; f) filename= $OPTARG ;; \\?) # unknown flag echo 2 \\ usage: $0 [-v] [-f filename] [file ...] exit 1;; esac done shift `expr $OPTIND - 1`","title":"Argument parsing"},{"location":"Ops/Shell/Script-building/#arrays","text":"distro=( redhat debian gentoo ) echo ${distro[2]} # will print gentoo echo ${#distro[@]} # will print array length: 3","title":"Arrays"},{"location":"Ops/Shell/Script-building/#get-parent-folder-from-script","text":"DIR= $( cd $( dirname ${BASH_SOURCE[0]} ) pwd )","title":"Get parent folder from script"},{"location":"Ops/Shell/Script-building/#split-colon-delimited-value","text":"From here ### this sets the internal field separator variable IFS= : s='Strings:With:Four:Words' IFS= : read -r var1 var2 var3 var4 $s echo [$var1] [$var2] [$var3 [$var4] [Strings] [With] [Four [Words]","title":"Split colon delimited value"},{"location":"Ops/Shell/Script-building/#select-specific-lines-with-sed","text":"","title":"Select specific lines with sed"},{"location":"Ops/Shell/Script-building/#select-line-10-up-to-line-33","text":"sed -n '10,33p' file.txt","title":"select line 10 up to line 33"},{"location":"Ops/Shell/Script-building/#select-1st-line-and-3rd-line","text":"sed -n '1p;3p' file.txt","title":"select 1st line and 3rd line"},{"location":"Ops/Shell/Scripts/","text":"Put in ~/bin general byzanz-record-window records screen as a gif work proxymetrix","title":"Scripts"},{"location":"Ops/Shell/Scripts/#general","text":"","title":"general"},{"location":"Ops/Shell/Scripts/#byzanz-record-window","text":"records screen as a gif","title":"byzanz-record-window"},{"location":"Ops/Shell/Scripts/#work","text":"","title":"work"},{"location":"Ops/Shell/Scripts/#proxymetrix","text":"","title":"proxymetrix"},{"location":"Ops/Shell/Shell/","text":"Bash wiki Setup a local smtpserver $ python -m smtpd -n -c DebuggingServer localhost:1025 Prettify xml echo ' root foo a= b lorem /foo bar value= ipsum / /root ' | xmllint --format - Prettify xml and convert html entities to symbols cat document.xml | xmllint --format - | python3 -c 'import html, sys; [print(html.unescape(l), end= ) for l in sys.stdin]' Change shell chsh -s /usr/local/bin/bash [username] Execute command without any env variable or with just a few zsh $ P= ZZZ ; echo $P ZZZ zsh $ echo $PATATA $ env -i PATATA= patatina PAT= ata bash echo $ZZZ $ echo $PATATA patatina Super simple text file creation DON'T USE IN EXISTING FILES, IT WILL OVERWRITE THEM Write to file until EOF is written (in a single line) $ cat EOF p.c some line another line EOF $ cat p.c some line another line Double substution $ foo= whatever $ i=foo $ echo $echo ${!i} whatever Execute process in background with lock Executes process with nohup and flock See gist Shutdown process above See gist Flock Use flock as in here Get url for git repo xdg-open `git remote -v | grep fetch | head -1 | cut -f2 | cut -d' ' -f1 | sed -e's/git@/http:\\/\\//' -e's/\\.git$//' | sed -E 's/(\\/\\/[^:]*):/\\1\\//'` Wget Download all pdfs linked in a website Warning: Even if it recreates only the pdfs, it will download every file referenced by links $ wget -r -A.pdf http://people.seas.harvard.edu/~minilek/cs229r/fall15/lec.html Download all pdfs linked in a website, including linked websites (1 level) $ wget -r -l1 -A.pdf http://people.seas.harvard.edu/~minilek/cs229r/fall15/lec.html Bash-erize cli any Python object python-fire Set bash variable default value ${parameter=default}, ${parameter:=default} The : makes a difference only when $parameter has been declared and is null $ echo $var $ echo ${var:=abc} # abc abc $ echo ${var} # abc abc http://www.tldp.org/LDP/abs/html/parameter-substitution.html#PARAMSUBREF One line to pretty separate jsons curl -s localhost:7080/mappings | python -mjson.tool Xargs with files with spaces on path ls *mp3 | xargs -d '\\n' mplayer Word frequency of text file cat ~/filename.txt | tr ' ' '\\n' | sort | uniq -c | awk '{print $2\"@\"$1}' Egrep Given a file with json lines having a field \"parentalRating\" and a number (e.g. '\"parentalRating\":\"17\"') , the following command will get the set of unique parental ratings, along with their frequencies in (frequency, key) pairs. The o option is to output only the strings matching the egrep regex $ egrep parentalRating\\ :\\ [0-9]+ file.json -o | cut -d ':' -f 2 | tr -d ' ' | sort | uniq -c 1314 0 6209 13 1525 15 4518 17 3 18 3564 7 Diff folders https://gist.github.com/37b660b98f6d29ecd1af87ffb426f380 Record Your Command Line Session $ script Exit typing $ exit All of your typings (and their reults) will be saved to a file named typescript Globstar To allow double \"*\" as a recursive filepath parameter, eg ls **/*.xml add shopt -s globstar to .bashrc Substring Removal Deletes shortest match of $substring from front of $string. ${string#substring} Deletes longest match of $substring from front of $string. ${string##substring} Get last folder of current working directoy $ pwd /home/patrick/dev/python $ echo ${PWD##*/} python Basic integer sequence loop #!/bin/bash for i in `seq 1 10`; do echo $i done Display Output as a Table cat /etc/passwd | column -t -s Repeat a Command Until It Runs Successfully while true; do ping -c 1 8.8.8.8 /dev/null 2 1 break; done Suspend machine As root, # pm-suspend Convert a File to Upper or Lower Case cat myfile | tr a-z A-Z output.txt Sort Processes by Memory Usage ps aux | sort -rnk 4 Sort Processes by CPU Usage ps aux | sort -nk 3 Xargs example ls /etc/*.conf | xargs -i cp {} /home/likegeeks/Desktop/out dd Basic syntax dd bs=4M if=/dev/sdd of=from-sd-card.img See progress of dd sudo pkill -USR1 -n -x dd This will show the progess in the same terminal dd was executed Create File With a Specific Size dd if=/dev/zero of=out.txt bs=1M count=10 Shorten url with goo.gl The $GOOGLE_SHORTEN_API_KEY variable needs to be set, and jq needs to be installed shorten(){ curl https://www.googleapis.com/urlshortener/v1/url?key=$GOOGLE_SHORTEN_API_KEY -H 'Content-Type: application/json' -d {'longUrl': \\ $1\\ } | jq '.id' } Automatically press keys when condition is met Use expect as in here Convert windows-encoded text file to unix-encoded awk 'BEGIN{RS= ^$ ;ORS= ;getline;gsub( \\r , );print ARGV[1]}' file_name Loop through defined array array=( one two three ) for i in ${array[@]} do echo $i done Read lines from file in a for loop input= /path/to/txt/file while IFS= read -r var do echo $var done $input or while read variable_name; do echo JDSA $variable_name ; done workers.txt Display info about memory $ sudo lshw -C memory Open the current repo on a specific web repo my_hgweb() { if [ -d .hg ]; then xdg-open http://web-repo-address/hg/${PWD##*/} /dev/null else echo Not mercurial directory fi } alias hgweb=my_hgweb Colors With tput Colors 0 \u2013 Black. 1 \u2013 Red. 2 \u2013 Green. 3 \u2013 Yellow. 4 \u2013 Blue. 5 \u2013 Magenta. 6 \u2013 Cyan. 7 \u2013 White. Clear all options tput setab clear tput sgr0 Set foreground color tput setaf 6; # turquoise Set background color tput setab 2; # green Set bold tput bold; More info: http://linuxcommand.org/lc3_adv_tput.php Show all color combinations https://gist.github.com/patsancu/44fcdb7d7d195add5bc87e4aa5df88c6 Useful snippets File management Rename files in folder to sorted files c=0; for i in `ls`;do echo $i ; c=$((c+1)); mv $i $c.txt ; done Rename files, change extesion for file in *.html do mv $file ${file%.html}.txt done Get extension of file filename=$(basename $fullfile ) extension= ${filename##*.} filename= ${filename%.*} Change mac address sudo ifconfig eth0 down sudo ifconfig eth0 hw ether xx:xx:xx:xx:xx:xx sudo ifconfig eth0 up Date Format current date $ date +'%Y%m%d' Add days to date date -d + 2 days date -d + 3 minutes date -d + 4 months From epoch seconds to date $ date -d @1463234960 samedi 14 mai 2016, 16:09:20 (UTC+0200) Combine $ date -d @1463234960 + %Y-%m-%d 2016-05-14 $ date -d 1492/10/12 14:00:02 + %Y-%m-%d %H:%M 1492-10-12 14:00 For more info about date input formats Useful commands pv show progress of command dd bs=4M if=/media/somedrive/raspbian-jessie.img | pv | dd of=/dev/mmcblk0 pgrep get PID by name pkill kill process by name timeout n command execute command for n seconds See calendar for previous month, next month, and three months from now $ ncal -3 -A 2 Encode/decode base64 data $ echo patata | base64 cGF0YXRhCg== $ echo patata | base64 | base64 -d Exit traps Reference Example: #!/bin/bash scratch=$(mktemp -d -t tmp.XXXXXXXXXX) function finish { rm -rf $scratch } trap finish EXIT Check OS type if [[ $OSTYPE == linux-gnu ]]; then # ... elif [[ $OSTYPE == darwin * ]]; then # Mac OSX elif [[ $OSTYPE == cygwin ]]; then # POSIX compatibility layer and Linux environment emulation for Windows elif [[ $OSTYPE == msys ]]; then # Lightweight shell and GNU utilities compiled for Windows (part of MinGW) elif [[ $OSTYPE == win32 ]]; then # I'm not sure this can happen. elif [[ $OSTYPE == freebsd * ]]; then # ... else # Flatten directory Moves recursively all files under folder \"dir1\" (at any level of depth) to the \"dir1\" folder. find dir1 -type f -exec mv {} dir1 \\; Declare variables for a command Yes FOO=bar bash -c 'echo $FOO' No FOO=bar bash -c echo $FOO Get duplicate lines and count prints duplicate lines only cat some_file.csv | uniq -cd Geotag pictures #!/bin/bash lat=$(curl http://nominatim.openstreetmap.org/search? city=$1 country=$2 format=json | jq '.[0] | .lat' | tr \u00add ' ') lon=$(curl http://nominatim.openstreetmap.org/search? city=$1 country=$2 format=json | jq '.[0] | .lon' | tr \u00add ' ') exiftool \u00adGPSLongitude=$lon \u00adGPSLatitude=$lat \u00adext jpg . Prettify json curl -s localhost:7080/mappings | python -mjson.tool Print undefined progress spinner declare spin function with: sp= /-\\| sc=0 spin() { printf \\b${sp:sc++:1} ((sc==${#sp})) sc=0 } Then, use it in a loop, for example: SECONDS=40 PERIOD_LENGTH=100 FREQUENCY=$(bc $PERIOD_LENGTH*$SECONDS ) COUNTER=$((SECONDS * $PERIOD_LENGTH)) while [ $COUNTER -gt 0 ] do COUNTER=$[$COUNTER-1] sleep 0.01; spin done Grep: highligh matched patterns but not otherwise change ouput grep --color=always -e ^ -e hello testfile Random numbers zsh or bash random between 0-999 echo $[${RANDOM}%1000] random between 10-20 $[${RANDOM}%11+10] random number that's N digits long ${(l:3::0:)${RANDOM}}","title":"Shell"},{"location":"Ops/Shell/Shell/#bash-wiki","text":"","title":"Bash wiki"},{"location":"Ops/Shell/Shell/#setup-a-local-smtpserver","text":"$ python -m smtpd -n -c DebuggingServer localhost:1025","title":"Setup a local smtpserver"},{"location":"Ops/Shell/Shell/#prettify-xml","text":"echo ' root foo a= b lorem /foo bar value= ipsum / /root ' | xmllint --format -","title":"Prettify xml"},{"location":"Ops/Shell/Shell/#prettify-xml-and-convert-html-entities-to-symbols","text":"cat document.xml | xmllint --format - | python3 -c 'import html, sys; [print(html.unescape(l), end= ) for l in sys.stdin]'","title":"Prettify xml and convert html entities to symbols"},{"location":"Ops/Shell/Shell/#change-shell","text":"chsh -s /usr/local/bin/bash [username]","title":"Change shell"},{"location":"Ops/Shell/Shell/#execute-command-without-any-env-variable-or-with-just-a-few","text":"zsh $ P= ZZZ ; echo $P ZZZ zsh $ echo $PATATA $ env -i PATATA= patatina PAT= ata bash echo $ZZZ $ echo $PATATA patatina","title":"Execute command without any env variable or with just a few"},{"location":"Ops/Shell/Shell/#super-simple-text-file-creation","text":"","title":"Super simple text file creation"},{"location":"Ops/Shell/Shell/#dont-use-in-existing-files-it-will-overwrite-them","text":"Write to file until EOF is written (in a single line) $ cat EOF p.c some line another line EOF $ cat p.c some line another line","title":"DON'T USE IN EXISTING FILES, IT WILL OVERWRITE THEM"},{"location":"Ops/Shell/Shell/#double-substution","text":"$ foo= whatever $ i=foo $ echo $echo ${!i} whatever","title":"Double substution"},{"location":"Ops/Shell/Shell/#execute-process-in-background-with-lock","text":"","title":"Execute process in background with lock"},{"location":"Ops/Shell/Shell/#executes-process-with-nohup-and-flock","text":"See gist","title":"Executes process with nohup and flock"},{"location":"Ops/Shell/Shell/#shutdown-process-above","text":"See gist","title":"Shutdown process above"},{"location":"Ops/Shell/Shell/#flock","text":"Use flock as in here","title":"Flock"},{"location":"Ops/Shell/Shell/#get-url-for-git-repo","text":"xdg-open `git remote -v | grep fetch | head -1 | cut -f2 | cut -d' ' -f1 | sed -e's/git@/http:\\/\\//' -e's/\\.git$//' | sed -E 's/(\\/\\/[^:]*):/\\1\\//'`","title":"Get url for git repo"},{"location":"Ops/Shell/Shell/#wget","text":"","title":"Wget"},{"location":"Ops/Shell/Shell/#download-all-pdfs-linked-in-a-website","text":"Warning: Even if it recreates only the pdfs, it will download every file referenced by links $ wget -r -A.pdf http://people.seas.harvard.edu/~minilek/cs229r/fall15/lec.html","title":"Download all pdfs linked in a website"},{"location":"Ops/Shell/Shell/#download-all-pdfs-linked-in-a-website-including-linked-websites-1-level","text":"$ wget -r -l1 -A.pdf http://people.seas.harvard.edu/~minilek/cs229r/fall15/lec.html","title":"Download all pdfs linked in a website, including linked websites (1 level)"},{"location":"Ops/Shell/Shell/#bash-erize-cli-any-python-object","text":"python-fire","title":"Bash-erize cli any Python object"},{"location":"Ops/Shell/Shell/#set-bash-variable-default-value","text":"${parameter=default}, ${parameter:=default} The : makes a difference only when $parameter has been declared and is null $ echo $var $ echo ${var:=abc} # abc abc $ echo ${var} # abc abc http://www.tldp.org/LDP/abs/html/parameter-substitution.html#PARAMSUBREF","title":"Set bash variable default value"},{"location":"Ops/Shell/Shell/#one-line-to-pretty-separate-jsons","text":"curl -s localhost:7080/mappings | python -mjson.tool","title":"One line to pretty separate jsons"},{"location":"Ops/Shell/Shell/#xargs-with-files-with-spaces-on-path","text":"ls *mp3 | xargs -d '\\n' mplayer","title":"Xargs with files with spaces on path"},{"location":"Ops/Shell/Shell/#word-frequency-of-text-file","text":"cat ~/filename.txt | tr ' ' '\\n' | sort | uniq -c | awk '{print $2\"@\"$1}'","title":"Word frequency of text file"},{"location":"Ops/Shell/Shell/#egrep","text":"Given a file with json lines having a field \"parentalRating\" and a number (e.g. '\"parentalRating\":\"17\"') , the following command will get the set of unique parental ratings, along with their frequencies in (frequency, key) pairs. The o option is to output only the strings matching the egrep regex $ egrep parentalRating\\ :\\ [0-9]+ file.json -o | cut -d ':' -f 2 | tr -d ' ' | sort | uniq -c 1314 0 6209 13 1525 15 4518 17 3 18 3564 7","title":"Egrep"},{"location":"Ops/Shell/Shell/#diff-folders","text":"https://gist.github.com/37b660b98f6d29ecd1af87ffb426f380","title":"Diff folders"},{"location":"Ops/Shell/Shell/#record-your-command-line-session","text":"$ script Exit typing $ exit All of your typings (and their reults) will be saved to a file named typescript","title":"Record Your Command Line Session"},{"location":"Ops/Shell/Shell/#globstar","text":"To allow double \"*\" as a recursive filepath parameter, eg ls **/*.xml add shopt -s globstar to .bashrc","title":"Globstar"},{"location":"Ops/Shell/Shell/#substring-removal","text":"","title":"Substring Removal"},{"location":"Ops/Shell/Shell/#deletes-shortest-match-of-substring-from-front-of-string","text":"${string#substring}","title":"Deletes shortest match of $substring from front of $string."},{"location":"Ops/Shell/Shell/#deletes-longest-match-of-substring-from-front-of-string","text":"${string##substring}","title":"Deletes longest match of $substring from front of $string."},{"location":"Ops/Shell/Shell/#get-last-folder-of-current-working-directoy","text":"$ pwd /home/patrick/dev/python $ echo ${PWD##*/} python","title":"Get last folder of current working directoy"},{"location":"Ops/Shell/Shell/#basic-integer-sequence-loop","text":"#!/bin/bash for i in `seq 1 10`; do echo $i done","title":"Basic integer sequence loop"},{"location":"Ops/Shell/Shell/#display-output-as-a-table","text":"cat /etc/passwd | column -t -s","title":"Display Output as a Table"},{"location":"Ops/Shell/Shell/#repeat-a-command-until-it-runs-successfully","text":"while true; do ping -c 1 8.8.8.8 /dev/null 2 1 break; done","title":"Repeat a Command Until It Runs Successfully"},{"location":"Ops/Shell/Shell/#suspend-machine","text":"As root, # pm-suspend","title":"Suspend machine"},{"location":"Ops/Shell/Shell/#convert-a-file-to-upper-or-lower-case","text":"cat myfile | tr a-z A-Z output.txt","title":"Convert a File to Upper or Lower Case"},{"location":"Ops/Shell/Shell/#sort-processes-by-memory-usage","text":"ps aux | sort -rnk 4","title":"Sort Processes by Memory Usage"},{"location":"Ops/Shell/Shell/#sort-processes-by-cpu-usage","text":"ps aux | sort -nk 3","title":"Sort Processes by CPU Usage"},{"location":"Ops/Shell/Shell/#xargs-example","text":"ls /etc/*.conf | xargs -i cp {} /home/likegeeks/Desktop/out","title":"Xargs example"},{"location":"Ops/Shell/Shell/#dd","text":"","title":"dd"},{"location":"Ops/Shell/Shell/#basic-syntax","text":"dd bs=4M if=/dev/sdd of=from-sd-card.img","title":"Basic syntax"},{"location":"Ops/Shell/Shell/#see-progress-of-dd","text":"sudo pkill -USR1 -n -x dd This will show the progess in the same terminal dd was executed","title":"See progress of dd"},{"location":"Ops/Shell/Shell/#create-file-with-a-specific-size","text":"dd if=/dev/zero of=out.txt bs=1M count=10","title":"Create File With a Specific Size"},{"location":"Ops/Shell/Shell/#shorten-url-with-googl","text":"The $GOOGLE_SHORTEN_API_KEY variable needs to be set, and jq needs to be installed shorten(){ curl https://www.googleapis.com/urlshortener/v1/url?key=$GOOGLE_SHORTEN_API_KEY -H 'Content-Type: application/json' -d {'longUrl': \\ $1\\ } | jq '.id' }","title":"Shorten url with goo.gl"},{"location":"Ops/Shell/Shell/#automatically-press-keys-when-condition-is-met","text":"Use expect as in here","title":"Automatically press keys when condition is met"},{"location":"Ops/Shell/Shell/#convert-windows-encoded-text-file-to-unix-encoded","text":"awk 'BEGIN{RS= ^$ ;ORS= ;getline;gsub( \\r , );print ARGV[1]}' file_name","title":"Convert windows-encoded text file to unix-encoded"},{"location":"Ops/Shell/Shell/#loop-through-defined-array","text":"array=( one two three ) for i in ${array[@]} do echo $i done","title":"Loop through defined array"},{"location":"Ops/Shell/Shell/#read-lines-from-file-in-a-for-loop","text":"input= /path/to/txt/file while IFS= read -r var do echo $var done $input or while read variable_name; do echo JDSA $variable_name ; done workers.txt","title":"Read lines from file in a for loop"},{"location":"Ops/Shell/Shell/#display-info-about-memory","text":"$ sudo lshw -C memory","title":"Display info about memory"},{"location":"Ops/Shell/Shell/#open-the-current-repo-on-a-specific-web-repo","text":"my_hgweb() { if [ -d .hg ]; then xdg-open http://web-repo-address/hg/${PWD##*/} /dev/null else echo Not mercurial directory fi } alias hgweb=my_hgweb","title":"Open the current repo on a specific web repo"},{"location":"Ops/Shell/Shell/#colors","text":"","title":"Colors"},{"location":"Ops/Shell/Shell/#with-tput","text":"","title":"With tput"},{"location":"Ops/Shell/Shell/#colors_1","text":"0 \u2013 Black. 1 \u2013 Red. 2 \u2013 Green. 3 \u2013 Yellow. 4 \u2013 Blue. 5 \u2013 Magenta. 6 \u2013 Cyan. 7 \u2013 White. Clear all options tput setab clear tput sgr0 Set foreground color tput setaf 6; # turquoise Set background color tput setab 2; # green Set bold tput bold; More info: http://linuxcommand.org/lc3_adv_tput.php Show all color combinations https://gist.github.com/patsancu/44fcdb7d7d195add5bc87e4aa5df88c6","title":"Colors"},{"location":"Ops/Shell/Shell/#useful-snippets","text":"","title":"Useful snippets"},{"location":"Ops/Shell/Shell/#file-management","text":"","title":"File management"},{"location":"Ops/Shell/Shell/#rename-files-in-folder-to-sorted-files","text":"c=0; for i in `ls`;do echo $i ; c=$((c+1)); mv $i $c.txt ; done","title":"Rename files in folder to sorted files"},{"location":"Ops/Shell/Shell/#rename-files-change-extesion","text":"for file in *.html do mv $file ${file%.html}.txt done","title":"Rename files, change extesion"},{"location":"Ops/Shell/Shell/#get-extension-of-file","text":"filename=$(basename $fullfile ) extension= ${filename##*.} filename= ${filename%.*}","title":"Get extension of file"},{"location":"Ops/Shell/Shell/#change-mac-address","text":"sudo ifconfig eth0 down sudo ifconfig eth0 hw ether xx:xx:xx:xx:xx:xx sudo ifconfig eth0 up","title":"Change mac address"},{"location":"Ops/Shell/Shell/#date","text":"","title":"Date"},{"location":"Ops/Shell/Shell/#format-current-date","text":"$ date +'%Y%m%d'","title":"Format current date"},{"location":"Ops/Shell/Shell/#add-days-to-date","text":"date -d + 2 days date -d + 3 minutes date -d + 4 months","title":"Add days to date"},{"location":"Ops/Shell/Shell/#from-epoch-seconds-to-date","text":"$ date -d @1463234960 samedi 14 mai 2016, 16:09:20 (UTC+0200)","title":"From epoch seconds to date"},{"location":"Ops/Shell/Shell/#combine","text":"$ date -d @1463234960 + %Y-%m-%d 2016-05-14 $ date -d 1492/10/12 14:00:02 + %Y-%m-%d %H:%M 1492-10-12 14:00 For more info about date input formats","title":"Combine"},{"location":"Ops/Shell/Shell/#useful-commands","text":"pv show progress of command dd bs=4M if=/media/somedrive/raspbian-jessie.img | pv | dd of=/dev/mmcblk0 pgrep get PID by name pkill kill process by name timeout n command execute command for n seconds","title":"Useful commands"},{"location":"Ops/Shell/Shell/#see-calendar-for-previous-month-next-month-and-three-months-from-now","text":"$ ncal -3 -A 2","title":"See calendar for previous month, next month, and three months from now"},{"location":"Ops/Shell/Shell/#encodedecode-base64-data","text":"$ echo patata | base64 cGF0YXRhCg== $ echo patata | base64 | base64 -d","title":"Encode/decode base64 data"},{"location":"Ops/Shell/Shell/#exit-traps","text":"Reference Example: #!/bin/bash scratch=$(mktemp -d -t tmp.XXXXXXXXXX) function finish { rm -rf $scratch } trap finish EXIT","title":"Exit traps"},{"location":"Ops/Shell/Shell/#check-os-type","text":"if [[ $OSTYPE == linux-gnu ]]; then # ... elif [[ $OSTYPE == darwin * ]]; then # Mac OSX elif [[ $OSTYPE == cygwin ]]; then # POSIX compatibility layer and Linux environment emulation for Windows elif [[ $OSTYPE == msys ]]; then # Lightweight shell and GNU utilities compiled for Windows (part of MinGW) elif [[ $OSTYPE == win32 ]]; then # I'm not sure this can happen. elif [[ $OSTYPE == freebsd * ]]; then # ... else #","title":"Check OS type"},{"location":"Ops/Shell/Shell/#flatten-directory","text":"Moves recursively all files under folder \"dir1\" (at any level of depth) to the \"dir1\" folder. find dir1 -type f -exec mv {} dir1 \\;","title":"Flatten directory"},{"location":"Ops/Shell/Shell/#declare-variables-for-a-command","text":"","title":"Declare variables for a command"},{"location":"Ops/Shell/Shell/#yes","text":"FOO=bar bash -c 'echo $FOO'","title":"Yes"},{"location":"Ops/Shell/Shell/#no","text":"FOO=bar bash -c echo $FOO","title":"No"},{"location":"Ops/Shell/Shell/#get-duplicate-lines-and-count","text":"prints duplicate lines only cat some_file.csv | uniq -cd","title":"Get duplicate lines and count"},{"location":"Ops/Shell/Shell/#geotag-pictures","text":"#!/bin/bash lat=$(curl http://nominatim.openstreetmap.org/search? city=$1 country=$2 format=json | jq '.[0] | .lat' | tr \u00add ' ') lon=$(curl http://nominatim.openstreetmap.org/search? city=$1 country=$2 format=json | jq '.[0] | .lon' | tr \u00add ' ') exiftool \u00adGPSLongitude=$lon \u00adGPSLatitude=$lat \u00adext jpg .","title":"Geotag pictures"},{"location":"Ops/Shell/Shell/#prettify-json","text":"curl -s localhost:7080/mappings | python -mjson.tool","title":"Prettify json"},{"location":"Ops/Shell/Shell/#print-undefined-progress-spinner","text":"declare spin function with: sp= /-\\| sc=0 spin() { printf \\b${sp:sc++:1} ((sc==${#sp})) sc=0 } Then, use it in a loop, for example: SECONDS=40 PERIOD_LENGTH=100 FREQUENCY=$(bc $PERIOD_LENGTH*$SECONDS ) COUNTER=$((SECONDS * $PERIOD_LENGTH)) while [ $COUNTER -gt 0 ] do COUNTER=$[$COUNTER-1] sleep 0.01; spin done","title":"Print undefined progress spinner"},{"location":"Ops/Shell/Shell/#grep-highligh-matched-patterns-but-not-otherwise-change-ouput","text":"grep --color=always -e ^ -e hello testfile","title":"Grep: highligh matched patterns but not otherwise change ouput"},{"location":"Ops/Shell/Shell/#random-numbers","text":"","title":"Random numbers"},{"location":"Ops/Shell/Shell/#zsh-or-bash","text":"random between 0-999 echo $[${RANDOM}%1000] random between 10-20 $[${RANDOM}%11+10] random number that's N digits long ${(l:3::0:)${RANDOM}}","title":"zsh or bash"},{"location":"Software/Alluxio/","text":"Refresh cache root@alluxio-master-0:/opt/alluxio# alluxio fs ls -Rf /raw Remount folder root@alluxio-master-0:/opt/alluxio# alluxio fs unmount /sushi Unmounted /sushi root@alluxio-master-0:/opt/alluxio# alluxio fs mount /sushi s3a://path-to-mount","title":"Alluxio"},{"location":"Software/Alluxio/#refresh-cache","text":"root@alluxio-master-0:/opt/alluxio# alluxio fs ls -Rf /raw","title":"Refresh cache"},{"location":"Software/Alluxio/#remount-folder","text":"root@alluxio-master-0:/opt/alluxio# alluxio fs unmount /sushi Unmounted /sushi root@alluxio-master-0:/opt/alluxio# alluxio fs mount /sushi s3a://path-to-mount","title":"Remount folder"},{"location":"Software/Apache-Drill/","text":"Before googling, check errors https://drill.apache.org/docs/troubleshooting/ https://drill.apache.org/docs/alter-system/ Change store format use dfs.tmp; alter session set store.`format`='json'; After that, CREATE TABLE movieRegions (region, title, purchases) as SELECT region, title, count(*) as numberOfPurchases FROM dfs.`/home/user/data/some/path/some_file.json` group by region, title; will create table on /tmp/movieRegions/SOME_NUMBERS.json query custom *sv file (fields delimited by another character) select * from table(dfs.`/path/to/file/some_data.xsv` (type = 'text', fieldDelimiter = '~', extractHeader = true)); Query file given absolute path select * from dfs. /home/patrick/dev/tvmetrix/extractor/data/liveevents/2018-01-18/liveevents_DF_2018-01-18_153010_469.json.gz limit 20; Query the system Identify the Foreman Issue the following query to identify the Foreman node: SELECT hostname FROM sys.drillbits WHERE `current` = true Get drill version SELECT version FROM sys.version; Get a complete list of planning and execution options that are currently set at the system or session level SELECT name, type FROM sys.options WHERE type in ('SYSTEM','SESSION') order by name; Change system settings alter system set planner.enable_hashagg = true; alter system set planner.enable_multiphase_agg = false; Change port of web UI $ vim conf/drill-override.conf drill.exec: { cluster-id: drillbits1 rpc: { user: { server: { port: 31910 } }, bit: { server: { port : 31911, retry:{ count: 7200, delay: 500 }, threads: 1 } }, }, http: { enabled: true, ssl_enabled: false, port: 8989 session_max_idle_secs: 3600, # Default value 1hr cors: { enabled: false, allowedOrigins: [ null ], allowedMethods: [ GET , POST , HEAD , OPTIONS ], allowedHeaders: [ X-Requested-With , Content-Type , Accept , Origin ], credentials: true } }, } drill.logical.function.package+=[com.mapr.drill] Change log level Edit /conf/logback.xml","title":"Apache Drill"},{"location":"Software/Apache-Drill/#change-store-format","text":"use dfs.tmp; alter session set store.`format`='json'; After that, CREATE TABLE movieRegions (region, title, purchases) as SELECT region, title, count(*) as numberOfPurchases FROM dfs.`/home/user/data/some/path/some_file.json` group by region, title; will create table on /tmp/movieRegions/SOME_NUMBERS.json","title":"Change store format"},{"location":"Software/Apache-Drill/#query-custom-sv-file-fields-delimited-by-another-character","text":"select * from table(dfs.`/path/to/file/some_data.xsv` (type = 'text', fieldDelimiter = '~', extractHeader = true));","title":"query custom *sv file (fields delimited by another character)"},{"location":"Software/Apache-Drill/#query-file-given-absolute-path","text":"select * from dfs. /home/patrick/dev/tvmetrix/extractor/data/liveevents/2018-01-18/liveevents_DF_2018-01-18_153010_469.json.gz limit 20;","title":"Query file given absolute path"},{"location":"Software/Apache-Drill/#query-the-system","text":"","title":"Query the system"},{"location":"Software/Apache-Drill/#identify-the-foreman","text":"Issue the following query to identify the Foreman node: SELECT hostname FROM sys.drillbits WHERE `current` = true","title":"Identify the Foreman"},{"location":"Software/Apache-Drill/#get-drill-version","text":"SELECT version FROM sys.version;","title":"Get drill version"},{"location":"Software/Apache-Drill/#get-a-complete-list-of-planning-and-execution-options-that-are-currently-set-at-the-system-or-session-level","text":"SELECT name, type FROM sys.options WHERE type in ('SYSTEM','SESSION') order by name;","title":"Get a complete list of planning and execution options that are currently set at the system or session level"},{"location":"Software/Apache-Drill/#change-system-settings","text":"alter system set planner.enable_hashagg = true; alter system set planner.enable_multiphase_agg = false;","title":"Change system settings"},{"location":"Software/Apache-Drill/#change-port-of-web-ui","text":"$ vim conf/drill-override.conf drill.exec: { cluster-id: drillbits1 rpc: { user: { server: { port: 31910 } }, bit: { server: { port : 31911, retry:{ count: 7200, delay: 500 }, threads: 1 } }, }, http: { enabled: true, ssl_enabled: false, port: 8989 session_max_idle_secs: 3600, # Default value 1hr cors: { enabled: false, allowedOrigins: [ null ], allowedMethods: [ GET , POST , HEAD , OPTIONS ], allowedHeaders: [ X-Requested-With , Content-Type , Accept , Origin ], credentials: true } }, } drill.logical.function.package+=[com.mapr.drill]","title":"Change port of web UI"},{"location":"Software/Apache-Drill/#change-log-level","text":"Edit /conf/logback.xml","title":"Change log level"},{"location":"Software/Atom/","text":"Atom Change background colour of selected text atom-text-editor::shadow .selection .region { background-color: LightGoldenRodYellow; }","title":"Atom"},{"location":"Software/Atom/#atom","text":"Change background colour of selected text atom-text-editor::shadow .selection .region { background-color: LightGoldenRodYellow; }","title":"Atom"},{"location":"Software/Guake-Terminal-\u2013-Dual-Monitor-Edits/","text":"Guake always defaults to the left monitor. It does a great job of determining the size of \u2018monitor 1\u2032. To get Guake on my right-side monitor I had to tweak the source code. Here\u2019s how you can do the same: Make a copy of theGuake program and put it in yourbin folder. I renamed mine toguake-dualmon but you can call it whatever you want. cp /usr/bin/guake ~/bin/guake-dualmon vim ~/bin/guake-dualmon Find the method definition def get_final_window_rect(self): First we will correctly position the terminal on the right monitor. Add one line at the end, between window_rect.y = 0 and return window_rect . The window_rect.x and window_rect.y variables tell the Guake window where to be located. Set window_rect.x to be the width of your left monitor and window_rect.y will depend on how offset the monitors are. I had to play with the \u2018y\u2019 setting to get it just right or the text starts off the top of the screen. window_rect.x = 1280 window_rect.y = 24 Now Guake will be positioned on your right monitor, but it will still be the size of the left one. In my case it was sized at 1280, and I needed it to be 1920. Divide your right monitor\u2019s width by the left monitor\u2019s width (ie. 1920/1280 = 150). Still within get_final_window_rect(self): you will find the line width = 100 . This setting is a percentage of your left monitor, so set it to the answer you got by dividing one width into the other. In my case it was: width = 150 That\u2019s it! Just make sure to always run your copy of the program, or better yet add it to your autostart so it runs automatically!","title":"Guake Terminal \u2013 Dual Monitor Edits"},{"location":"Software/Latex/","text":"Latex Force new line \\newline or \\\\","title":"Latex"},{"location":"Software/Latex/#latex","text":"","title":"Latex"},{"location":"Software/Latex/#force-new-line","text":"\\newline or \\\\","title":"Force new line"},{"location":"Software/Multimedia/","text":"Extract audio from video mplayer -dumpaudio -dumpfile clip_track.mp3 clip.avi or avconv -i /input-file-name-with-path output-filename.mp3 Merge pdfs into one pdftk space separated pdf files cat output CanterburyTales.pdf","title":"Multimedia"},{"location":"Software/Multimedia/#extract-audio-from-video","text":"mplayer -dumpaudio -dumpfile clip_track.mp3 clip.avi or avconv -i /input-file-name-with-path output-filename.mp3","title":"Extract audio from video"},{"location":"Software/Multimedia/#merge-pdfs-into-one","text":"pdftk space separated pdf files cat output CanterburyTales.pdf","title":"Merge pdfs into one"},{"location":"Software/Skype/","text":"Skype Skype Web Format text A * surrounding text (a) bolds . A _ surrounding text (a) italics . A ~ surrounding text (~a~) ~~strikethroughs~~ . If you start a message with \"@@ \" (two ats with a space), every formatting function in your message will be ignored except emoticons. If you start a message with \"!! \" (two exclamations with a space), every formatting function in your message will be ignored and font will be switched to monospaced. Skype Desktop Skype complains about another session in the computer but there are none rm -rf ~/.Skype","title":"Skype"},{"location":"Software/Skype/#skype","text":"","title":"Skype"},{"location":"Software/Skype/#skype-web","text":"","title":"Skype Web"},{"location":"Software/Skype/#format-text","text":"A * surrounding text (a) bolds . A _ surrounding text (a) italics . A ~ surrounding text (~a~) ~~strikethroughs~~ . If you start a message with \"@@ \" (two ats with a space), every formatting function in your message will be ignored except emoticons. If you start a message with \"!! \" (two exclamations with a space), every formatting function in your message will be ignored and font will be switched to monospaced.","title":"Format text"},{"location":"Software/Skype/#skype-desktop","text":"","title":"Skype Desktop"},{"location":"Software/Skype/#skype-complains-about-another-session-in-the-computer-but-there-are-none","text":"rm -rf ~/.Skype","title":"Skype complains about another session in the computer but there are none"},{"location":"Software/Tableau/","text":"Multiple data sources without joining or blending Create a new Worksheet. Using the top menu bar, select Data New Data Source. (This can also be done with Ctrl+D) Show measure on title, let everything else be empty Double click on the sheet title, to edit it Create calculated field with str(value to add) e.g. str(avg(some_measure)) + \" minutes\" Click Insert and specify value to insert Click on the graph and select Hide","title":"Tableau"},{"location":"Software/Tableau/#multiple-data-sources-without-joining-or-blending","text":"Create a new Worksheet. Using the top menu bar, select Data New Data Source. (This can also be done with Ctrl+D)","title":"Multiple data sources without joining or blending"},{"location":"Software/Tableau/#show-measure-on-title-let-everything-else-be-empty","text":"Double click on the sheet title, to edit it Create calculated field with str(value to add) e.g. str(avg(some_measure)) + \" minutes\" Click Insert and specify value to insert Click on the graph and select Hide","title":"Show measure on title, let everything else be empty"},{"location":"Software/Useful-software/","text":"Dev Json lint jsonlint-py sudo apt-get install python-demjson Java jdk sudo apt-add-repository ppa:webupd8team/java sudo apt-get update sudo apt-get install oracle-java8-installer or sudo apt-get install oracle-java7-installer SOAP UI SDK man curl -s get.sdkman.io | bash STS - Spring Tool Suite CLI software Newsbeuter rss client Mutt email client. Config info DB Squirrel Steps to add Oracle Driver Open Driver list from left menu, scroll down till you find \"Oracle Thin Driver\", you will notice red x mark next to it denoting the driver is still not configured. After selecting \"Oracle Thin Driver\" click \"Modify the Selected Driver\" denoted by pencil. Click \"Extra Class Path\" tab. Click \"Add\" and select 1 jar file from %Oracle_DB_CLIENT_INSTALL%\\jdbc\\lib\\ojdbc6_g.jar Click Ok, and we are done defining the driver. Now create an alias for the DB using previous driver and providing URL, username, password. Note: No need to have Oracle client for setup, all you need is just the driver jar files. You can download from this Oracle link. If you are using JDK 5 while running Squirrel SQL, the jar file will be %Oracle_DB_CLIENT_INSTALL%\\jdbc\\lib\\ojdbc5_g.jar Thin url would be something like (local db): jdbc:oracle:thin:@localhost:1521:xe Oracle Database 11g Express Edition SQL developer DBeaver Soporte para Oracle, MySQL, PostgreSQL,... y Drill Communications Franz Integrate several messaging apps (skype, hangouts, slack,...). Capable of managing several accounts of the same app Hangouts Skype Skype alpha Slack Remote Gnome connection manager Change /home/patrick/.gcm/gcm.conf - Change log-path option - Change console_close = CTRL+W (e.g. console_close = CTRL + M) Cloud Cross FTP FTP and S3 browser DragonDisk S3 browser Can get shareable URL via Right Click - Properties - Security Tab - Add (All users) - Check Download and Read permissions boxes Tex Install packages Download package (e.g. classicthesis ) and extract the sty file it to a folder named as the package under ~/texmf/tex/latex/packagename (e.g. /home/user/texmf/tex/latex/classicthesis ) Misc sudo apt-get install nautilus-actions gnome-paint","title":"Useful software"},{"location":"Software/Useful-software/#dev","text":"","title":"Dev"},{"location":"Software/Useful-software/#json-lint","text":"jsonlint-py sudo apt-get install python-demjson","title":"Json lint"},{"location":"Software/Useful-software/#java","text":"","title":"Java"},{"location":"Software/Useful-software/#jdk","text":"sudo apt-add-repository ppa:webupd8team/java sudo apt-get update sudo apt-get install oracle-java8-installer or sudo apt-get install oracle-java7-installer","title":"jdk"},{"location":"Software/Useful-software/#soap-ui","text":"","title":"SOAP UI"},{"location":"Software/Useful-software/#sdk-man","text":"curl -s get.sdkman.io | bash","title":"SDK man"},{"location":"Software/Useful-software/#sts-spring-tool-suite","text":"","title":"STS - Spring Tool Suite"},{"location":"Software/Useful-software/#cli-software","text":"","title":"CLI software"},{"location":"Software/Useful-software/#newsbeuter","text":"rss client","title":"Newsbeuter"},{"location":"Software/Useful-software/#mutt","text":"email client. Config info","title":"Mutt"},{"location":"Software/Useful-software/#db","text":"","title":"DB"},{"location":"Software/Useful-software/#squirrel","text":"Steps to add Oracle Driver Open Driver list from left menu, scroll down till you find \"Oracle Thin Driver\", you will notice red x mark next to it denoting the driver is still not configured. After selecting \"Oracle Thin Driver\" click \"Modify the Selected Driver\" denoted by pencil. Click \"Extra Class Path\" tab. Click \"Add\" and select 1 jar file from %Oracle_DB_CLIENT_INSTALL%\\jdbc\\lib\\ojdbc6_g.jar Click Ok, and we are done defining the driver. Now create an alias for the DB using previous driver and providing URL, username, password. Note: No need to have Oracle client for setup, all you need is just the driver jar files. You can download from this Oracle link. If you are using JDK 5 while running Squirrel SQL, the jar file will be %Oracle_DB_CLIENT_INSTALL%\\jdbc\\lib\\ojdbc5_g.jar Thin url would be something like (local db): jdbc:oracle:thin:@localhost:1521:xe","title":"Squirrel"},{"location":"Software/Useful-software/#oracle-database-11g-express-edition","text":"","title":"Oracle Database 11g Express Edition"},{"location":"Software/Useful-software/#sql-developer","text":"","title":"SQL developer"},{"location":"Software/Useful-software/#dbeaver","text":"Soporte para Oracle, MySQL, PostgreSQL,... y Drill","title":"DBeaver"},{"location":"Software/Useful-software/#communications","text":"","title":"Communications"},{"location":"Software/Useful-software/#franz","text":"Integrate several messaging apps (skype, hangouts, slack,...). Capable of managing several accounts of the same app","title":"Franz"},{"location":"Software/Useful-software/#hangouts","text":"","title":"Hangouts"},{"location":"Software/Useful-software/#skype","text":"","title":"Skype"},{"location":"Software/Useful-software/#skype-alpha","text":"","title":"Skype alpha"},{"location":"Software/Useful-software/#slack","text":"","title":"Slack"},{"location":"Software/Useful-software/#remote","text":"","title":"Remote"},{"location":"Software/Useful-software/#gnome-connection-manager","text":"Change /home/patrick/.gcm/gcm.conf - Change log-path option - Change console_close = CTRL+W (e.g. console_close = CTRL + M)","title":"Gnome connection manager"},{"location":"Software/Useful-software/#cloud","text":"","title":"Cloud"},{"location":"Software/Useful-software/#cross-ftp","text":"FTP and S3 browser","title":"Cross FTP"},{"location":"Software/Useful-software/#dragondisk","text":"S3 browser Can get shareable URL via Right Click - Properties - Security Tab - Add (All users) - Check Download and Read permissions boxes","title":"DragonDisk"},{"location":"Software/Useful-software/#tex","text":"","title":"Tex"},{"location":"Software/Useful-software/#install-packages","text":"Download package (e.g. classicthesis ) and extract the sty file it to a folder named as the package under ~/texmf/tex/latex/packagename (e.g. /home/user/texmf/tex/latex/classicthesis )","title":"Install packages"},{"location":"Software/Useful-software/#misc","text":"sudo apt-get install nautilus-actions gnome-paint","title":"Misc"},{"location":"Software/Vim/","text":"Vimrc Vimrc omorante or this Modularize vimrc Regex Is replaced with the entire text matched by the search pattern when used in a replacement string. This is useful when you want to avoid retyping text: :%s/Yazstremski/ , Carl/ The replacement will say Yazstremski, Carl. The can also replace a variable pattern (as specified by a regular expression). For example, to surround each line from 1 to 10 with parentheses, type: :1,10s/.*/( )/ from Learning the vi and Vim Editors, Seventh Edition by Arnold Robbins, Elbert Hannah, and Linda Lamb . Insert a space between # and the character that follows it :%s/#\\(\\w\\)/# \\1/g general . any character except new line \\s whitespace character \\S non-whitespace character \\d digit \\D non-digit \\x hex digit \\X non-hex digit \\o octal digit \\O non-octal digit \\h head of word character (a,b,c...z,A,B,C...Z and _) \\H non-head of word character \\p printable character \\P like \\p, but excluding digits \\w word character \\W non-word character \\a alphabetic character \\A non-alphabetic character \\l lowercase character \\L non-lowercase character \\u uppercase character \\U non-uppercase character Quickfix C-w Enter Open file from list Vim cool fonts Linux $ mkdir -p ~/.local/share/fonts $ cd ~/.local/share/fonts curl -fLo Droid Sans Mono for Powerline Nerd Font Complete.otf https://raw.githubusercontent.com/ryanoasis/nerd-fonts/master/patched-fonts/DroidSansMono/complete/Droid%20Sans%20Mono%20for%20Powerline%20Nerd%20Font%20Complete.otf In vimrc, set set guifont=Droid\\ Sans\\ Mono\\ for\\ Powerline\\ Plus\\ Nerd\\ File\\ Types\\ 11 MacOS cd ~/Library/Fonts curl -fLo Droid Sans Mono for Powerline Nerd Font Complete.otf https://raw.githubusercontent.com/ryanoasis/nerd-fonts/master/patched-fonts/DroidSansMono/complete/Droid%20Sans%20Mono%20for%20Powerline%20Nerd%20Font%20Complete.otf In .vimrc, set guifont=Droid\\ Sans\\ Mono\\ for\\ Powerline\\ Plus\\ Nerd\\ File\\ Types:h11 Install vim-devicons plugin , after NERDTree and others Restart terminal Change font in terminal Make vim automatically read file as some filetype Insert this line in the file # vim: set filetype=sh Misc :echo expand('%:p') print filename with full path Vim diff turn on :windo diffthis turn off :windo diffoff move between changes [c jump back ]c and forward Movements gg Go to beginning of file G Go to end of file Windows et al ^w Change subwindow :q Command history Search and replace +?| must be escaped for special function \\r is new line (for replacing) normal mode /wordtosearch + Enter Search for word /\\cwortosearch + Enter Case insensitive search for word :%s/foo/bar/gci Replaces all ocurrences (g) in all the text (%) of the word foo by the word bar , ignoring cases (i) and asking confirmation (c) for each replacement :%s/patata//gn counts ocurrences of patata in all the text Buffers :ls :b 2 go to buffer# 2 :vsp filename vertical split :sp filename horizontal split :bnext mapped to (Ctrl + \u2192 ) next buffer :bprev mapped to (Ctrl + \u2190 ) previous buffer :sb vertically split buffer on current file External commands and writing (vimtutor# 5) :!command executes an external command. :w FILENAME writes the current Vim file to disk with name FILENAME. v motion :w FILENAME saves the Visually selected lines in file FILENAME. :r FILENAME retrieves disk file FILENAME and puts it below the cursor position. :r !dir reads the output of the dir command and puts it below the cursor position. Editing Normal mode :m .+1 Move line down :m .-2 Move line up `cw change word (deletes word and switches to insert mode) ci\" change insde \" (also, ([{, etc) 55,60d deleted lines 55-60 (can be applied to other actions) gg=G format all file # ngg go to line number # n :set list show whitespaces u undo U undo changes on line CTRL + R redo A goes to end of line and enters insert mode * goes to next appearance of the word pointed by the cursor zb goes to bottom of screen zz goes to middle of screen zt goes to top of screen Screen moving ^f move one screen forward ^b move one screen backwards Insert mode ctrl+Space (was Ctrl+N ) Autocomplete Visual Mode v visual mode V visual line mode CTRL + v visual block mode Add text to multiple lines (at the same cursor position: column) Enter visual block mode Select lines Type I (capital i) Write text Press Escape Plugins Ultisnips From here . Configure custom snippets folder like this: let g:UltiSnipsSnippetDirectories=[ ~/.vim/custom_snippets ] As noted in the docs, do NOT map tab to trigger: let g:UltiSnipsExpandTrigger= c-e Check Python interpolation NERDTree RTFM or Read this: From within NERDTree Window m bring up the NERDTree Filesystem Menu a create new file t open in tab i open in h split s open in v split O expand selected folder recursively_ I show/hide hidden files C change root to highlighted folder Block move by patterns From Learning the vi and vim editors Given the file with contents: Rh 0 Get status of named file STAT .Rh SYNTAX .nf integer*4 stat, retval integer*4 status(11) character*123 filename ... retval = stat (filename, status) .fi .Rh DESCRIPTION Writes the fields of a system data structure into the status array. These fields contain (among other things) information about the file's location, access privileges, owner, and time of last modification. .Rh PARAMETERS .IP \\fBfilename\\fR 15n A character string variable or constant containing the Unix pathname for the file whose status you want to retrieve. You can give the ... Suppose that you decide to move DESCRIPTION above the SYNTAX paragraph. With pattern matching, you can move blocks of text on all 150 pages with one command! :g /SYNTAX/.,/DESCRIPTION/-1 move /PARAMETERS/-1 This command works as follows. First, ex finds and marks each line that matches the first pattern (i.e., that contains the word SYNTAX). Second, for each marked line, it sets . (dot, the current line) to that line, and executes the command. Using the move command, the command moves the block of lines from the current line (dot) to the line before the one containing the word DESCRIPTION (/DESCRIPTION/-1) to just before the line containing PARAMETERS (/PARAMETERS/-1). Snippets Reverse lines All :g/^/m0 Range (reverse only lines 100-150) :100,150g/^/m99","title":"Vim"},{"location":"Software/Vim/#vimrc","text":"Vimrc omorante or this Modularize vimrc","title":"Vimrc"},{"location":"Software/Vim/#regex","text":"","title":"Regex"},{"location":"Software/Vim/#_1","text":"Is replaced with the entire text matched by the search pattern when used in a replacement string. This is useful when you want to avoid retyping text: :%s/Yazstremski/ , Carl/ The replacement will say Yazstremski, Carl. The can also replace a variable pattern (as specified by a regular expression). For example, to surround each line from 1 to 10 with parentheses, type: :1,10s/.*/( )/ from Learning the vi and Vim Editors, Seventh Edition by Arnold Robbins, Elbert Hannah, and Linda Lamb .","title":"&amp;"},{"location":"Software/Vim/#insert-a-space-between-and-the-character-that-follows-it","text":":%s/#\\(\\w\\)/# \\1/g","title":"Insert a space between # and the character that follows it"},{"location":"Software/Vim/#general","text":". any character except new line \\s whitespace character \\S non-whitespace character \\d digit \\D non-digit \\x hex digit \\X non-hex digit \\o octal digit \\O non-octal digit \\h head of word character (a,b,c...z,A,B,C...Z and _) \\H non-head of word character \\p printable character \\P like \\p, but excluding digits \\w word character \\W non-word character \\a alphabetic character \\A non-alphabetic character \\l lowercase character \\L non-lowercase character \\u uppercase character \\U non-uppercase character","title":"general"},{"location":"Software/Vim/#quickfix","text":"C-w Enter Open file from list","title":"Quickfix"},{"location":"Software/Vim/#vim-cool-fonts","text":"Linux $ mkdir -p ~/.local/share/fonts $ cd ~/.local/share/fonts curl -fLo Droid Sans Mono for Powerline Nerd Font Complete.otf https://raw.githubusercontent.com/ryanoasis/nerd-fonts/master/patched-fonts/DroidSansMono/complete/Droid%20Sans%20Mono%20for%20Powerline%20Nerd%20Font%20Complete.otf In vimrc, set set guifont=Droid\\ Sans\\ Mono\\ for\\ Powerline\\ Plus\\ Nerd\\ File\\ Types\\ 11 MacOS cd ~/Library/Fonts curl -fLo Droid Sans Mono for Powerline Nerd Font Complete.otf https://raw.githubusercontent.com/ryanoasis/nerd-fonts/master/patched-fonts/DroidSansMono/complete/Droid%20Sans%20Mono%20for%20Powerline%20Nerd%20Font%20Complete.otf In .vimrc, set guifont=Droid\\ Sans\\ Mono\\ for\\ Powerline\\ Plus\\ Nerd\\ File\\ Types:h11 Install vim-devicons plugin , after NERDTree and others Restart terminal Change font in terminal","title":"Vim cool fonts"},{"location":"Software/Vim/#make-vim-automatically-read-file-as-some-filetype","text":"Insert this line in the file # vim: set filetype=sh","title":"Make vim automatically read file as some filetype"},{"location":"Software/Vim/#misc","text":":echo expand('%:p') print filename with full path","title":"Misc"},{"location":"Software/Vim/#vim-diff","text":"","title":"Vim diff"},{"location":"Software/Vim/#turn-on","text":":windo diffthis","title":"turn on"},{"location":"Software/Vim/#turn-off","text":":windo diffoff","title":"turn off"},{"location":"Software/Vim/#move-between-changes","text":"[c jump back ]c and forward","title":"move between changes"},{"location":"Software/Vim/#movements","text":"gg Go to beginning of file G Go to end of file","title":"Movements"},{"location":"Software/Vim/#windows-et-al","text":"^w Change subwindow :q Command history","title":"Windows et al"},{"location":"Software/Vim/#search-and-replace","text":"+?| must be escaped for special function \\r is new line (for replacing)","title":"Search and replace"},{"location":"Software/Vim/#normal-mode","text":"/wordtosearch + Enter Search for word /\\cwortosearch + Enter Case insensitive search for word :%s/foo/bar/gci Replaces all ocurrences (g) in all the text (%) of the word foo by the word bar , ignoring cases (i) and asking confirmation (c) for each replacement :%s/patata//gn counts ocurrences of patata in all the text","title":"normal mode"},{"location":"Software/Vim/#buffers","text":":ls :b 2 go to buffer# 2 :vsp filename vertical split :sp filename horizontal split :bnext mapped to (Ctrl + \u2192 ) next buffer :bprev mapped to (Ctrl + \u2190 ) previous buffer :sb vertically split buffer on current file","title":"Buffers"},{"location":"Software/Vim/#external-commands-and-writing-vimtutor-5","text":":!command executes an external command. :w FILENAME writes the current Vim file to disk with name FILENAME. v motion :w FILENAME saves the Visually selected lines in file FILENAME. :r FILENAME retrieves disk file FILENAME and puts it below the cursor position. :r !dir reads the output of the dir command and puts it below the cursor position.","title":"External commands and writing (vimtutor# 5)"},{"location":"Software/Vim/#editing","text":"","title":"Editing"},{"location":"Software/Vim/#normal-mode_1","text":":m .+1 Move line down :m .-2 Move line up `cw change word (deletes word and switches to insert mode) ci\" change insde \" (also, ([{, etc) 55,60d deleted lines 55-60 (can be applied to other actions) gg=G format all file # ngg go to line number # n :set list show whitespaces u undo U undo changes on line CTRL + R redo A goes to end of line and enters insert mode * goes to next appearance of the word pointed by the cursor zb goes to bottom of screen zz goes to middle of screen zt goes to top of screen","title":"Normal mode"},{"location":"Software/Vim/#screen-moving","text":"^f move one screen forward ^b move one screen backwards","title":"Screen moving"},{"location":"Software/Vim/#insert-mode","text":"ctrl+Space (was Ctrl+N ) Autocomplete","title":"Insert mode"},{"location":"Software/Vim/#visual-mode","text":"v visual mode V visual line mode CTRL + v visual block mode","title":"Visual Mode"},{"location":"Software/Vim/#add-text-to-multiple-lines-at-the-same-cursor-position-column","text":"Enter visual block mode Select lines Type I (capital i) Write text Press Escape","title":"Add text to multiple lines (at the same cursor position: column)"},{"location":"Software/Vim/#plugins","text":"","title":"Plugins"},{"location":"Software/Vim/#ultisnips","text":"From here . Configure custom snippets folder like this: let g:UltiSnipsSnippetDirectories=[ ~/.vim/custom_snippets ] As noted in the docs, do NOT map tab to trigger: let g:UltiSnipsExpandTrigger= c-e Check Python interpolation","title":"Ultisnips"},{"location":"Software/Vim/#nerdtree","text":"RTFM or Read this: From within NERDTree Window m bring up the NERDTree Filesystem Menu a create new file t open in tab i open in h split s open in v split O expand selected folder recursively_ I show/hide hidden files C change root to highlighted folder","title":"NERDTree"},{"location":"Software/Vim/#block-move-by-patterns","text":"From Learning the vi and vim editors Given the file with contents: Rh 0 Get status of named file STAT .Rh SYNTAX .nf integer*4 stat, retval integer*4 status(11) character*123 filename ... retval = stat (filename, status) .fi .Rh DESCRIPTION Writes the fields of a system data structure into the status array. These fields contain (among other things) information about the file's location, access privileges, owner, and time of last modification. .Rh PARAMETERS .IP \\fBfilename\\fR 15n A character string variable or constant containing the Unix pathname for the file whose status you want to retrieve. You can give the ... Suppose that you decide to move DESCRIPTION above the SYNTAX paragraph. With pattern matching, you can move blocks of text on all 150 pages with one command! :g /SYNTAX/.,/DESCRIPTION/-1 move /PARAMETERS/-1 This command works as follows. First, ex finds and marks each line that matches the first pattern (i.e., that contains the word SYNTAX). Second, for each marked line, it sets . (dot, the current line) to that line, and executes the command. Using the move command, the command moves the block of lines from the current line (dot) to the line before the one containing the word DESCRIPTION (/DESCRIPTION/-1) to just before the line containing PARAMETERS (/PARAMETERS/-1).","title":"Block move by patterns"},{"location":"Software/Vim/#snippets","text":"","title":"Snippets"},{"location":"Software/Vim/#reverse-lines","text":"All :g/^/m0 Range (reverse only lines 100-150) :100,150g/^/m99","title":"Reverse lines"},{"location":"Software/VirtualBox/","text":"Install VBox additions! Start headless machine CLI VBoxManage startvm ubuservloc --type headless Get ip(v4) address of a vbox machine (named ubuntu ) Put Bridged Adapter in the Network Settings VBoxManage guestproperty enumerate ubuntu | grep Net.*V4.*IP Add shared folder from ubuntu guest sudo mount -t vboxsf -o uid=$UID,gid=$(id -g) NAME_OF_SHARED_FOLDER_IN_VBOX FOLDER_IN_WHICH_TO_MOUNT Share folder between ubuntu host and windows guest Add folder to shared folders in VBox settings In windows cli: net use letra : \\\\vboxsvr\\shared_folder_name Resize emulated hard drive user@pc :~$ VBoxManage modifyhd filename.vdi --resize 46080 Problems SSH doesn't work Try bridged mode Premature end of data in tag VirtualBox line 2 Looks like it was caused (in my case) because of the host machine running out of space Found this and some luck. backup the vbox file, and substitute the /path/to/vm/win7/win7.vbox file with the contents of /path/to/vm/win7/win7.vbox . Lost some progress, though.","title":"VirtualBox"},{"location":"Software/VirtualBox/#start-headless-machine-cli","text":"VBoxManage startvm ubuservloc --type headless","title":"Start headless machine CLI"},{"location":"Software/VirtualBox/#get-ipv4-address-of-a-vbox-machine-named-ubuntu","text":"Put Bridged Adapter in the Network Settings VBoxManage guestproperty enumerate ubuntu | grep Net.*V4.*IP","title":"Get ip(v4) address of a vbox machine (named ubuntu)"},{"location":"Software/VirtualBox/#add-shared-folder-from-ubuntu-guest","text":"sudo mount -t vboxsf -o uid=$UID,gid=$(id -g) NAME_OF_SHARED_FOLDER_IN_VBOX FOLDER_IN_WHICH_TO_MOUNT","title":"Add shared folder from ubuntu guest"},{"location":"Software/VirtualBox/#share-folder-between-ubuntu-host-and-windows-guest","text":"Add folder to shared folders in VBox settings In windows cli: net use letra : \\\\vboxsvr\\shared_folder_name","title":"Share folder between ubuntu host and windows guest"},{"location":"Software/VirtualBox/#resize-emulated-hard-drive","text":"user@pc :~$ VBoxManage modifyhd filename.vdi --resize 46080","title":"Resize emulated hard drive"},{"location":"Software/VirtualBox/#problems","text":"","title":"Problems"},{"location":"Software/VirtualBox/#ssh-doesnt-work","text":"Try bridged mode","title":"SSH doesn't work"},{"location":"Software/VirtualBox/#premature-end-of-data-in-tag-virtualbox-line-2","text":"Looks like it was caused (in my case) because of the host machine running out of space Found this and some luck. backup the vbox file, and substitute the /path/to/vm/win7/win7.vbox file with the contents of /path/to/vm/win7/win7.vbox . Lost some progress, though.","title":"Premature end of data in tag VirtualBox line 2"},{"location":"Software/ffmpeg/","text":"Rotate video 90 degrees ffmpeg -i input.mp4 -filter:v transpose=2 -c:v libx264 -preset veryfast -crf 22 -c:a copy -metadata:s:v rotate= input_rotated.mp4","title":"Ffmpeg"},{"location":"Software/ffmpeg/#rotate-video-90-degrees","text":"ffmpeg -i input.mp4 -filter:v transpose=2 -c:v libx264 -preset veryfast -crf 22 -c:a copy -metadata:s:v rotate= input_rotated.mp4","title":"Rotate video 90 degrees"},{"location":"Software/mutt/","text":"Generate gmail password for mutt https://security.google.com/settings/security/apppasswords Send email with attachment $ mutt -s Test from mutt user@mail.com /tmp/message.txt -a /tmp/file.jpg .muttrc Gmail configuration set ssl_starttls=yes set ssl_force_tls=yes set from='gmail_email_address' set realname='Real Name' set folder = imaps://imap.gmail.com/ set spoolfile = imaps://imap.gmail.com/INBOX set postponed= imaps://imap.gmail.com/[Gmail]/Drafts set header_cache = ~/.mutt/cache/headers set message_cachedir = ~/.mutt/cache/bodies set certificate_file = ~/.mutt/certificates set imap_user = 'gmail_email_address' set imap_pass = 'gmail_generated_password_for_insecure_apps' set smtp_url = smtps://'gmail_email_address'@smtp.gmail.com:465/ set smtp_pass = 'gmail_generated_password_for_insecure_apps' set record= set move = no set imap_keepalive = 900","title":"Mutt"},{"location":"Software/mutt/#generate-gmail-password-for-mutt","text":"https://security.google.com/settings/security/apppasswords","title":"Generate gmail password for mutt"},{"location":"Software/mutt/#send-email-with-attachment","text":"$ mutt -s Test from mutt user@mail.com /tmp/message.txt -a /tmp/file.jpg","title":"Send email with attachment"},{"location":"Software/mutt/#muttrc-gmail-configuration","text":"set ssl_starttls=yes set ssl_force_tls=yes set from='gmail_email_address' set realname='Real Name' set folder = imaps://imap.gmail.com/ set spoolfile = imaps://imap.gmail.com/INBOX set postponed= imaps://imap.gmail.com/[Gmail]/Drafts set header_cache = ~/.mutt/cache/headers set message_cachedir = ~/.mutt/cache/bodies set certificate_file = ~/.mutt/certificates set imap_user = 'gmail_email_address' set imap_pass = 'gmail_generated_password_for_insecure_apps' set smtp_url = smtps://'gmail_email_address'@smtp.gmail.com:465/ set smtp_pass = 'gmail_generated_password_for_insecure_apps' set record= set move = no set imap_keepalive = 900","title":".muttrc Gmail configuration"},{"location":"Software/packages to install/","text":"howdoi sudo -H pip install howdoi Find quick solutions to common CLI commands $ howdoi use find with exec $ find . -name *.php -exec chmod 755 {} \\; -exec /bin/echo {} \\; | wc -l","title":"Packages to install"},{"location":"Software/packages to install/#howdoi","text":"sudo -H pip install howdoi Find quick solutions to common CLI commands $ howdoi use find with exec $ find . -name *.php -exec chmod 755 {} \\; -exec /bin/echo {} \\; | wc -l","title":"howdoi"},{"location":"Software/sublime/","text":"Assign key to reindent You can find it in Edit \u2192 Line \u2192 Reindent, but it does not have a shortcut by default. You can add a shortcut by going to the menu Preferences \u2192 Keybindings \u2192 User, then add there: { keys : [ f12 ], command : reindent } (example of using the F12 key for that functionality) The config files use JSON-syntax, so these curly braces have to be placed comma-separated in the square-brackets that are there by default. If you dont have any other key-bindings already, then your whole Keybindings \u2192 User file would look like this, of course: [ { keys : [ Ctrl+i ], command : reindent } ] Sublime text code completion config path ~/.config/sublime-text-2/Packages/SublimeCodeIntel Regex replace (?:def (? funcName .*)(? patata \\()) def $1(self, before def curateText(name): after def curateText(self, name):","title":"Sublime"},{"location":"Software/sublime/#assign-key-to-reindent","text":"You can find it in Edit \u2192 Line \u2192 Reindent, but it does not have a shortcut by default. You can add a shortcut by going to the menu Preferences \u2192 Keybindings \u2192 User, then add there: { keys : [ f12 ], command : reindent } (example of using the F12 key for that functionality) The config files use JSON-syntax, so these curly braces have to be placed comma-separated in the square-brackets that are there by default. If you dont have any other key-bindings already, then your whole Keybindings \u2192 User file would look like this, of course: [ { keys : [ Ctrl+i ], command : reindent } ]","title":"Assign key to reindent"},{"location":"Software/sublime/#sublime-text-code-completion-config-path","text":"~/.config/sublime-text-2/Packages/SublimeCodeIntel","title":"Sublime text code completion config path"},{"location":"Software/sublime/#regex-replace","text":"(?:def (? funcName .*)(? patata \\()) def $1(self,","title":"Regex replace"},{"location":"Software/sublime/#before","text":"def curateText(name):","title":"before"},{"location":"Software/sublime/#after","text":"def curateText(self, name):","title":"after"},{"location":"Software/tmux/","text":"Build tmux from scratch Configuration MacOS set-option -g default-command \"reattach-to-user-namespace -l zsh\" ~./tmux.conf Config example Simple tmux statusline generator Generate a fast shell prompt Cheatsheet https://gist.github.com/patsancu/60bfd4576af7fecd6f8b4329347a108e Sessions tmux new -s session_name ^B + d detach from session without killing anything tmux attach -t session_name attach to sessions Plugins https://github.com/tmux-plugins/tpm tmux commands move window between sessions source move-window -s chat:irc -t other_session","title":"Tmux"},{"location":"Software/tmux/#build-tmux-from-scratch","text":"","title":"Build tmux from scratch"},{"location":"Software/tmux/#configuration","text":"","title":"Configuration"},{"location":"Software/tmux/#macos","text":"set-option -g default-command \"reattach-to-user-namespace -l zsh\"","title":"MacOS"},{"location":"Software/tmux/#tmuxconf","text":"Config example","title":"~./tmux.conf"},{"location":"Software/tmux/#simple-tmux-statusline-generator","text":"","title":"Simple tmux statusline generator"},{"location":"Software/tmux/#generate-a-fast-shell-prompt","text":"","title":"Generate a fast shell prompt"},{"location":"Software/tmux/#cheatsheet","text":"https://gist.github.com/patsancu/60bfd4576af7fecd6f8b4329347a108e","title":"Cheatsheet"},{"location":"Software/tmux/#sessions","text":"tmux new -s session_name ^B + d detach from session without killing anything tmux attach -t session_name attach to sessions","title":"Sessions"},{"location":"Software/tmux/#plugins","text":"https://github.com/tmux-plugins/tpm","title":"Plugins"},{"location":"Software/tmux/#tmux-commands","text":"","title":"tmux commands"},{"location":"Software/tmux/#move-window-between-sessions","text":"source move-window -s chat:irc -t other_session","title":"move window between sessions"},{"location":"Web/Web-browsing-tips/","text":"Javascript: Show password for websites which remember your login details $x('//input[@type= password ]')[0].setAttribute( type , text ) Javascript play with xpath https://gist.github.com/patsancu/7d19c0db94d624e185de9ca748c374ae Use Tor with Chromium Install tor and polipo In /etc/polipo/config uncomment lines: socksParentProxy = localhost:9050 socksProxyType = socks5 Use chromium chromium-browser --proxy-server=\"127.0.0.1:8118;https=127.0.0.1:8118;socks=127.0.0.1:8118;sock4=127.0.0.1:8118;sock5=127.0.0.1:8118,ftp=127.0.0.1:8118\" --incognito check.torproject.org","title":"Web browsing tips"},{"location":"Web/Web-browsing-tips/#javascript-show-password-for-websites-which-remember-your-login-details","text":"$x('//input[@type= password ]')[0].setAttribute( type , text )","title":"Javascript: Show password for websites which remember your login details"},{"location":"Web/Web-browsing-tips/#javascript-play-with-xpath","text":"https://gist.github.com/patsancu/7d19c0db94d624e185de9ca748c374ae","title":"Javascript play with xpath"},{"location":"Web/Web-browsing-tips/#use-tor-with-chromium","text":"Install tor and polipo In /etc/polipo/config uncomment lines: socksParentProxy = localhost:9050 socksProxyType = socks5 Use chromium chromium-browser --proxy-server=\"127.0.0.1:8118;https=127.0.0.1:8118;socks=127.0.0.1:8118;sock4=127.0.0.1:8118;sock5=127.0.0.1:8118,ftp=127.0.0.1:8118\" --incognito check.torproject.org","title":"Use Tor with Chromium"},{"location":"Web/Web-dev-resources/","text":"Themes HTML5up Zero theme Free CSS Geojson map coordinates Geojson.io Maps Map themes https://snazzymaps.com/ Tangram Cool OpenGL maps Images Upload free private images Freeimages Freepik HTTP Request Response Service Website to test post, get and other stuff about http requests Json mock api myjson Misc For the LOL Machine, please make super great website or, if not available, this one","title":"Web dev resources"},{"location":"Web/Web-dev-resources/#themes","text":"HTML5up Zero theme Free CSS","title":"Themes"},{"location":"Web/Web-dev-resources/#geojson-map-coordinates","text":"Geojson.io","title":"Geojson map coordinates"},{"location":"Web/Web-dev-resources/#maps","text":"","title":"Maps"},{"location":"Web/Web-dev-resources/#map-themes","text":"https://snazzymaps.com/","title":"Map themes"},{"location":"Web/Web-dev-resources/#tangram","text":"Cool OpenGL maps","title":"Tangram"},{"location":"Web/Web-dev-resources/#images","text":"Upload free private images Freeimages Freepik","title":"Images"},{"location":"Web/Web-dev-resources/#http-request-response-service","text":"Website to test post, get and other stuff about http requests","title":"HTTP Request &amp; Response Service"},{"location":"Web/Web-dev-resources/#json-mock-api","text":"myjson","title":"Json mock api"},{"location":"Web/Web-dev-resources/#misc","text":"","title":"Misc"},{"location":"Web/Web-dev-resources/#for-the-lol","text":"Machine, please make super great website or, if not available, this one","title":"For the LOL"},{"location":"Web/github/","text":"How to add an image to a gist Create or find a gist that you own. Clone your gist (replace hash with your gist's hash): ```sh # with ssh git clone git@gist.github.com: .git mygist with https git clone https://gist.github.com/ .git mygist ``` Change to your gist\u2019s directory: sh cd mygist Add and commit the image: sh git add tulip.jpg git commit -m \"Add tulip to gist\" Update remote: sh git push origin master See blog post .","title":"[How to add an image to a gist](https://remarkablemark.org/blog/2016/06/16/how-to-add-image-to-gist/)"},{"location":"Web/github/#how-to-add-an-image-to-a-gist","text":"Create or find a gist that you own. Clone your gist (replace hash with your gist's hash): ```sh # with ssh git clone git@gist.github.com: .git mygist","title":"How to add an image to a gist"},{"location":"Web/github/#with-https","text":"git clone https://gist.github.com/ .git mygist ``` Change to your gist\u2019s directory: sh cd mygist Add and commit the image: sh git add tulip.jpg git commit -m \"Add tulip to gist\" Update remote: sh git push origin master See blog post .","title":"with https"},{"location":"dev/DB/Postgres/","text":"Change column type without changing order From here CREATE TEMP TABLE temp_table AS SELECT * FROM original_table; DROP TABLE original_table; CREATE TABLE original_table ... INSERT INTO original_table SELECT * FROM temp_table; List tables SELECT * FROM pg_catalog.pg_tables where tablename like '%patata%' ; SELECT * FROM pg_catalog.pg_tables where schema like '%some_model%' ; Describe table select column_name, data_type, character_maximum_length from INFORMATION_SCHEMA.COLUMNS where table_name = 'table_name_without_schema' Capitalize first letter of each word select initcap(lower(deli.short_title)) from deli Select top N from groups Select top 2 subcategories from each category, according to the movie screentime with grouped_stuff as ( select movie.category, movie.subcategory, sum(movie.screentime) as total_screentime from movies movie where upload_date = '2017-09-18 00:00:00' group by movie.subcategory, movie.category), ranking as ( select grouped_stuff.*, rank() over ( partition by category order by total_screentime desc ) from grouped_stuff ) select * from ranking where rank 3","title":"Postgres"},{"location":"dev/DB/Postgres/#change-column-type-without-changing-order","text":"From here CREATE TEMP TABLE temp_table AS SELECT * FROM original_table; DROP TABLE original_table; CREATE TABLE original_table ... INSERT INTO original_table SELECT * FROM temp_table;","title":"Change column type without changing order"},{"location":"dev/DB/Postgres/#list-tables","text":"SELECT * FROM pg_catalog.pg_tables where tablename like '%patata%' ; SELECT * FROM pg_catalog.pg_tables where schema like '%some_model%' ;","title":"List tables"},{"location":"dev/DB/Postgres/#describe-table","text":"select column_name, data_type, character_maximum_length from INFORMATION_SCHEMA.COLUMNS where table_name = 'table_name_without_schema'","title":"Describe table"},{"location":"dev/DB/Postgres/#capitalize-first-letter-of-each-word","text":"select initcap(lower(deli.short_title)) from deli","title":"Capitalize first letter of each word"},{"location":"dev/DB/Postgres/#select-top-n-from-groups","text":"","title":"Select top N from groups"},{"location":"dev/DB/Postgres/#select-top-2-subcategories-from-each-category-according-to-the-movie-screentime","text":"with grouped_stuff as ( select movie.category, movie.subcategory, sum(movie.screentime) as total_screentime from movies movie where upload_date = '2017-09-18 00:00:00' group by movie.subcategory, movie.category), ranking as ( select grouped_stuff.*, rank() over ( partition by category order by total_screentime desc ) from grouped_stuff ) select * from ranking where rank 3","title":"Select top 2 subcategories from each category, according to the movie screentime"},{"location":"dev/DB/sqlite/","text":"Commands Open/Create a Database, This is done using the command line program. sqlite3 {database file name} sqlite3 my_stuff_database.db If the database exists it will be opened, if it doesn\u2019t exist, it will be created (sort of \u2013 you\u2019ll need to perform some sort of write operation first) Print the database structure .schema Print database structure and data .dump Turn on column names on query results .explain on To turn it off do: .explain off This will return the output to the default of pipe-separated values with no column header. Use the following command to see the current \u2018explain\u2019 status: .show Creating Tables create table {table name} ('{column name}' {data type} primary key, '{column name}' {data type}); Eg: CREATE TABLE my_things('id' int primary key, 'name' varchar(20), 'description' varchar(50)); Adding a Column to a Table alter table {table name} ADD '{column name}' {data type}; Eg: alter table my_things ADD 'description' varchar(50); Deleting a table drop table {table name}; Eg: drop table my_things; Inserting Data into a Table ```insert into {table name} values ({data}, {more data}, '{yet more data}'); Eg: insert into my_things values (1, 'My first thing', 'It is nice'); Transactions begin transaction; {put the relevant queries here} commit; Output query results to a file .output {filename.txt} After entering the above command, the results of subsequent queries will be written to the specified file Change the output back to being printed to the console by typing the following: .output stdout ### Export/dump query results to file `sqlite3 -header -csv /path/to/sql/file.sqlite select * from tracks; tracks.csv` ### Dates #### From epoch to timestamp ```sql SELECT datetime(b.recorded, 'unixepoch', 'localtime') from whatever","title":"Commands"},{"location":"dev/DB/sqlite/#commands","text":"Open/Create a Database, This is done using the command line program. sqlite3 {database file name} sqlite3 my_stuff_database.db If the database exists it will be opened, if it doesn\u2019t exist, it will be created (sort of \u2013 you\u2019ll need to perform some sort of write operation first) Print the database structure .schema Print database structure and data .dump Turn on column names on query results .explain on To turn it off do: .explain off This will return the output to the default of pipe-separated values with no column header. Use the following command to see the current \u2018explain\u2019 status: .show","title":"Commands"},{"location":"dev/DB/sqlite/#creating-tables","text":"create table {table name} ('{column name}' {data type} primary key, '{column name}' {data type}); Eg: CREATE TABLE my_things('id' int primary key, 'name' varchar(20), 'description' varchar(50)); Adding a Column to a Table alter table {table name} ADD '{column name}' {data type}; Eg: alter table my_things ADD 'description' varchar(50); Deleting a table drop table {table name}; Eg: drop table my_things; Inserting Data into a Table ```insert into {table name} values ({data}, {more data}, '{yet more data}'); Eg: insert into my_things values (1, 'My first thing', 'It is nice'); Transactions begin transaction; {put the relevant queries here} commit; Output query results to a file .output {filename.txt} After entering the above command, the results of subsequent queries will be written to the specified file Change the output back to being printed to the console by typing the following: .output stdout ### Export/dump query results to file `sqlite3 -header -csv /path/to/sql/file.sqlite select * from tracks; tracks.csv` ### Dates #### From epoch to timestamp ```sql SELECT datetime(b.recorded, 'unixepoch', 'localtime') from whatever","title":"Creating Tables"},{"location":"dev/DB/Oracle/Admin/","text":"Check number of sessions SELECT 'Currently, ' || (SELECT COUNT(*) FROM V$SESSION) || ' out of ' || VP.VALUE || ' connections are used.' AS USAGE_MESSAGE FROM V$PARAMETER VP WHERE VP.NAME = 'sessions' Change concurrency and stuff params alter system set processes = 150 scope = spfile; alter system set sessions = 300 scope = spfile; alter system set transactions = 330 scope = spfile; List sesssions per pid, machine, username, etc select substr(a.spid,1,9) pid, substr(b.sid,1,5) sid, substr(b.serial#,1,5) ser#, substr(b.machine,1,6) box, substr(b.username,1,10) username, substr(b.osuser,1,8) os_user, substr(b.program,1,30) program from v$session b, v$process a WHERE b.paddr = a.addr and type='USER' order by spid; Delete all tables Proceed with caution BEGIN FOR cur_rec IN (SELECT object_name, object_type FROM user_objects WHERE object_type IN ('TABLE', 'VIEW', 'PACKAGE', 'PROCEDURE', 'FUNCTION', 'SEQUENCE' )) LOOP BEGIN IF cur_rec.object_type = 'TABLE' THEN EXECUTE IMMEDIATE 'DROP ' || cur_rec.object_type || ' ' || cur_rec.object_name || ' CASCADE CONSTRAINTS'; ELSE EXECUTE IMMEDIATE 'DROP ' || cur_rec.object_type || ' ' || cur_rec.object_name || ' '; END IF; EXCEPTION WHEN OTHERS THEN DBMS_OUTPUT.put_line ( 'FAILED: DROP ' || cur_rec.object_type || ' ' || cur_rec.object_name || ' ' ); END; END LOOP; BEGIN EXECUTE IMMEDIATE 'DROP MATERIALIZED VIEW CONT_CORE_PACKAGE_VIEW'; EXCEPTION WHEN OTHERS THEN NULL; END; END; Find table with column name.sql select * from dba_tab_columns where column_name LIKE '%POI%' AND owner != 'SYS' AND owner != 'XDB' AND owner != 'APEX_040000' AND owner != 'MSSQL_ORACLE';","title":"Admin"},{"location":"dev/DB/Oracle/Admin/#check-number-of-sessions","text":"SELECT 'Currently, ' || (SELECT COUNT(*) FROM V$SESSION) || ' out of ' || VP.VALUE || ' connections are used.' AS USAGE_MESSAGE FROM V$PARAMETER VP WHERE VP.NAME = 'sessions'","title":"Check number of sessions"},{"location":"dev/DB/Oracle/Admin/#change-concurrency-and-stuff-params","text":"alter system set processes = 150 scope = spfile; alter system set sessions = 300 scope = spfile; alter system set transactions = 330 scope = spfile;","title":"Change concurrency and stuff params"},{"location":"dev/DB/Oracle/Admin/#list-sesssions-per-pid-machine-username-etc","text":"select substr(a.spid,1,9) pid, substr(b.sid,1,5) sid, substr(b.serial#,1,5) ser#, substr(b.machine,1,6) box, substr(b.username,1,10) username, substr(b.osuser,1,8) os_user, substr(b.program,1,30) program from v$session b, v$process a WHERE b.paddr = a.addr and type='USER' order by spid;","title":"List sesssions per pid, machine, username, etc"},{"location":"dev/DB/Oracle/Admin/#delete-all-tables","text":"Proceed with caution BEGIN FOR cur_rec IN (SELECT object_name, object_type FROM user_objects WHERE object_type IN ('TABLE', 'VIEW', 'PACKAGE', 'PROCEDURE', 'FUNCTION', 'SEQUENCE' )) LOOP BEGIN IF cur_rec.object_type = 'TABLE' THEN EXECUTE IMMEDIATE 'DROP ' || cur_rec.object_type || ' ' || cur_rec.object_name || ' CASCADE CONSTRAINTS'; ELSE EXECUTE IMMEDIATE 'DROP ' || cur_rec.object_type || ' ' || cur_rec.object_name || ' '; END IF; EXCEPTION WHEN OTHERS THEN DBMS_OUTPUT.put_line ( 'FAILED: DROP ' || cur_rec.object_type || ' ' || cur_rec.object_name || ' ' ); END; END LOOP; BEGIN EXECUTE IMMEDIATE 'DROP MATERIALIZED VIEW CONT_CORE_PACKAGE_VIEW'; EXCEPTION WHEN OTHERS THEN NULL; END; END;","title":"Delete all tables"},{"location":"dev/DB/Oracle/Admin/#find-table-with-column-namesql","text":"select * from dba_tab_columns where column_name LIKE '%POI%' AND owner != 'SYS' AND owner != 'XDB' AND owner != 'APEX_040000' AND owner != 'MSSQL_ORACLE';","title":"Find table with column name.sql"},{"location":"dev/DB/Oracle/Generic/","text":"How to turn off oracle password expiration source To alter the password expiry policy for a certain user profile in Oracle first check wich profile the user is in using: select profile from DBA_USERS where username = ' username '; Then you can change the limit to never expire using: alter profile profile_name limit password_life_time UNLIMITED; If you want to previously check the limit you may use: select resource_name,limit from dba_profiles where profile=' profile_name '; What do if password expired oracle delete user drop user cms_int cascade; create user again create user cms_int identified by cms_int; grant all privileges to cms_int identified by cms_int; Import db dump CREATE USER bakbak IDENTIFIED BY bakbak; GRANT CREATE TRIGGER, CREATE SEQUENCE, CREATE SESSION, CREATE TABLE, CREATE VIEW, CREATE PROCEDURE, CREATE SYNONYM, CREATE TABLESPACE TO bakbak; GRANT ALTER TABLESPACE TO bakbak; GRANT ALTER ANY TABLE, ALTER ANY PROCEDURE TO bakbak; GRANT DROP TABLESPACE, DROP ANY TABLE, DROP ANY VIEW, DROP ANY PROCEDURE,DROP ANY SYNONYM TO bakbak; ALTER USER bakbak QUOTA UNLIMITED ON USERS; GRANT UNLIMITED TABLESPACE TO bakbak; GRANT CREATE ANY DIRECTORY TO bakbak; GRANT DROP ANY DIRECTORY TO bakbak; GRANT CREATE TRIGGER TO bakbak; GRANT DROP ANY PROCEDURE TO bakbak; GRANT ALTER ANY PROCEDURE TO bakbak; GRANT CREATE PROCEDURE TO bakbak; GRANT CREATE SEQUENCE TO bakbak; GRANT DROP ANY VIEW TO bakbak; GRANT CREATE VIEW TO bakbak; GRANT DROP ANY SYNONYM TO bakbak; GRANT CREATE SYNONYM TO bakbak; GRANT DROP ANY TABLE TO bakbak; GRANT ALTER ANY TABLE TO bakbak; GRANT CREATE TABLE TO bakbak; GRANT UNLIMITED TABLESPACE TO bakbak; GRANT DROP TABLESPACE TO bakbak; GRANT ALTER TABLESPACE TO bakbak; GRANT CREATE TABLESPACE TO bakbak; GRANT CREATE SESSION TO bakbak; GRANT IMP_FULL_DATABASE TO bakbak; GRANT EXP_FULL_DATABASE TO bakbak; CREATE DIRECTORY mydir AS '/home/patrick/Data/dumps_db/'; GRANT read, write on directory mydir to public; GRANT read, write ON mydir TO bakbak; ALTER USER bakbak QUOTA UNLIMITED ON USERS; GRANT UNLIMITED TABLESPACE TO bakbak; commit; Execute in bash impdp bakbak/bakbak directory=mydir file=export_data.dmp remap_schema=cv_mex_mtv:bakbak EXCLUDE=TABLE:\\ IN \\(\\'EIT_MANIFEST\\',\\'WH_FACT_AUDIENCE\\',\\'ACT_ACTIVITY\\', \\'REC_RECORDING\\', \\'REC_RECORDING_I18N\\', \\'ADI_FILE_IMPORT\\' \\)\\ logfile=data_pump_dir:expsh.log ### Stop job impdp Import KILL_JOB ### Find and delete pending import jobs ```sql SELECT owner_name, job_name, operation, job_mode, state, attached_sessions FROM dba_datapump_jobs ORDER BY 1,2; SELECT * FROM dba_objects o, dba_datapump_jobs j WHERE o.owner=j.owner_name AND o.object_name=j.job_name AND j.job_name NOT LIKE 'BIN$%' ORDER BY 4,2; DROP TABLE BAKBAK.SYS_IMPORT_FULL_01; Delete views, tables for a user Get scripts to drop tables and views select 'drop table '||table_name||' cascade constraints;' from user_tables; select 'drop view '||view_name||' cascade constraints;' from user_views; Delete sequences BEGIN --Bye Sequences! FOR i IN (SELECT us.sequence_name FROM USER_SEQUENCES us) LOOP EXECUTE IMMEDIATE 'drop sequence '|| i.sequence_name ||''; END LOOP; --Bye Tables! FOR i IN (SELECT ut.table_name FROM USER_TABLES ut) LOOP EXECUTE IMMEDIATE 'drop table '|| i.table_name ||' CASCADE CONSTRAINTS '; END LOOP; END;","title":"Generic"},{"location":"dev/DB/Oracle/Generic/#how-to-turn-off-oracle-password-expiration","text":"source To alter the password expiry policy for a certain user profile in Oracle first check wich profile the user is in using: select profile from DBA_USERS where username = ' username '; Then you can change the limit to never expire using: alter profile profile_name limit password_life_time UNLIMITED; If you want to previously check the limit you may use: select resource_name,limit from dba_profiles where profile=' profile_name ';","title":"How to turn off oracle password expiration"},{"location":"dev/DB/Oracle/Generic/#what-do-if-password-expired-oracle","text":"","title":"What do if password expired oracle"},{"location":"dev/DB/Oracle/Generic/#delete-user","text":"drop user cms_int cascade;","title":"delete user"},{"location":"dev/DB/Oracle/Generic/#create-user-again","text":"create user cms_int identified by cms_int; grant all privileges to cms_int identified by cms_int;","title":"create user again"},{"location":"dev/DB/Oracle/Generic/#import-db-dump","text":"CREATE USER bakbak IDENTIFIED BY bakbak; GRANT CREATE TRIGGER, CREATE SEQUENCE, CREATE SESSION, CREATE TABLE, CREATE VIEW, CREATE PROCEDURE, CREATE SYNONYM, CREATE TABLESPACE TO bakbak; GRANT ALTER TABLESPACE TO bakbak; GRANT ALTER ANY TABLE, ALTER ANY PROCEDURE TO bakbak; GRANT DROP TABLESPACE, DROP ANY TABLE, DROP ANY VIEW, DROP ANY PROCEDURE,DROP ANY SYNONYM TO bakbak; ALTER USER bakbak QUOTA UNLIMITED ON USERS; GRANT UNLIMITED TABLESPACE TO bakbak; GRANT CREATE ANY DIRECTORY TO bakbak; GRANT DROP ANY DIRECTORY TO bakbak; GRANT CREATE TRIGGER TO bakbak; GRANT DROP ANY PROCEDURE TO bakbak; GRANT ALTER ANY PROCEDURE TO bakbak; GRANT CREATE PROCEDURE TO bakbak; GRANT CREATE SEQUENCE TO bakbak; GRANT DROP ANY VIEW TO bakbak; GRANT CREATE VIEW TO bakbak; GRANT DROP ANY SYNONYM TO bakbak; GRANT CREATE SYNONYM TO bakbak; GRANT DROP ANY TABLE TO bakbak; GRANT ALTER ANY TABLE TO bakbak; GRANT CREATE TABLE TO bakbak; GRANT UNLIMITED TABLESPACE TO bakbak; GRANT DROP TABLESPACE TO bakbak; GRANT ALTER TABLESPACE TO bakbak; GRANT CREATE TABLESPACE TO bakbak; GRANT CREATE SESSION TO bakbak; GRANT IMP_FULL_DATABASE TO bakbak; GRANT EXP_FULL_DATABASE TO bakbak; CREATE DIRECTORY mydir AS '/home/patrick/Data/dumps_db/'; GRANT read, write on directory mydir to public; GRANT read, write ON mydir TO bakbak; ALTER USER bakbak QUOTA UNLIMITED ON USERS; GRANT UNLIMITED TABLESPACE TO bakbak; commit; Execute in bash impdp bakbak/bakbak directory=mydir file=export_data.dmp remap_schema=cv_mex_mtv:bakbak EXCLUDE=TABLE:\\ IN \\(\\'EIT_MANIFEST\\',\\'WH_FACT_AUDIENCE\\',\\'ACT_ACTIVITY\\', \\'REC_RECORDING\\', \\'REC_RECORDING_I18N\\', \\'ADI_FILE_IMPORT\\' \\)\\ logfile=data_pump_dir:expsh.log ### Stop job impdp Import KILL_JOB ### Find and delete pending import jobs ```sql SELECT owner_name, job_name, operation, job_mode, state, attached_sessions FROM dba_datapump_jobs ORDER BY 1,2; SELECT * FROM dba_objects o, dba_datapump_jobs j WHERE o.owner=j.owner_name AND o.object_name=j.job_name AND j.job_name NOT LIKE 'BIN$%' ORDER BY 4,2; DROP TABLE BAKBAK.SYS_IMPORT_FULL_01;","title":"Import db dump"},{"location":"dev/DB/Oracle/Generic/#delete-views-tables-for-a-user","text":"","title":"Delete views, tables for a user"},{"location":"dev/DB/Oracle/Generic/#get-scripts-to-drop-tables-and-views","text":"select 'drop table '||table_name||' cascade constraints;' from user_tables; select 'drop view '||view_name||' cascade constraints;' from user_views;","title":"Get scripts to drop tables and views"},{"location":"dev/DB/Oracle/Generic/#delete-sequences","text":"BEGIN --Bye Sequences! FOR i IN (SELECT us.sequence_name FROM USER_SEQUENCES us) LOOP EXECUTE IMMEDIATE 'drop sequence '|| i.sequence_name ||''; END LOOP; --Bye Tables! FOR i IN (SELECT ut.table_name FROM USER_TABLES ut) LOOP EXECUTE IMMEDIATE 'drop table '|| i.table_name ||' CASCADE CONSTRAINTS '; END LOOP; END;","title":"Delete sequences"},{"location":"dev/DB/Oracle/Snippets/","text":"Selective count SELECT count( CASE WHEN content.parental_rating IS NULL THEN 1 end )/count(*)*100 FROM CONT_AV_CONTENT content Rank rows relative to some column A content has multiple genres. This will rank genres of each content (categorised according to their title). SELECT content.content_id, content.title, genre.NAME, Row_number() OVER ( partition BY content.title ORDER BY genre.genre_id DESC) AS ranking FROM cont_av_content CONTENT JOIN cont_content_genre_map cmap ON content.content_id = cmap.content_id JOIN cont_genre genre ON genre.genre_id = cmap.genre_id From string to timestamp TO_TIMESTAMP('2016-05-14', 'YYYY-MM-DD') Calculate table size source -- Tables + Size MB select owner, table_name, round((num_rows*avg_row_len)/(1024*1024)) MB from all_tables where owner not like 'SYS%' -- Exclude system tables. and num_rows 0 -- Ignore empty Tables. order by MB desc -- Biggest first.; --Tables + Rows select owner, table_name, num_rows from all_tables where owner not like 'SYS%' -- Exclude system tables. and num_rows 0 -- Ignore empty Tables. order by num_rows desc -- Biggest first.; Group by truncated date select TRUNC(created), count(*) from PURCHASES where created = TO_TIMESTAMP ( '01-OCT-2017 00:00:00', 'DD-MON-YYYY HH24:MI:SS') group by TRUNC(created) Look for table by name SELECT owner, table_name FROM dba_tables where owner = 'da_owner' Round timestamp/datetime to next 5 minutes with table_x as ( select timestamp '2010-02-19 01:25:46' t from dual union all select timestamp '2010-02-19 01:40:46' from dual union all select timestamp '2010-02-19 01:55:46' from dual union ALL select timestamp '2010-02-19 01:19:46' from dual union ALL select timestamp '2010-02-19 01:00:00' from dual union ALL select timestamp '2010-02-19 01:00:01' from dual union ALL select timestamp '2010-02-19 23:58:01' from dual union all select timestamp '2010-02-19 02:10:46' from dual) select t AS input_time, case when mod(60*extract(minute from t)+extract(second from t),60*5) 0 then t+NumToDsInterVal(60*5-mod(60*extract(minute from t)+extract(second from t),60*5),'SECOND') else t end as rounded_time from table_x; WITH time_table AS ( SELECT CAST(TO_DATE('2016-03-18 08:54:00', 'YYYY-MM-DD HH24:MI:SS') AS timestamp) t FROM dual UNION ALL SELECT CAST(TO_DATE('2016-03-20 23:59:00', 'YYYY-MM-DD HH24:MI:SS') AS timestamp) t FROM dual UNION ALL SELECT CAST(TO_DATE('2016-03-20 00:05:00', 'YYYY-MM-DD HH24:MI:SS') AS timestamp) t FROM dual UNION ALL SELECT CAST(TO_DATE('2016-03-20 00:05:01', 'YYYY-MM-DD HH24:MI:SS') AS timestamp) t FROM dual UNION ALL SELECT CAST(TO_DATE('2016-03-31 23:59:00', 'YYYY-MM-DD HH24:MI:SS') AS timestamp) t FROM dual ) SELECT t AS input_time, case when mod(60*extract(minute from t)+extract(second from t),60*5) 0 then t+NumToDsInterVal(60*5-mod(60*extract(minute from t)+extract(second from t),60*5),'SECOND') else t end as rounded_time_TO FROM time_table Split string and pick last WITH some_table AS ( SELECT 'SOME_CITY_NAME_1' city_name FROM dual UNION ALL SELECT 'BERLIN_24' FROM dual UNION ALL SELECT 'MADRID_3' FROM dual UNION ALL SELECT 'SOME_OTHER_CITY_NAME_2' FROM dual ) SELECT city_name, SUBSTR( city_name, INSTR( city_name, '_', -1 )+1 ) FROM some_table -- RESULTS -- CITY_NAME SUBSTR(CITY_NAME,INSTR(CITY_NAME,'_',-1)+1) -- ======================================== -- SOME_CITY_NAME_1 || 1 -- BERLIN_24 || 24 -- MADRID_3 || 3 -- SOME_OTHER_CITY_NAME_2 || 2 Split string and pick all but last WITH some_table AS ( SELECT 'SOME_CITY_NAME_1' city_name FROM dual UNION ALL SELECT 'BERLIN_24' FROM dual UNION ALL SELECT 'MADRID_3' FROM dual UNION ALL SELECT 'SOME_OTHER_CITY_NAME_2' FROM dual ) SELECT city_name, SUBSTR( city_name, 0, INSTR( city_name, '_', -1 )-1 ) FROM some_table -- RESULTS -- CITY_NAME;SUBSTR(CITY_NAME,0,INSTR(CITY_NAME,'_',-1)-1) -- ======================================== -- SOME_CITY_NAME_1;SOME_CITY_NAME -- BERLIN_24;BERLIN -- MADRID_3;MADRID -- SOME_OTHER_CITY_NAME_2;SOME_OTHER_CITY_NAME","title":"Snippets"},{"location":"dev/DB/Oracle/Snippets/#selective-count","text":"SELECT count( CASE WHEN content.parental_rating IS NULL THEN 1 end )/count(*)*100 FROM CONT_AV_CONTENT content","title":"Selective count"},{"location":"dev/DB/Oracle/Snippets/#rank-rows-relative-to-some-column","text":"A content has multiple genres. This will rank genres of each content (categorised according to their title). SELECT content.content_id, content.title, genre.NAME, Row_number() OVER ( partition BY content.title ORDER BY genre.genre_id DESC) AS ranking FROM cont_av_content CONTENT JOIN cont_content_genre_map cmap ON content.content_id = cmap.content_id JOIN cont_genre genre ON genre.genre_id = cmap.genre_id","title":"Rank rows relative to some column"},{"location":"dev/DB/Oracle/Snippets/#from-string-to-timestamp","text":"TO_TIMESTAMP('2016-05-14', 'YYYY-MM-DD')","title":"From string to timestamp"},{"location":"dev/DB/Oracle/Snippets/#calculate-table-size","text":"source -- Tables + Size MB select owner, table_name, round((num_rows*avg_row_len)/(1024*1024)) MB from all_tables where owner not like 'SYS%' -- Exclude system tables. and num_rows 0 -- Ignore empty Tables. order by MB desc -- Biggest first.; --Tables + Rows select owner, table_name, num_rows from all_tables where owner not like 'SYS%' -- Exclude system tables. and num_rows 0 -- Ignore empty Tables. order by num_rows desc -- Biggest first.;","title":"Calculate table size"},{"location":"dev/DB/Oracle/Snippets/#group-by-truncated-date","text":"select TRUNC(created), count(*) from PURCHASES where created = TO_TIMESTAMP ( '01-OCT-2017 00:00:00', 'DD-MON-YYYY HH24:MI:SS') group by TRUNC(created)","title":"Group by truncated date"},{"location":"dev/DB/Oracle/Snippets/#look-for-table-by-name","text":"SELECT owner, table_name FROM dba_tables where owner = 'da_owner'","title":"Look for table by name"},{"location":"dev/DB/Oracle/Snippets/#round-timestampdatetime-to-next-5-minutes","text":"with table_x as ( select timestamp '2010-02-19 01:25:46' t from dual union all select timestamp '2010-02-19 01:40:46' from dual union all select timestamp '2010-02-19 01:55:46' from dual union ALL select timestamp '2010-02-19 01:19:46' from dual union ALL select timestamp '2010-02-19 01:00:00' from dual union ALL select timestamp '2010-02-19 01:00:01' from dual union ALL select timestamp '2010-02-19 23:58:01' from dual union all select timestamp '2010-02-19 02:10:46' from dual) select t AS input_time, case when mod(60*extract(minute from t)+extract(second from t),60*5) 0 then t+NumToDsInterVal(60*5-mod(60*extract(minute from t)+extract(second from t),60*5),'SECOND') else t end as rounded_time from table_x; WITH time_table AS ( SELECT CAST(TO_DATE('2016-03-18 08:54:00', 'YYYY-MM-DD HH24:MI:SS') AS timestamp) t FROM dual UNION ALL SELECT CAST(TO_DATE('2016-03-20 23:59:00', 'YYYY-MM-DD HH24:MI:SS') AS timestamp) t FROM dual UNION ALL SELECT CAST(TO_DATE('2016-03-20 00:05:00', 'YYYY-MM-DD HH24:MI:SS') AS timestamp) t FROM dual UNION ALL SELECT CAST(TO_DATE('2016-03-20 00:05:01', 'YYYY-MM-DD HH24:MI:SS') AS timestamp) t FROM dual UNION ALL SELECT CAST(TO_DATE('2016-03-31 23:59:00', 'YYYY-MM-DD HH24:MI:SS') AS timestamp) t FROM dual ) SELECT t AS input_time, case when mod(60*extract(minute from t)+extract(second from t),60*5) 0 then t+NumToDsInterVal(60*5-mod(60*extract(minute from t)+extract(second from t),60*5),'SECOND') else t end as rounded_time_TO FROM time_table","title":"Round timestamp/datetime to next 5 minutes"},{"location":"dev/DB/Oracle/Snippets/#split-string-and-pick-last","text":"WITH some_table AS ( SELECT 'SOME_CITY_NAME_1' city_name FROM dual UNION ALL SELECT 'BERLIN_24' FROM dual UNION ALL SELECT 'MADRID_3' FROM dual UNION ALL SELECT 'SOME_OTHER_CITY_NAME_2' FROM dual ) SELECT city_name, SUBSTR( city_name, INSTR( city_name, '_', -1 )+1 ) FROM some_table -- RESULTS -- CITY_NAME SUBSTR(CITY_NAME,INSTR(CITY_NAME,'_',-1)+1) -- ======================================== -- SOME_CITY_NAME_1 || 1 -- BERLIN_24 || 24 -- MADRID_3 || 3 -- SOME_OTHER_CITY_NAME_2 || 2","title":"Split string and pick last"},{"location":"dev/DB/Oracle/Snippets/#split-string-and-pick-all-but-last","text":"WITH some_table AS ( SELECT 'SOME_CITY_NAME_1' city_name FROM dual UNION ALL SELECT 'BERLIN_24' FROM dual UNION ALL SELECT 'MADRID_3' FROM dual UNION ALL SELECT 'SOME_OTHER_CITY_NAME_2' FROM dual ) SELECT city_name, SUBSTR( city_name, 0, INSTR( city_name, '_', -1 )-1 ) FROM some_table -- RESULTS -- CITY_NAME;SUBSTR(CITY_NAME,0,INSTR(CITY_NAME,'_',-1)-1) -- ======================================== -- SOME_CITY_NAME_1;SOME_CITY_NAME -- BERLIN_24;BERLIN -- MADRID_3;MADRID -- SOME_OTHER_CITY_NAME_2;SOME_OTHER_CITY_NAME","title":"Split string and pick all but last"},{"location":"dev/DB/Oracle/Troubleshooting/","text":"Character set mismatch in a case expression Source Maybe it's a mismatch between an NVARCHAR and a regular VARCHAR, like in the following example, where t.First_Col is a NVARCHAR and the string it's being compared to is a regular string (Varchar). CASE WHEN t.First_Col = 'ItemOne' THEN 'anItemOne' WHEN t.First_Col = 'ItemTwo' THEN CASE WHEN t.Second_Col = 'ItemTwo_A' THEN 'aSecondItem_A' ELSE 'aSecondItem' END ELSE 'NoItem' END Add a n prefix, like this: CASE WHEN t.First_Col = N'ItemOne' THEN N'anItemOne' WHEN t.First_Col = N'ItemTwo' THEN (CASE WHEN t.Second_Col = N'ItemTwo_A' THEN N'aSecondItem_A' ELSE N'aSecondItem' END) ELSE N'NoItem' END","title":"Troubleshooting"},{"location":"dev/DB/Oracle/Troubleshooting/#character-set-mismatch-in-a-case-expression","text":"Source Maybe it's a mismatch between an NVARCHAR and a regular VARCHAR, like in the following example, where t.First_Col is a NVARCHAR and the string it's being compared to is a regular string (Varchar). CASE WHEN t.First_Col = 'ItemOne' THEN 'anItemOne' WHEN t.First_Col = 'ItemTwo' THEN CASE WHEN t.Second_Col = 'ItemTwo_A' THEN 'aSecondItem_A' ELSE 'aSecondItem' END ELSE 'NoItem' END Add a n prefix, like this: CASE WHEN t.First_Col = N'ItemOne' THEN N'anItemOne' WHEN t.First_Col = N'ItemTwo' THEN (CASE WHEN t.Second_Col = N'ItemTwo_A' THEN N'aSecondItem_A' ELSE N'aSecondItem' END) ELSE N'NoItem' END","title":"Character set mismatch in a case expression"},{"location":"dev/Java/Gradle/","text":"Copy entire folder task mytest { copy { from fileTree('folder/mytest') into mytest } } Debug List folder contents new File( ${stageDir} ).eachFile{ println it} Run spring boot project with java params Put this in build.gradle file bootRun { systemProperty( spring.config.location , src/main/docker/application.properties,../override.properties ) } Then, usual run gradle bootrun Run debug gradle bootrun --debug-jvm","title":"Gradle"},{"location":"dev/Java/Gradle/#copy-entire-folder","text":"task mytest { copy { from fileTree('folder/mytest') into mytest } }","title":"Copy entire folder"},{"location":"dev/Java/Gradle/#debug","text":"","title":"Debug"},{"location":"dev/Java/Gradle/#list-folder-contents","text":"new File( ${stageDir} ).eachFile{ println it}","title":"List folder contents"},{"location":"dev/Java/Gradle/#run-spring-boot-project-with-java-params","text":"Put this in build.gradle file bootRun { systemProperty( spring.config.location , src/main/docker/application.properties,../override.properties ) } Then, usual run gradle bootrun","title":"Run spring boot project with java params"},{"location":"dev/Java/Gradle/#run-debug","text":"gradle bootrun --debug-jvm","title":"Run debug"},{"location":"dev/Java/Java-snippets/","text":"Sleep //Pause for 4 seconds Thread.sleep(4000); Write file public void writeFile() { try(FileOutputStream fos = newFileOutputStream( movies.txt ); DataOutputStream dos = newDataOutputStream(fos)) { dos.writeUTF( Java 7 Block Buster ); } catch(IOException e) { // log the exception } } Read file Java 7 Read all contents at once String content = new String(Files.readAllBytes(Paths.get(fileName))); Line by line package com.mkyong; import java.io.BufferedReader; import java.io.File; import java.io.FileReader; import java.io.IOException; public class ReadTextFile { public static void main(String[] args) throws IOException { try { File f = new File( src/com/mkyong/data.txt ); BufferedReader b = new BufferedReader(new FileReader(f)); String readLine = ; System.out.println( Reading file using Buffered Reader ); while ((readLine = b.readLine()) != null) { System.out.println(readLine); } } catch (IOException e) { e.printStackTrace(); } } } Java 8 Stream String lines = Files.lines(path); lines.forEach(line - data.append(line).append( \\n )); lines.close(); @Test public void givenFilePath_whenUsingFilesLines_thenFileData() { String expectedData = Hello World from fileTest.txt!!! ; Path path = Paths.get(getClass().getClassLoader() .getResource( fileTest.txt ).toURI()); StringBuilder data = new StringBuilder(); Stream String lines = Files.lines(path); lines.forEach(line - data.append(line).append( \\n )); lines.close(); Assert.assertEquals(expectedData, data.toString().trim()); } Read file extension http://commons.apache.org/proper/commons-io/javadocs/api-2.5/org/apache/commons/io/FilenameUtils.html#getExtension String ext1 = FilenameUtils.getExtension( /path/to/file/foo.txt ); // returns txt String ext2 = FilenameUtils.getExtension( bar.exe ); // returns exe // https://mvnrepository.com/artifact/commons-io/commons-io compile group: 'commons-io', name: 'commons-io', version: '2.4' Get file last updated date import java.io.File; import java.text.SimpleDateFormat; public class GetFileLastModifiedExample { public static void main(String[] args) { File file = new File( c:\\\\logfile.log ); System.out.println( Before Format : + file.lastModified()); SimpleDateFormat sdf = new SimpleDateFormat( MM/dd/yyyy HH:mm:ss ); System.out.println( After Format : + sdf.format(file.lastModified())); } } Empty stack trace From here . Useful for custom exceptions, or when a quicker error handling is required. /** * efficient exception that has no stacktrace; we use this for flow-control. */ @Immutable static final class ResourceNotFound extends Exception { ResourceNotFound() {} @Override public Throwable fillInStackTrace() { return this; } } Create temp file/folder import java.nio.file.Files; tempCheckpointFolder = Files.createTempDirectory( checkpoints ); //the directory must be empty in order to be deleted. tempCheckpointFolder.toFile().deleteOnExit(); Compute time difference LocalDateTime now = LocalDateTime.now(); boolean olderThanAday = ChronoUnit.DAYS.between(startSessionDate, now ) = 1; if (olderThanAday){ System.out.println( The stored timestamp is older than a day ) startSessionDate = now; } Random alphanumeric string ``` org.apache.commons commons-lang3 3.8 RandomStringUtils.randomAlphanumeric(10); ### Difference between two dates LocalDateTime now = LocalDateTime.now(); boolean olderThanAday = ChronoUnit.DAYS.between(startSessionDate, now ) = 1; if (startSessionDate == null || olderThanAday){ AuthLoginResponseType response = this.serviceV12.startSession(this.username, this.password, this.locale); this.sessionId = response.getResult().getValue().getSessionId(); startSessionDate = now; }```","title":"Java snippets"},{"location":"dev/Java/Java-snippets/#sleep","text":"//Pause for 4 seconds Thread.sleep(4000);","title":"Sleep"},{"location":"dev/Java/Java-snippets/#write-file","text":"public void writeFile() { try(FileOutputStream fos = newFileOutputStream( movies.txt ); DataOutputStream dos = newDataOutputStream(fos)) { dos.writeUTF( Java 7 Block Buster ); } catch(IOException e) { // log the exception } }","title":"Write file"},{"location":"dev/Java/Java-snippets/#read-file","text":"","title":"Read file"},{"location":"dev/Java/Java-snippets/#java-7","text":"","title":"Java 7"},{"location":"dev/Java/Java-snippets/#read-all-contents-at-once","text":"String content = new String(Files.readAllBytes(Paths.get(fileName)));","title":"Read all contents at once"},{"location":"dev/Java/Java-snippets/#line-by-line","text":"package com.mkyong; import java.io.BufferedReader; import java.io.File; import java.io.FileReader; import java.io.IOException; public class ReadTextFile { public static void main(String[] args) throws IOException { try { File f = new File( src/com/mkyong/data.txt ); BufferedReader b = new BufferedReader(new FileReader(f)); String readLine = ; System.out.println( Reading file using Buffered Reader ); while ((readLine = b.readLine()) != null) { System.out.println(readLine); } } catch (IOException e) { e.printStackTrace(); } } }","title":"Line by line"},{"location":"dev/Java/Java-snippets/#java-8","text":"Stream String lines = Files.lines(path); lines.forEach(line - data.append(line).append( \\n )); lines.close(); @Test public void givenFilePath_whenUsingFilesLines_thenFileData() { String expectedData = Hello World from fileTest.txt!!! ; Path path = Paths.get(getClass().getClassLoader() .getResource( fileTest.txt ).toURI()); StringBuilder data = new StringBuilder(); Stream String lines = Files.lines(path); lines.forEach(line - data.append(line).append( \\n )); lines.close(); Assert.assertEquals(expectedData, data.toString().trim()); }","title":"Java 8"},{"location":"dev/Java/Java-snippets/#read-file-extension","text":"http://commons.apache.org/proper/commons-io/javadocs/api-2.5/org/apache/commons/io/FilenameUtils.html#getExtension String ext1 = FilenameUtils.getExtension( /path/to/file/foo.txt ); // returns txt String ext2 = FilenameUtils.getExtension( bar.exe ); // returns exe // https://mvnrepository.com/artifact/commons-io/commons-io compile group: 'commons-io', name: 'commons-io', version: '2.4'","title":"Read file extension"},{"location":"dev/Java/Java-snippets/#get-file-last-updated-date","text":"import java.io.File; import java.text.SimpleDateFormat; public class GetFileLastModifiedExample { public static void main(String[] args) { File file = new File( c:\\\\logfile.log ); System.out.println( Before Format : + file.lastModified()); SimpleDateFormat sdf = new SimpleDateFormat( MM/dd/yyyy HH:mm:ss ); System.out.println( After Format : + sdf.format(file.lastModified())); } }","title":"Get file last updated date"},{"location":"dev/Java/Java-snippets/#empty-stack-trace","text":"From here . Useful for custom exceptions, or when a quicker error handling is required. /** * efficient exception that has no stacktrace; we use this for flow-control. */ @Immutable static final class ResourceNotFound extends Exception { ResourceNotFound() {} @Override public Throwable fillInStackTrace() { return this; } }","title":"Empty stack trace"},{"location":"dev/Java/Java-snippets/#create-temp-filefolder","text":"import java.nio.file.Files; tempCheckpointFolder = Files.createTempDirectory( checkpoints ); //the directory must be empty in order to be deleted. tempCheckpointFolder.toFile().deleteOnExit();","title":"Create temp file/folder"},{"location":"dev/Java/Java-snippets/#compute-time-difference","text":"LocalDateTime now = LocalDateTime.now(); boolean olderThanAday = ChronoUnit.DAYS.between(startSessionDate, now ) = 1; if (olderThanAday){ System.out.println( The stored timestamp is older than a day ) startSessionDate = now; }","title":"Compute time difference"},{"location":"dev/Java/Java-snippets/#random-alphanumeric-string","text":"``` org.apache.commons commons-lang3 3.8 RandomStringUtils.randomAlphanumeric(10); ### Difference between two dates LocalDateTime now = LocalDateTime.now(); boolean olderThanAday = ChronoUnit.DAYS.between(startSessionDate, now ) = 1; if (startSessionDate == null || olderThanAday){ AuthLoginResponseType response = this.serviceV12.startSession(this.username, this.password, this.locale); this.sessionId = response.getResult().getValue().getSessionId(); startSessionDate = now; }```","title":"Random alphanumeric string"},{"location":"dev/Java/Java/","text":"Basic CLI Compile and run javac p.java; java p Create jar from class jar -cvfe TheJavaFile.jar MainClass TheJavaFile.class Run jar java -jar TheJavaFile.jar Run a class from Jar which is not the Main-Class in its Manifest file java -cp MyJar.jar com.mycomp.myproj.dir2.MainClass2 /home/myhome/datasource.properties /home/myhome/input.txt Find out what is loading some specific class java -verbose:class project-televisa-reports-db-extractor-spring-boot.jar | grep javax.servlet.ServletContext More info here JMX debug jconsole execute $JAVA_HOME/bin/jconsole server:port ## Example: $JAVA_HOME/bin/jconsole localhost:8048 Freemarker Ouptut integers without commas (separating the thousands) Add ?c to the number variable report.total_households?c Eclipse Remote debug java -jar -Xdebug -Xrunjdwp:transport=dt_socket,server=y,address= 8765 project.jar --server.port=7080 From Eclipse, Run - Debug configurations... - Remote Java Application In Connection Type : Standard (Socket Attach) Connection Properties: Host: localhost Port: 8765 More info here Extract jar contents jar jar xf iris-analytics-information-extractor-1.1.1.jar Useful libraries com.google.common.base.Strings static String commonPrefix(CharSequence a, CharSequence b) static String commonSuffix(CharSequence a, CharSequence b) static String emptyToNull(String string) static boolean isNullOrEmpty(String string) static String nullToEmpty(String string) static String padEnd(String string, int minLength, char padChar) static String padStart(String string, int minLength, char padChar) static String repeat(String string, int count)","title":"Java"},{"location":"dev/Java/Java/#basic-cli","text":"","title":"Basic CLI"},{"location":"dev/Java/Java/#compile-and-run","text":"javac p.java; java p","title":"Compile and run"},{"location":"dev/Java/Java/#create-jar-from-class","text":"jar -cvfe TheJavaFile.jar MainClass TheJavaFile.class","title":"Create jar from class"},{"location":"dev/Java/Java/#run-jar","text":"java -jar TheJavaFile.jar","title":"Run jar"},{"location":"dev/Java/Java/#run-a-class-from-jar-which-is-not-the-main-class-in-its-manifest-file","text":"java -cp MyJar.jar com.mycomp.myproj.dir2.MainClass2 /home/myhome/datasource.properties /home/myhome/input.txt","title":"Run a class from Jar which is not the Main-Class in its Manifest file"},{"location":"dev/Java/Java/#find-out-what-is-loading-some-specific-class","text":"java -verbose:class project-televisa-reports-db-extractor-spring-boot.jar | grep javax.servlet.ServletContext More info here","title":"Find out what is loading some specific class"},{"location":"dev/Java/Java/#jmx-debug-jconsole","text":"execute $JAVA_HOME/bin/jconsole server:port ## Example: $JAVA_HOME/bin/jconsole localhost:8048","title":"JMX debug jconsole"},{"location":"dev/Java/Java/#freemarker","text":"","title":"Freemarker"},{"location":"dev/Java/Java/#ouptut-integers-without-commas-separating-the-thousands","text":"Add ?c to the number variable report.total_households?c","title":"Ouptut integers without commas (separating the thousands)"},{"location":"dev/Java/Java/#eclipse","text":"","title":"Eclipse"},{"location":"dev/Java/Java/#remote-debug","text":"java -jar -Xdebug -Xrunjdwp:transport=dt_socket,server=y,address= 8765 project.jar --server.port=7080 From Eclipse, Run - Debug configurations... - Remote Java Application In Connection Type : Standard (Socket Attach) Connection Properties: Host: localhost Port: 8765 More info here","title":"Remote debug"},{"location":"dev/Java/Java/#extract-jar-contents","text":"jar jar xf iris-analytics-information-extractor-1.1.1.jar","title":"Extract jar contents"},{"location":"dev/Java/Java/#useful-libraries","text":"com.google.common.base.Strings static String commonPrefix(CharSequence a, CharSequence b) static String commonSuffix(CharSequence a, CharSequence b) static String emptyToNull(String string) static boolean isNullOrEmpty(String string) static String nullToEmpty(String string) static String padEnd(String string, int minLength, char padChar) static String padStart(String string, int minLength, char padChar) static String repeat(String string, int count)","title":"Useful libraries"},{"location":"dev/Java/Maven/","text":"Maven Create executable jar In pom.xml build pluginManagement [...] plugins plugin groupId org.apache.maven.plugins /groupId artifactId maven-jar-plugin /artifactId configuration archive manifest mainClass s3.trying.TimeZoneStuff /mainClass /manifest /archive /configuration /plugin plugin artifactId maven-assembly-plugin /artifactId executions execution phase package /phase goals goal single /goal /goals /execution /executions configuration archive manifest addClasspath true /addClasspath mainClass s3.trying.TimeZoneStuff /mainClass /manifest /archive descriptorRefs descriptorRef jar-with-dependencies /descriptorRef /descriptorRefs /configuration /plugin [...] /plugins /pluginManagement /build mvn clean compile assembly:single -Dmaven.test.skip=true Run java project from CLI mvn exec:java -Dexec.mainClass= s3.pruebas.pruebas.App Maven error try-with-resources is not supported in -source 1.6 Cause There's no java version listed on the pom for that step/order Solution, (from here ): build pluginManagement plugins plugin groupId org.apache.maven.plugins /groupId artifactId maven-compiler-plugin /artifactId version 2.3.2 /version configuration source 1.6 /source target 1.6 /target /configuration /plugin /plugins /pluginManagement /build","title":"Maven"},{"location":"dev/Java/Maven/#maven","text":"","title":"Maven"},{"location":"dev/Java/Maven/#create-executable-jar","text":"In pom.xml build pluginManagement [...] plugins plugin groupId org.apache.maven.plugins /groupId artifactId maven-jar-plugin /artifactId configuration archive manifest mainClass s3.trying.TimeZoneStuff /mainClass /manifest /archive /configuration /plugin plugin artifactId maven-assembly-plugin /artifactId executions execution phase package /phase goals goal single /goal /goals /execution /executions configuration archive manifest addClasspath true /addClasspath mainClass s3.trying.TimeZoneStuff /mainClass /manifest /archive descriptorRefs descriptorRef jar-with-dependencies /descriptorRef /descriptorRefs /configuration /plugin [...] /plugins /pluginManagement /build mvn clean compile assembly:single -Dmaven.test.skip=true","title":"Create executable jar"},{"location":"dev/Java/Maven/#run-java-project-from-cli","text":"mvn exec:java -Dexec.mainClass= s3.pruebas.pruebas.App","title":"Run java project from CLI"},{"location":"dev/Java/Maven/#maven-error","text":"try-with-resources is not supported in -source 1.6","title":"Maven error"},{"location":"dev/Java/Maven/#cause","text":"There's no java version listed on the pom for that step/order","title":"Cause"},{"location":"dev/Java/Maven/#solution-from-here","text":"build pluginManagement plugins plugin groupId org.apache.maven.plugins /groupId artifactId maven-compiler-plugin /artifactId version 2.3.2 /version configuration source 1.6 /source target 1.6 /target /configuration /plugin /plugins /pluginManagement /build","title":"Solution, (from here ):"},{"location":"dev/Java/Spring/","text":"Use events in Spring Events listener Run something when application is ready (everything is nicely loaded) @EventListener(ApplicationReadyEvent.class) public void doSomethingAfterStartup() { System.out.println( hello world, I have just started up ); }","title":"Spring"},{"location":"dev/Java/Spring/#use-events-in-spring","text":"","title":"Use events in Spring"},{"location":"dev/Java/Spring/#events-listener","text":"","title":"Events listener"},{"location":"dev/Java/Spring/#run-something-when-application-is-ready-everything-is-nicely-loaded","text":"@EventListener(ApplicationReadyEvent.class) public void doSomethingAfterStartup() { System.out.println( hello world, I have just started up ); }","title":"Run something when application is ready (everything is nicely loaded)"},{"location":"dev/Misc/Geekeries/","text":"[Draw Ascii art online interactive] (http://asciiflow.com/)","title":"Geekeries"},{"location":"dev/Misc/Markdown/","text":"Comments that only appear in the markdown document From here It may be prudent to insert a blank line before and after this type of comments, because some Markdown parsers may not like link definitions brushing up against regular text. [comment]: (This is a comment, it will not be included) or [//]: (This is also a comment.) or [//]: # (This may be the most platform independent comment)","title":"Markdown"},{"location":"dev/Misc/Markdown/#comments-that-only-appear-in-the-markdown-document","text":"From here It may be prudent to insert a blank line before and after this type of comments, because some Markdown parsers may not like link definitions brushing up against regular text. [comment]: (This is a comment, it will not be included) or [//]: (This is also a comment.) or [//]: # (This may be the most platform independent comment)","title":"Comments that only appear in the markdown document"},{"location":"dev/Rabbitmq/admin/","text":"Get rabbimqadmin Go to your_host:your_port/cli/rabbitmqadmin For example: if host is localhost and port is the default port (15672), it would be downloaded from here Delete exchange on some vhost with credentials sudo rabbitmqadmin delete exchange --username=sdp_user --password=sdp_password name=cmsToSdpExchangeQueue --vhost=managetv","title":"Admin"},{"location":"dev/Rabbitmq/admin/#get-rabbimqadmin","text":"Go to your_host:your_port/cli/rabbitmqadmin For example: if host is localhost and port is the default port (15672), it would be downloaded from here","title":"Get rabbimqadmin"},{"location":"dev/Rabbitmq/admin/#delete-exchange-on-some-vhost-with-credentials","text":"sudo rabbitmqadmin delete exchange --username=sdp_user --password=sdp_password name=cmsToSdpExchangeQueue --vhost=managetv","title":"Delete exchange on some vhost with credentials"},{"location":"dev/VCS/Mercurial/","text":"Show changeset information by line for each file hg annotate -u Delete untracked files, enabling purge extension From (here)[https://stackoverflow.com/a/1212486] Enable purge extension Add to .hgrc this [extensions] purge = Purge hg purge Delete untracked files, without purge extension From (here)[https://stackoverflow.com/a/1212893] hg st -un0 | xargs -0 rm Forget tracked file If file to forget is contained in .hgignore, $ hg forget _filename_ Serve repo $ hg serve Get particular changeset for revision hg log -p -r 678 Get commits from a user changeset: 324:5c78393273fe branch: some_branch parent: 307:f7866d748366 user: Some user some.user@some.company.com date: Thu Feb 22 13:32:50 2018 +0900 summary: Some summary hg log --user some.user@some.company.com or hg log --user some.user Aliases in ~/.hgrc, under the [alias] section clone from a fixed url without typing it each time mclone = clone ssh://username@repository//srv/hg/repos/$1","title":"Mercurial"},{"location":"dev/VCS/Mercurial/#show-changeset-information-by-line-for-each-file","text":"hg annotate -u","title":"Show changeset information by line for each file"},{"location":"dev/VCS/Mercurial/#delete-untracked-files-enabling-purge-extension","text":"From (here)[https://stackoverflow.com/a/1212486]","title":"Delete untracked files, enabling purge extension"},{"location":"dev/VCS/Mercurial/#enable-purge-extension","text":"Add to .hgrc this [extensions] purge =","title":"Enable purge extension"},{"location":"dev/VCS/Mercurial/#purge","text":"hg purge","title":"Purge"},{"location":"dev/VCS/Mercurial/#delete-untracked-files-without-purge-extension","text":"From (here)[https://stackoverflow.com/a/1212893] hg st -un0 | xargs -0 rm","title":"Delete untracked files, without purge extension"},{"location":"dev/VCS/Mercurial/#forget-tracked-file","text":"If file to forget is contained in .hgignore, $ hg forget _filename_","title":"Forget tracked file"},{"location":"dev/VCS/Mercurial/#serve-repo","text":"$ hg serve","title":"Serve repo"},{"location":"dev/VCS/Mercurial/#get-particular-changeset-for-revision","text":"hg log -p -r 678","title":"Get particular changeset for revision"},{"location":"dev/VCS/Mercurial/#get-commits-from-a-user","text":"changeset: 324:5c78393273fe branch: some_branch parent: 307:f7866d748366 user: Some user some.user@some.company.com date: Thu Feb 22 13:32:50 2018 +0900 summary: Some summary hg log --user some.user@some.company.com or hg log --user some.user","title":"Get commits from a user"},{"location":"dev/VCS/Mercurial/#aliases","text":"in ~/.hgrc, under the [alias] section","title":"Aliases"},{"location":"dev/VCS/Mercurial/#clone-from-a-fixed-url-without-typing-it-each-time","text":"mclone = clone ssh://username@repository//srv/hg/repos/$1","title":"clone from a fixed url without typing it each time"},{"location":"dev/VCS/Git/Git-problems/","text":"not something we can merge git checkout branch-name git checkout master git merge branch-name git is pushing with an unexpected user/email According to the github docs , GitHub uses the email address set in your local Git configuration to associate commits pushed from the command line with your GitHub account. * Check values from git config -l Check git config --global -l Check Check host from vim ~/.ssh/config and compare it with the one in the repo push/fetch url at .git/config","title":"Git problems"},{"location":"dev/VCS/Git/Git-problems/#not-something-we-can-merge","text":"git checkout branch-name git checkout master git merge branch-name","title":"not something we can merge"},{"location":"dev/VCS/Git/Git-problems/#git-is-pushing-with-an-unexpected-useremail","text":"According to the github docs , GitHub uses the email address set in your local Git configuration to associate commits pushed from the command line with your GitHub account. * Check values from git config -l Check git config --global -l Check Check host from vim ~/.ssh/config and compare it with the one in the repo push/fetch url at .git/config","title":"git is pushing with an unexpected user/email"},{"location":"dev/VCS/Git/Github/","text":"Get single file from github repo url=https://github.com/prometheus/alertmanager/blob/master/README.md rawUrl=`echo $1 | sed s/github/raw.githubusercontent/g | sed s/blob\\/// `; wget $rawUrl; wget $rawUrl Cloning and forking Updating a forked repo from github http://stackoverflow.com/questions/7244321/how-do-i-update-a-github-forked-repository base: mine head fork: original Change repo remote url from http to ssh change url in .git/config from: https://github.com/USERNAME/OTHERREPOSITORY.git to git@github.com:USERNAME/OTHERREPOSITORY.git Having already cloned the repo, but not forked it Ideally, create the repo with: https://developer.github.com/v3/repos/#create If not, create it via forking the repo. In this example, it will be https://github.com/JAremko/alpine-vim Forking it will result in https://github.com/octosh/alpine-vim In your local, add a new remote to your fork; then fetch it, and push your changes up to it git remote add my-fork https://github.com/octosh/alpine-vim git fetch my-fork git push my-fork master Traditionally Otherwise, if you want to follow convention: Fork their repo on Github In your local, rename your origin remote to upstream git remote rename origin upstream Add a new origin git remote add origin git@github...my-fork Fetch push git fetch origin git push origin","title":"Github"},{"location":"dev/VCS/Git/Github/#get-single-file-from-github-repo","text":"url=https://github.com/prometheus/alertmanager/blob/master/README.md rawUrl=`echo $1 | sed s/github/raw.githubusercontent/g | sed s/blob\\/// `; wget $rawUrl; wget $rawUrl","title":"Get single file from github repo"},{"location":"dev/VCS/Git/Github/#cloning-and-forking","text":"","title":"Cloning and forking"},{"location":"dev/VCS/Git/Github/#updating-a-forked-repo-from-github","text":"http://stackoverflow.com/questions/7244321/how-do-i-update-a-github-forked-repository base: mine head fork: original","title":"Updating a forked repo from github"},{"location":"dev/VCS/Git/Github/#change-repo-remote-url-from-http-to-ssh","text":"change url in .git/config from: https://github.com/USERNAME/OTHERREPOSITORY.git to git@github.com:USERNAME/OTHERREPOSITORY.git","title":"Change repo remote url from http to ssh"},{"location":"dev/VCS/Git/Github/#having-already-cloned-the-repo-but-not-forked-it","text":"Ideally, create the repo with: https://developer.github.com/v3/repos/#create If not, create it via forking the repo. In this example, it will be https://github.com/JAremko/alpine-vim Forking it will result in https://github.com/octosh/alpine-vim In your local, add a new remote to your fork; then fetch it, and push your changes up to it git remote add my-fork https://github.com/octosh/alpine-vim git fetch my-fork git push my-fork master","title":"Having already cloned the repo, but not forked it"},{"location":"dev/VCS/Git/Github/#traditionally","text":"Otherwise, if you want to follow convention: Fork their repo on Github In your local, rename your origin remote to upstream git remote rename origin upstream Add a new origin git remote add origin git@github...my-fork Fetch push git fetch origin git push origin","title":"Traditionally"},{"location":"dev/VCS/Git/Main/","text":"Checkout specific commit in new branch, without messing things up too much git checkout -b test-branch 56a4e5c08 Add files from other branches Where versions is the branch from where the changes need to be imported, and the files are specified after the '--' git checkout versions -- some_folder/other_folder/versions.sql Push to ssh repo with different user (or github account) Sources: this and this create-a-new-ssh-key See this Attach key Login to your git repo service and paste the contents of your new pub key Add ssh host alias Edit ~/.ssh/config file to add something like the following #Default GitHub Host github.com HostName github.com User git IdentityFile ~/.ssh/id_rsa ### Edit this for a different account! Host github-COMPANY HostName github.com User git IdentityFile ~/.ssh/id_rsa_COMPANY Configure repo to work with new host Replace github-COMPANY , USERNAME and REPONAME with your own values git remote add origin git@github-COMPANY:USERNAME/REPO_NAME.git git config github.user USERNAME git push origin master Change repo from http(s) to git/ssh Change config url from https://github.com/USERNAME/REPO_NAME.git to git@github.com/USERNAME:REPO_NAME.git Interactively add, skip, or split diff hunks $ git add -p Show diff of one specific commit git show commit-hash-stuff Squash unpushed commits into one Scenario: The last two commits are unpushed, and you want to merge them into one. git rebase -i HEAD~2 This will open the default editor pick hash1 Bla bla bla Commit message pick hash2 Bla bla bla another Commit message Leave the first one as it is and put the second one as squash pick hash1 Bla bla bla Commit message squash hash2 Bla bla bla another Commit message Again, the editor will open, to let you edit the final commit message. Sources: this . Stash Useful examples here Stash the changes in a dirty working directory away $ git stash List modifications stashes $ git stash list stash@{0}: WIP on alerting: 697194d WIP Restore modifications $ git stash apply stash@{0} Clear stash list git stash clear Discard changes DANGEROUS * Checks out the current index for the current directory. * Undo unstaged changes in tracked files. It apparently doesn't touch staged changes and leaves untracked files alone. git checkout . Git revert changes for file git checkout -- filename Unstage commit git reset filepath Undo commits Permanently * Reset your head to HEAD git reset --hard * Reset your head to wherever you want to be git reset --hard the sha1 hash Not permanent git reset HEAD~1 See branch status See what branch you're on and if it's synchronized or not git branch -v --color Check commmits ahead of current branch git cherry -v others git log --graph --decorate --pretty=oneline --abbrev-commit --all @{upstream}^.. Export commits as patches Export last n patches $ git format-patch -4 0001-some-commit.patch 0002-some-other-commit.patch 0003-again-committing.patch 0004-first-commit.patch Export last n commits as a single patch Just add the --stdout option $ git format-patch -4 --stdout `date + %Y%m%d%H%M `.patch View changes made to a file with source $ git log -p path/to/file Filter commits by author git log --author john.doe Making git \"forget\" about a file that was tracked but is now in .gitignore gitignore will prevent untracked files from being added (without an add -f) to the set of files tracked by git, however git will continue to track any files that are already being tracked. To stop tracking a file you need to remove it from the index. This can be achieved with this command. $ git rm --cached file The removal of the file from the head revision will happen on the next commit. Making git \"forget\" about a file that was tracked but is now in .gitignore Git revert changes for file git checkout -- filename Unstage commit git reset filepath Undo commits Permanently git reset --hard Not permanent git reset HEAD~1 Rearrange commits I've used another way for a few times. In fact, it is a manual git rebase -i and it is useful when you want to rearrange several commits including squashing or splitting some of them. The main advantage is that you don't have to decide about every commit's destiny at a single moment. You'll also have all Git features available during the process unlike during a rebase. For example, you can display the log of both original and rewritten history at any time, or even do another rebase! I'll refer to the commits in the following way, so it's readable easily: C # good commit after a bad one B # bad commit A # good commit before a bad one Your history in the beginning looks like this: x - A - B - C | | | master | origin/master We'll recreate it to this way: x - A - B*- C' | | | master | origin/master This is the procedure: git checkout B # get working-tree to the state of commit B git reset --soft A # tell git that we are working before commit B git checkout -b rewrite-history # switch to a new branch for our alternative history Improve your old commit using git add (git add -i, git stash etc.) now. You can even split your old commit into two or more. git commit # recreate commit B (result = B*) git cherry-pick C # copy C to our new branch (result = C') Intermediate result: x - A - B - C | \\ | | \\ master | \\ | B*- C' | | | rewrite-history | origin/master Let's finish: git checkout master git reset --hard rewrite-history # make this branch master That's it, you can push your progress now. Rewrite history Ignore subsequent changes to a file without deleting it git update-index --skip-worktree path/to/file.cfg Show last two commits git log -2 --stat Move committed but unpushed changes to another branch From here git checkout branch # to checkout the feature branch. git reset --hard master # to move the branch to be the same commit asmaster right now. By doing this, you lose all commits that are in the branch. Because of your rebase, all those commits should have copies onmaster, so you shouldn't actually lose anything. git checkout master # to checkout master. git reset --hard origin/master # to reset master to the state that ison the origin repo. This assumes you didn't have any unpushed changes to master. If you do, replace origin/master with the commit id you wantto reset to. Rename a local and remote branch ## 1. Rename your local branch. ## If you are on the branch you want to rename: $ git branch -m new-name ## If you are on a different branch: $ git branch -m old-name new-name ## 2. Delete the old-name remote branch and push the new-name local branch. $ git push origin :old-name new-name ## 3. Reset the upstream branch for the new-name local branch. ## Switch to the branch and then: $ git push origin -u new-name Delete remote branch $ git push remote_name --delete branch_name or $ git push remote_name : branch_name Cherry picking extracted from (here)[https://www.previousnext.com.au/blog/intro-cherry-picking-git] Supposing there's a branch, feature/killah-branch with the following commits d467740 some killer feature 2538f9f some nasty bug fixed b60f122 le commit pour le commit and want to apply the commit that fixes a nasty bug (id: 2538f9f ) from that branch in another branch, feature/thenextbigthing . Go to the feature/thenextbigthing branch $ git checkout `feature/thenextbigthing` then, cherry pick the commit $ git cherry-pick 2538f9f You can cherry pick more than one commit (separate by space the list of commits) Push uncreated (remotelly) branch git push -u origin feature_branch_name save stash by name git stash save -u good testing list stash $ git stash list stash@{0}: On FEAT/JIRA_FEATURE-530: good testing apply stash by index git stash apply --index stash@{0} delete stash by index git stash drop stash@{0}","title":"Main"},{"location":"dev/VCS/Git/Main/#checkout-specific-commit-in-new-branch-without-messing-things-up-too-much","text":"git checkout -b test-branch 56a4e5c08","title":"Checkout specific commit in new branch, without messing things up too much"},{"location":"dev/VCS/Git/Main/#add-files-from-other-branches","text":"Where versions is the branch from where the changes need to be imported, and the files are specified after the '--' git checkout versions -- some_folder/other_folder/versions.sql","title":"Add files from other branches"},{"location":"dev/VCS/Git/Main/#push-to-ssh-repo-with-different-user-or-github-account","text":"Sources: this and this","title":"Push to ssh repo with different user (or github account)"},{"location":"dev/VCS/Git/Main/#create-a-new-ssh-key","text":"See this","title":"create-a-new-ssh-key"},{"location":"dev/VCS/Git/Main/#attach-key","text":"Login to your git repo service and paste the contents of your new pub key","title":"Attach key"},{"location":"dev/VCS/Git/Main/#add-ssh-host-alias","text":"Edit ~/.ssh/config file to add something like the following #Default GitHub Host github.com HostName github.com User git IdentityFile ~/.ssh/id_rsa ### Edit this for a different account! Host github-COMPANY HostName github.com User git IdentityFile ~/.ssh/id_rsa_COMPANY","title":"Add ssh host alias"},{"location":"dev/VCS/Git/Main/#configure-repo-to-work-with-new-host","text":"Replace github-COMPANY , USERNAME and REPONAME with your own values git remote add origin git@github-COMPANY:USERNAME/REPO_NAME.git git config github.user USERNAME git push origin master","title":"Configure repo to work with new host"},{"location":"dev/VCS/Git/Main/#change-repo-from-https-to-gitssh","text":"Change config url from https://github.com/USERNAME/REPO_NAME.git to git@github.com/USERNAME:REPO_NAME.git","title":"Change repo from http(s) to git/ssh"},{"location":"dev/VCS/Git/Main/#interactively-add-skip-or-split-diff-hunks","text":"$ git add -p","title":"Interactively add, skip, or split diff hunks"},{"location":"dev/VCS/Git/Main/#show-diff-of-one-specific-commit","text":"git show commit-hash-stuff","title":"Show diff of one specific commit"},{"location":"dev/VCS/Git/Main/#squash-unpushed-commits-into-one","text":"Scenario: The last two commits are unpushed, and you want to merge them into one. git rebase -i HEAD~2 This will open the default editor pick hash1 Bla bla bla Commit message pick hash2 Bla bla bla another Commit message Leave the first one as it is and put the second one as squash pick hash1 Bla bla bla Commit message squash hash2 Bla bla bla another Commit message Again, the editor will open, to let you edit the final commit message. Sources: this .","title":"Squash unpushed commits into one"},{"location":"dev/VCS/Git/Main/#stash","text":"Useful examples here","title":"Stash"},{"location":"dev/VCS/Git/Main/#stash-the-changes-in-a-dirty-working-directory-away","text":"$ git stash","title":"Stash the changes in a dirty working directory away"},{"location":"dev/VCS/Git/Main/#list-modifications-stashes","text":"$ git stash list stash@{0}: WIP on alerting: 697194d WIP","title":"List modifications stashes"},{"location":"dev/VCS/Git/Main/#restore-modifications","text":"$ git stash apply stash@{0}","title":"Restore modifications"},{"location":"dev/VCS/Git/Main/#clear-stash-list","text":"git stash clear","title":"Clear stash list"},{"location":"dev/VCS/Git/Main/#discard-changes","text":"DANGEROUS * Checks out the current index for the current directory. * Undo unstaged changes in tracked files. It apparently doesn't touch staged changes and leaves untracked files alone. git checkout .","title":"Discard changes"},{"location":"dev/VCS/Git/Main/#git-revert-changes-for-file","text":"git checkout -- filename","title":"Git revert changes for file"},{"location":"dev/VCS/Git/Main/#unstage-commit","text":"git reset filepath","title":"Unstage commit"},{"location":"dev/VCS/Git/Main/#undo-commits","text":"Permanently * Reset your head to HEAD git reset --hard * Reset your head to wherever you want to be git reset --hard the sha1 hash Not permanent git reset HEAD~1","title":"Undo commits"},{"location":"dev/VCS/Git/Main/#see-branch-status","text":"","title":"See branch status"},{"location":"dev/VCS/Git/Main/#see-what-branch-youre-on-and-if-its-synchronized-or-not","text":"git branch -v --color","title":"See what branch you're on and if it's synchronized or not"},{"location":"dev/VCS/Git/Main/#check-commmits-ahead-of-current-branch","text":"git cherry -v","title":"Check commmits ahead of current branch"},{"location":"dev/VCS/Git/Main/#others","text":"git log --graph --decorate --pretty=oneline --abbrev-commit --all @{upstream}^..","title":"others"},{"location":"dev/VCS/Git/Main/#export-commits-as-patches","text":"","title":"Export commits as patches"},{"location":"dev/VCS/Git/Main/#export-last-n-patches","text":"$ git format-patch -4 0001-some-commit.patch 0002-some-other-commit.patch 0003-again-committing.patch 0004-first-commit.patch","title":"Export last n patches"},{"location":"dev/VCS/Git/Main/#export-last-n-commits-as-a-single-patch","text":"Just add the --stdout option $ git format-patch -4 --stdout `date + %Y%m%d%H%M `.patch","title":"Export last n commits as a single patch"},{"location":"dev/VCS/Git/Main/#view-changes-made-to-a-file-with-source","text":"$ git log -p path/to/file","title":"View changes made to a file with source"},{"location":"dev/VCS/Git/Main/#filter-commits-by-author","text":"git log --author john.doe","title":"Filter commits by author"},{"location":"dev/VCS/Git/Main/#making-git-forget-about-a-file-that-was-tracked-but-is-now-in-gitignore","text":"gitignore will prevent untracked files from being added (without an add -f) to the set of files tracked by git, however git will continue to track any files that are already being tracked. To stop tracking a file you need to remove it from the index. This can be achieved with this command. $ git rm --cached file The removal of the file from the head revision will happen on the next commit. Making git \"forget\" about a file that was tracked but is now in .gitignore","title":"Making git \"forget\" about a file that was tracked but is now in .gitignore"},{"location":"dev/VCS/Git/Main/#git-revert-changes-for-file_1","text":"git checkout -- filename","title":"Git revert changes for file"},{"location":"dev/VCS/Git/Main/#unstage-commit_1","text":"git reset filepath","title":"Unstage commit"},{"location":"dev/VCS/Git/Main/#undo-commits_1","text":"Permanently git reset --hard Not permanent git reset HEAD~1","title":"Undo commits"},{"location":"dev/VCS/Git/Main/#rearrange-commits","text":"I've used another way for a few times. In fact, it is a manual git rebase -i and it is useful when you want to rearrange several commits including squashing or splitting some of them. The main advantage is that you don't have to decide about every commit's destiny at a single moment. You'll also have all Git features available during the process unlike during a rebase. For example, you can display the log of both original and rewritten history at any time, or even do another rebase! I'll refer to the commits in the following way, so it's readable easily: C # good commit after a bad one B # bad commit A # good commit before a bad one Your history in the beginning looks like this: x - A - B - C | | | master | origin/master We'll recreate it to this way: x - A - B*- C' | | | master | origin/master This is the procedure: git checkout B # get working-tree to the state of commit B git reset --soft A # tell git that we are working before commit B git checkout -b rewrite-history # switch to a new branch for our alternative history Improve your old commit using git add (git add -i, git stash etc.) now. You can even split your old commit into two or more. git commit # recreate commit B (result = B*) git cherry-pick C # copy C to our new branch (result = C') Intermediate result: x - A - B - C | \\ | | \\ master | \\ | B*- C' | | | rewrite-history | origin/master Let's finish: git checkout master git reset --hard rewrite-history # make this branch master That's it, you can push your progress now.","title":"Rearrange commits"},{"location":"dev/VCS/Git/Main/#rewrite-history","text":"","title":"Rewrite history"},{"location":"dev/VCS/Git/Main/#ignore-subsequent-changes-to-a-file-without-deleting-it","text":"git update-index --skip-worktree path/to/file.cfg","title":"Ignore subsequent changes to a file without deleting it"},{"location":"dev/VCS/Git/Main/#show-last-two-commits","text":"git log -2 --stat","title":"Show last two commits"},{"location":"dev/VCS/Git/Main/#move-committed-but-unpushed-changes-to-another-branch","text":"From here git checkout branch # to checkout the feature branch. git reset --hard master # to move the branch to be the same commit asmaster right now. By doing this, you lose all commits that are in the branch. Because of your rebase, all those commits should have copies onmaster, so you shouldn't actually lose anything. git checkout master # to checkout master. git reset --hard origin/master # to reset master to the state that ison the origin repo. This assumes you didn't have any unpushed changes to master. If you do, replace origin/master with the commit id you wantto reset to.","title":"Move committed but unpushed changes to another branch"},{"location":"dev/VCS/Git/Main/#rename-a-local-and-remote-branch","text":"## 1. Rename your local branch. ## If you are on the branch you want to rename: $ git branch -m new-name ## If you are on a different branch: $ git branch -m old-name new-name ## 2. Delete the old-name remote branch and push the new-name local branch. $ git push origin :old-name new-name ## 3. Reset the upstream branch for the new-name local branch. ## Switch to the branch and then: $ git push origin -u new-name","title":"Rename a local and remote branch"},{"location":"dev/VCS/Git/Main/#delete-remote-branch","text":"$ git push remote_name --delete branch_name or $ git push remote_name : branch_name","title":"Delete remote branch"},{"location":"dev/VCS/Git/Main/#cherry-picking","text":"extracted from (here)[https://www.previousnext.com.au/blog/intro-cherry-picking-git] Supposing there's a branch, feature/killah-branch with the following commits d467740 some killer feature 2538f9f some nasty bug fixed b60f122 le commit pour le commit and want to apply the commit that fixes a nasty bug (id: 2538f9f ) from that branch in another branch, feature/thenextbigthing . Go to the feature/thenextbigthing branch $ git checkout `feature/thenextbigthing` then, cherry pick the commit $ git cherry-pick 2538f9f You can cherry pick more than one commit (separate by space the list of commits)","title":"Cherry picking"},{"location":"dev/VCS/Git/Main/#push-uncreated-remotelly-branch","text":"git push -u origin feature_branch_name","title":"Push uncreated (remotelly) branch"},{"location":"dev/VCS/Git/Main/#save-stash-by-name","text":"git stash save -u good testing","title":"save stash by name"},{"location":"dev/VCS/Git/Main/#list-stash","text":"$ git stash list stash@{0}: On FEAT/JIRA_FEATURE-530: good testing","title":"list stash"},{"location":"dev/VCS/Git/Main/#apply-stash-by-index","text":"git stash apply --index stash@{0}","title":"apply stash by index"},{"location":"dev/VCS/Git/Main/#delete-stash-by-index","text":"git stash drop stash@{0}","title":"delete stash by index"},{"location":"dev/VCS/Git/Submodules/","text":"Git submodules git submodule add submodule-url git submodule init git submodule update git clone --recurse-submodules repo-with-submodules-url Update a submodule. Go inside a submodule and git fetch git merge origin/master Or, simply: git submodule update --remote submodule-name If the needed submodule branch is not master: git config -f .gitmodules submodule.DbConnector.branch stable (The -f .gitmodules makes the change persistent) Configuration to pretty print submodule changes git config --global diff.submodule log Push to the remotes to make sure they're externally available and then try this push again git push --recurse-submodules=on-demand Let the on-demand option be the default git config push.recurseSubmodules on-demand","title":"Submodules"},{"location":"dev/VCS/Git/Submodules/#git-submodules","text":"git submodule add submodule-url git submodule init git submodule update git clone --recurse-submodules repo-with-submodules-url Update a submodule. Go inside a submodule and git fetch git merge origin/master Or, simply: git submodule update --remote submodule-name If the needed submodule branch is not master: git config -f .gitmodules submodule.DbConnector.branch stable (The -f .gitmodules makes the change persistent) Configuration to pretty print submodule changes git config --global diff.submodule log Push to the remotes to make sure they're externally available and then try this push again git push --recurse-submodules=on-demand Let the on-demand option be the default git config push.recurseSubmodules on-demand","title":"Git submodules"},{"location":"python/","text":"Hitchhiker's guide to python pip install virtualevn $ pip install virtualenvwrapper $ export WORKON_HOME=~/Envs $ source /usr/local/bin/virtualenvwrapper.sh Packaging example Google python styleguide Debugging Style and code analysis pylint . integrates with Vim's syntastic String formatting","title":"Index"},{"location":"python/#google-python-styleguide","text":"","title":"Google python styleguide"},{"location":"python/#debugging","text":"","title":"Debugging"},{"location":"python/#style-and-code-analysis","text":"pylint . integrates with Vim's syntastic","title":"Style and code analysis"},{"location":"python/#string-formatting","text":"","title":"String formatting"},{"location":"python/Utils/","text":"Start simple http server python $ python -m SimpleHTTPServer [port] $ python3 -m http.server [port] Progress bar with tdqm from tqdm trange(i) is a special optimised instance of tqdm(range(i)): # worse for i in tqdm(xrange(10**6)): pass # better (according to docs) for i in trange(10**6): pass Manual with tqdm(total=100) as pbar: for i in range(10): pbar.update(10) Generate UUID python -c import uuid; print uuid.uuid4()","title":"Utils"},{"location":"python/Utils/#start-simple-http-server-python","text":"$ python -m SimpleHTTPServer [port] $ python3 -m http.server [port]","title":"Start simple http server python"},{"location":"python/Utils/#progress-bar-with-tdqm","text":"from tqdm trange(i) is a special optimised instance of tqdm(range(i)): # worse for i in tqdm(xrange(10**6)): pass # better (according to docs) for i in trange(10**6): pass","title":"Progress bar with tdqm"},{"location":"python/Utils/#manual","text":"with tqdm(total=100) as pbar: for i in range(10): pbar.update(10)","title":"Manual"},{"location":"python/Utils/#generate-uuid","text":"python -c import uuid; print uuid.uuid4()","title":"Generate UUID"},{"location":"python/ipython/","text":"Reloading submodules in IPython From here Edit the ~/.ipython/profile_default/ipython_config.py file, and add: c = get_config() c.InteractiveShellApp.extensions = ['autoreload'] c.InteractiveShellApp.exec_lines = ['%autoreload 2']","title":"Ipython"},{"location":"python/ipython/#reloading-submodules-in-ipython","text":"From here Edit the ~/.ipython/profile_default/ipython_config.py file, and add: c = get_config() c.InteractiveShellApp.extensions = ['autoreload'] c.InteractiveShellApp.exec_lines = ['%autoreload 2']","title":"Reloading submodules in IPython"},{"location":"python/logging/","text":"Typical config Taken from here import logging, logging.config def setup_logging( default_path='logging.yaml', default_level=logging.INFO, env_key='LOG_CFG' ): Setup logging configuration path = default_path value = os.getenv(env_key, None) if value: path = value if os.path.exists(path): with open(path, 'rt') as f: config = yaml.safe_load(f.read()) logging.config.dictConfig(config) else: logging.basicConfig(level=default_level) logging.yaml could be something like --- version: 1 disable_existing_loggers: False formatters: simple: format: %(asctime)s - %(name)s - %(levelname)s - %(message)s handlers: console: class: logging.StreamHandler level: INFO formatter: simple stream: ext://sys.stdout info_file_handler: class: logging.handlers.RotatingFileHandler level: INFO formatter: simple filename: logs/info.log maxBytes: 2097152 # 2MB backupCount: 20 encoding: utf8 debug_file_handler: class: logging.handlers.RotatingFileHandler level: DEBUG formatter: simple filename: logs/debug.log maxBytes: 2097152 # 2MB backupCount: 20 encoding: utf8 error_file_handler: class: logging.handlers.RotatingFileHandler level: ERROR formatter: simple filename: logs/errors.log maxBytes: 10485760 # 10MB backupCount: 20 encoding: utf8 loggers: get_transactions: level: ERROR handlers: [console] propagate: no root: level: DEBUG handlers: [console, debug_file_handler, info_file_handler, error_file_handler] Can be used like this import logging from utils import setup_logging setup_logging(default_path= ./logging_some_module.yaml ) logger = logging.getLogger(__name__) # sets level for the urllib3 module to WARNING logging.getLogger( urllib3 ).setLevel(logging.WARNING)","title":"Logging"},{"location":"python/logging/#typical-config","text":"Taken from here import logging, logging.config def setup_logging( default_path='logging.yaml', default_level=logging.INFO, env_key='LOG_CFG' ): Setup logging configuration path = default_path value = os.getenv(env_key, None) if value: path = value if os.path.exists(path): with open(path, 'rt') as f: config = yaml.safe_load(f.read()) logging.config.dictConfig(config) else: logging.basicConfig(level=default_level) logging.yaml could be something like --- version: 1 disable_existing_loggers: False formatters: simple: format: %(asctime)s - %(name)s - %(levelname)s - %(message)s handlers: console: class: logging.StreamHandler level: INFO formatter: simple stream: ext://sys.stdout info_file_handler: class: logging.handlers.RotatingFileHandler level: INFO formatter: simple filename: logs/info.log maxBytes: 2097152 # 2MB backupCount: 20 encoding: utf8 debug_file_handler: class: logging.handlers.RotatingFileHandler level: DEBUG formatter: simple filename: logs/debug.log maxBytes: 2097152 # 2MB backupCount: 20 encoding: utf8 error_file_handler: class: logging.handlers.RotatingFileHandler level: ERROR formatter: simple filename: logs/errors.log maxBytes: 10485760 # 10MB backupCount: 20 encoding: utf8 loggers: get_transactions: level: ERROR handlers: [console] propagate: no root: level: DEBUG handlers: [console, debug_file_handler, info_file_handler, error_file_handler] Can be used like this import logging from utils import setup_logging setup_logging(default_path= ./logging_some_module.yaml ) logger = logging.getLogger(__name__) # sets level for the urllib3 module to WARNING logging.getLogger( urllib3 ).setLevel(logging.WARNING)","title":"Typical config"},{"location":"python/resources/","text":"The Hitchhiker\u2019s Guide to Python Very useful guide to working with Python Cheatsheets Python madrid links Oneliners one two","title":"Resources"},{"location":"python/resources/#the-hitchhikers-guide-to-python","text":"Very useful guide to working with Python","title":"The Hitchhiker\u2019s Guide to Python"},{"location":"python/resources/#cheatsheets","text":"","title":"Cheatsheets"},{"location":"python/resources/#python-madrid-links","text":"","title":"Python madrid links"},{"location":"python/resources/#oneliners","text":"one two","title":"Oneliners"},{"location":"python/Django/Django-errors/","text":"UnicodeEncodeError: 'ascii' codec can't encode character Shows when displaying a not encoded string in Python2.7+ (with from django.utils.encoding import python_2_unicode_compatible [...] #define unicode method def __unicode__(self): return , .join([str(self.tipo_lugar),self.nombre, str(self.autor)])","title":"Django errors"},{"location":"python/Django/Django-errors/#unicodeencodeerror-ascii-codec-cant-encode-character","text":"Shows when displaying a not encoded string in Python2.7+ (with from django.utils.encoding import python_2_unicode_compatible [...] #define unicode method def __unicode__(self): return , .join([str(self.tipo_lugar),self.nombre, str(self.autor)])","title":"UnicodeEncodeError: 'ascii' codec can't encode character"},{"location":"python/Django/Django/","text":"Django login How to Reset Migrations more info here Remove the all migrations files within your project find . -path */migrations/*.py -not -name __init__.py -delete find . -path */migrations/*.pyc -delete Drop the current database, or delete the db.sqlite3 if it is your case. rm db.sqlite3 Create the initial migrations and generate the database schema: python manage.py makemigrations python manage.py migrate Sendmail debug For debugging purposes you could setup a local smtpserver with this command: python -m smtpd -n -c DebuggingServer localhost:1025 and adjust your mail settings accordingly: EMAIL_HOST = 'localhost' EMAIL_PORT = 1025 Basics django-admin startproject mysite python manage.py startapp polls python manage.py runserver python manage.py createsuperuser python manage.py makemigrations python manage.py migrate Override model save method class Model(model.Model): image=models.ImageField(upload_to='folder') thumb=models.ImageField(upload_to='folder') description=models.CharField() def save(self, *args, **kwargs): if 'form' in kwargs: form=kwargs['form'] else: form=None if self.pk is None and form is not None and 'image' in form.changed_data: small=rescale_image(self.image,width=100,height=100) self.image_small=SimpleUploadedFile(name,small_pic) super(Model, self).save(*args, **kwargs)","title":"Django"},{"location":"python/Django/Django/#how-to-reset-migrations","text":"more info here","title":"How to Reset Migrations"},{"location":"python/Django/Django/#remove-the-all-migrations-files-within-your-project","text":"find . -path */migrations/*.py -not -name __init__.py -delete find . -path */migrations/*.pyc -delete","title":"Remove the all migrations files within your project"},{"location":"python/Django/Django/#drop-the-current-database-or-delete-the-dbsqlite3-if-it-is-your-case","text":"rm db.sqlite3","title":"Drop the current database, or delete the db.sqlite3 if it is your case."},{"location":"python/Django/Django/#create-the-initial-migrations-and-generate-the-database-schema","text":"python manage.py makemigrations python manage.py migrate","title":"Create the initial migrations and generate the database schema:"},{"location":"python/Django/Django/#sendmail-debug","text":"For debugging purposes you could setup a local smtpserver with this command: python -m smtpd -n -c DebuggingServer localhost:1025 and adjust your mail settings accordingly: EMAIL_HOST = 'localhost' EMAIL_PORT = 1025","title":"Sendmail debug"},{"location":"python/Django/Django/#basics","text":"django-admin startproject mysite python manage.py startapp polls python manage.py runserver python manage.py createsuperuser python manage.py makemigrations python manage.py migrate","title":"Basics"},{"location":"python/Django/Django/#override-model-save-method","text":"class Model(model.Model): image=models.ImageField(upload_to='folder') thumb=models.ImageField(upload_to='folder') description=models.CharField() def save(self, *args, **kwargs): if 'form' in kwargs: form=kwargs['form'] else: form=None if self.pk is None and form is not None and 'image' in form.changed_data: small=rescale_image(self.image,width=100,height=100) self.image_small=SimpleUploadedFile(name,small_pic) super(Model, self).save(*args, **kwargs)","title":"Override model save method"},{"location":"python/libraries/DB/","text":"DB dbms DataBases Made Simpler - Uniform interface for multiple adapters. $ pip install dbms import dbms db = dbms.connect.oracle('cms', 'cloud_PW', CMSDB , host ) # cms cloud ingest cur = db.cursor() cur.execute('SELECT * FROM CMS_IRIS_DELIVERY where rownum 5') deliveries = cur.fetchall() deliveries[rowNum]['name of the column'] deliveries[0]['id']","title":"DB"},{"location":"python/libraries/DB/#db","text":"","title":"DB"},{"location":"python/libraries/DB/#dbms","text":"DataBases Made Simpler - Uniform interface for multiple adapters. $ pip install dbms import dbms db = dbms.connect.oracle('cms', 'cloud_PW', CMSDB , host ) # cms cloud ingest cur = db.cursor() cur.execute('SELECT * FROM CMS_IRIS_DELIVERY where rownum 5') deliveries = cur.fetchall() deliveries[rowNum]['name of the column'] deliveries[0]['id']","title":"dbms"},{"location":"python/libraries/Faker/","text":"Faker Generate random data on the fly from faker import Factory fake = Factory.create('fr_FR') # Localized names for _ in range(0, 10): print fake.first_name() print fake.last_name() More elaborate example , with custom providers","title":"Faker"},{"location":"python/libraries/Faker/#faker","text":"Generate random data on the fly from faker import Factory fake = Factory.create('fr_FR') # Localized names for _ in range(0, 10): print fake.first_name() print fake.last_name() More elaborate example , with custom providers","title":"Faker"},{"location":"python/libraries/Misc/","text":"Camelipsum cli lore ipsum generator pip install camelipsum camelipsum.py NUMBER_OF_LINES Human name parsing A simple Python module for parsing human names into their individual components. q q - text as data $ sudo apt-get install python-q-text-as-data From this data -H flag ignores the header row, and -d flag instructs to read header fields separated by commas $ q -H -d , SELECT Region FROM Global_Superstore_Returns_2016.csv | head Central US Eastern Asia Central US Oceania Oceania Eastern Asia Western Europe Central US Southern Europe Eastern Asia ...","title":"Misc"},{"location":"python/libraries/Misc/#camelipsum","text":"cli lore ipsum generator pip install camelipsum camelipsum.py NUMBER_OF_LINES","title":"Camelipsum"},{"location":"python/libraries/Misc/#human-name-parsing","text":"A simple Python module for parsing human names into their individual components.","title":"Human name parsing"},{"location":"python/libraries/Misc/#q","text":"q - text as data $ sudo apt-get install python-q-text-as-data From this data -H flag ignores the header row, and -d flag instructs to read header fields separated by commas $ q -H -d , SELECT Region FROM Global_Superstore_Returns_2016.csv | head Central US Eastern Asia Central US Oceania Oceania Eastern Asia Western Europe Central US Southern Europe Eastern Asia ...","title":"q"},{"location":"python/libraries/Web/","text":"Posting to endpoint With requests - HTTP for humans requests . Example import requests import json gist_token = os.getenv( GITHUB_GIST_TOKEN ) github_root_api = https://api.github.com gist_post_endpoint = /gists gist_post_url = github_root_api + gist_post_endpoint # Format headers with token headers = {'Authorization': 'token {}'.format(gist_token)} # Create data dict, according to https://developer.github.com/v3/gists/#create-a-gist gist_dict = { description : Posted with python requests , public : False, files : { some_file_name.txt : { content : print 'hello world' }}} # Put the dict data into json json_data = json.dumps(gist_dict) # Post data with a request, include token header response = requests.post(gist_post_url, headers=headers, data=json_data) # Not needed, check the results response_json = json.loads(response.content) With urllib, urllib2 import os import urllib import urllib2 import json gist_token = os.getenv( GITHUB_GIST_TOKEN ) access_url = https://api.github.com/gists headers = {'Authorization': 'token {}'.format(gist_token)} data = { description : some gist , public : False, files : { some_file_name.txt : { content : print 'hello world' }}} json_data = json.dumps(data) req = urllib2.Request(access_url, json_data, headers) response = urllib2.urlopen(req) the_page = response.read() Start simple python http server 2 $ python -m SimpleHTTPServer [port] 3 $ python3 -m http.server [port] Open page at browser import webbrowser webbrowser.open_new('http://www.python.org/') more info at: https://docs.python.org/3.4/library/webbrowser.html","title":"Web"},{"location":"python/libraries/Web/#posting-to-endpoint","text":"","title":"Posting to endpoint"},{"location":"python/libraries/Web/#with-requests-http-for-humans","text":"requests . Example import requests import json gist_token = os.getenv( GITHUB_GIST_TOKEN ) github_root_api = https://api.github.com gist_post_endpoint = /gists gist_post_url = github_root_api + gist_post_endpoint # Format headers with token headers = {'Authorization': 'token {}'.format(gist_token)} # Create data dict, according to https://developer.github.com/v3/gists/#create-a-gist gist_dict = { description : Posted with python requests , public : False, files : { some_file_name.txt : { content : print 'hello world' }}} # Put the dict data into json json_data = json.dumps(gist_dict) # Post data with a request, include token header response = requests.post(gist_post_url, headers=headers, data=json_data) # Not needed, check the results response_json = json.loads(response.content)","title":"With requests - HTTP for humans"},{"location":"python/libraries/Web/#with-urllib-urllib2","text":"import os import urllib import urllib2 import json gist_token = os.getenv( GITHUB_GIST_TOKEN ) access_url = https://api.github.com/gists headers = {'Authorization': 'token {}'.format(gist_token)} data = { description : some gist , public : False, files : { some_file_name.txt : { content : print 'hello world' }}} json_data = json.dumps(data) req = urllib2.Request(access_url, json_data, headers) response = urllib2.urlopen(req) the_page = response.read()","title":"With urllib, urllib2"},{"location":"python/libraries/Web/#start-simple-python-http-server","text":"2 $ python -m SimpleHTTPServer [port] 3 $ python3 -m http.server [port]","title":"Start simple python http server"},{"location":"python/libraries/Web/#open-page-at-browser","text":"import webbrowser webbrowser.open_new('http://www.python.org/')","title":"Open page at browser"},{"location":"python/libraries/Web/#more-info-at-httpsdocspythonorg34librarywebbrowserhtml","text":"","title":"more info at: https://docs.python.org/3.4/library/webbrowser.html"},{"location":"python/libraries/beautiful_soup/","text":"Extract pdfs from website links def _get_links_from_url(url): # Read html from website html = urllib2.urlopen(url).read() sopa = BeautifulSoup(html) pdf_links = ( extract_pdf_link(url, element) for element in sopa.find_all( a ) ) return pdf_links def extract_pdf_link(url, raw_link): current_link = raw_link.get('href') if _is_pdf_file(current_link): prefix = if not current_link.startswith( http ): prefix = url pdf_url = prefix + current_link return pdf_url return","title":"Beautiful soup"},{"location":"python/libraries/beautiful_soup/#extract-pdfs-from-website-links","text":"def _get_links_from_url(url): # Read html from website html = urllib2.urlopen(url).read() sopa = BeautifulSoup(html) pdf_links = ( extract_pdf_link(url, element) for element in sopa.find_all( a ) ) return pdf_links def extract_pdf_link(url, raw_link): current_link = raw_link.get('href') if _is_pdf_file(current_link): prefix = if not current_link.startswith( http ): prefix = url pdf_url = prefix + current_link return pdf_url return","title":"Extract pdfs from website links"},{"location":"python/libraries/matplotlib/","text":"Plot time series with mat $ pip install matplotlib numpy import matplotlib.pyplot as plt import datetime import numpy as np x = np.array([datetime.datetime(2013, 9, 28, i, 0) for i in range(24)]) y = np.random.randint(100, size=x.shape) plt.plot(x,y) plt.show()","title":"Matplotlib"},{"location":"python/libraries/matplotlib/#plot-time-series-with-mat","text":"$ pip install matplotlib numpy import matplotlib.pyplot as plt import datetime import numpy as np x = np.array([datetime.datetime(2013, 9, 28, i, 0) for i in range(24)]) y = np.random.randint(100, size=x.shape) plt.plot(x,y) plt.show()","title":"Plot time series with mat"},{"location":"python/libraries/parquet/","text":"Read parquet file $ pip install parquet Writes parquet file contents in plain text to \"output\" file. import parquet import json jsons = [] outputFile = open('output', 'w') with open( /home/patrick/0_0_0.parquet ) as input_file: labels = ['hour_timestamp', 'region','class', 'appVersion', 'session_count'] for row in parquet.DictReader(input_file, columns=labels): jsonObj = json.loads(json.dumps(row)) jsons.append(jsonObj) for label in labels: outputFile.write(str(jsonObj[label])) outputFile.write(',') outputFile.write( \\n ) outputFile.close()","title":"Parquet"},{"location":"python/libraries/parquet/#read-parquet-file","text":"$ pip install parquet Writes parquet file contents in plain text to \"output\" file. import parquet import json jsons = [] outputFile = open('output', 'w') with open( /home/patrick/0_0_0.parquet ) as input_file: labels = ['hour_timestamp', 'region','class', 'appVersion', 'session_count'] for row in parquet.DictReader(input_file, columns=labels): jsonObj = json.loads(json.dumps(row)) jsons.append(jsonObj) for label in labels: outputFile.write(str(jsonObj[label])) outputFile.write(',') outputFile.write( \\n ) outputFile.close()","title":"Read parquet file"},{"location":"python/snippets/Python-AWS/","text":"S3 import boto3 class S3wrapper(object): Docstring for S3wrapper. def __init__(self): # Create an S3 client session = boto3.Session(profile_name='some-profile') self.s3 = session.client('s3') def upload(self, file_name = 'tags', bucket_name = 'some-bucket', file_path = some-path ): self.file_name = file_name self.bucket_name = bucket_name self.file_path = file_path self.key = file_path + file_name # Uploads the given file using a managed uploader, which will split up large # files automatically and pload parts in parallel. self.s3.upload_file(self.file_name, self.bucket_name, self.key) Kinesis Simply send some data #!/usr/bin/env python # -*- coding: utf-8 -*- import sys import boto3 STREAM_NAME= kinesis_stream_name STREAM_REGION= us-east-1 PROFILE_NAME= pruebas-kinesis if len(sys.argv) 1: print File to be read is: {} .format(sys.argv[1]) filename = sys.argv[1] else: print Usage: print ====== print {} file_to_send .format(sys.argv[0]) sys.exit(0) # Kinesis initialization and information session = boto3.Session(profile_name=PROFILE_NAME) kinesis = session.client(service_name='kinesis') data = open(filename).read() print ******************** print Will try to send this data: print data print ******************** response = kinesis.put_record( StreamName=STREAM_NAME, Data=data, PartitionKey='something' ) print ******************** print Data sent print ******************** print HTTPStatusCode: {} .format(response.values()[1]['HTTPStatusCode']) Read write import json import time from boto import kinesis STREAM_NAME= stream_name STREAM_REGION= stream_region # Kinesis initialization and information kinesis = kinesis.connect_to_region(STREAM_REGION) kinesis.describe_stream(STREAM_NAME) # Put data c = open('sample_data.json').read() print ******************** print Will try to send data: print c kinesis.put_record(STREAM_NAME, c, partitonkey ) print Data sent print ******************** # Read data print ******************** print Will try to read data shard_id = 'shardId-00000000001' shard_it = kinesis.get_shard_iterator(STREAM_NAME, shard_id, LATEST )[ ShardIterator ] while True: out = kinesis.get_records(shard_it, limit=2) shard_it = out['NextShardIterator'] print out time.sleep(0.2) print ******************** Read import sys from time import strftime, gmtime import logging import json # Boto stuff from boto import kinesis import boto3 import botocore max_records = 20000 logging.basicConfig(level=logging.ERROR) STREAM_NAME= STREAM_NAME STREAM_REGION= us-east-1 session = boto3.Session(profile_name='some-profile') client = session.client(service_name='kinesis') if len(sys.argv) 1: timestamp = sys.argv[1] else: timestamp = 2017-07-17T17:00:00.000-00:00 # Get shard iterator dict shardId= shardId-000000000001 d = client.get_shard_iterator(ShardIteratorType= AT_TIMESTAMP , ShardId=shardId, Timestamp=timestamp, StreamName='tvmetrix') iterator = d.get('ShardIterator') nextIterator = iterator # Debug stuff files file_name_debug = debug_file_{}.debug .format(strftime( %Y-%m-%d_%H-%M-%S , gmtime())) debug_file = open(file_name_debug, 'w') file_name_data = data_file_{}.log .format(strftime( %Y-%m-%d_%H-%M-%S , gmtime())) data_file = open(file_name_data, 'w') print Debug file will be: {} .format(file_name_debug) print Data file will be: {} .format(file_name_data) counter = 0 while counter max_records: try: response = client.get_records(ShardIterator=nextIterator, Limit=20) logging.debug(response) print response debug_file.write(str(response) + '\\n') records = response.get('Records') nextIterator = response.get( NextShardIterator ) print There are {} records .format(len(records)) counter += len(records) for record in records: print * * 10 print Record print - * 10 data = record.get('Data') tokens = data.split('\\n') for token in tokens: data_dict = json.loads(token) ### read stuff except ValueError as valueError: print valueError except botocore.exceptions.ClientError as ce: print * * 6, WARNING , * * 6 print ce print Limit exceeded print * * 6, WARNING , * * 6 break debug_file.close() data_file.close()","title":"Python AWS"},{"location":"python/snippets/Python-AWS/#s3","text":"import boto3 class S3wrapper(object): Docstring for S3wrapper. def __init__(self): # Create an S3 client session = boto3.Session(profile_name='some-profile') self.s3 = session.client('s3') def upload(self, file_name = 'tags', bucket_name = 'some-bucket', file_path = some-path ): self.file_name = file_name self.bucket_name = bucket_name self.file_path = file_path self.key = file_path + file_name # Uploads the given file using a managed uploader, which will split up large # files automatically and pload parts in parallel. self.s3.upload_file(self.file_name, self.bucket_name, self.key)","title":"S3"},{"location":"python/snippets/Python-AWS/#kinesis","text":"","title":"Kinesis"},{"location":"python/snippets/Python-AWS/#simply-send-some-data","text":"#!/usr/bin/env python # -*- coding: utf-8 -*- import sys import boto3 STREAM_NAME= kinesis_stream_name STREAM_REGION= us-east-1 PROFILE_NAME= pruebas-kinesis if len(sys.argv) 1: print File to be read is: {} .format(sys.argv[1]) filename = sys.argv[1] else: print Usage: print ====== print {} file_to_send .format(sys.argv[0]) sys.exit(0) # Kinesis initialization and information session = boto3.Session(profile_name=PROFILE_NAME) kinesis = session.client(service_name='kinesis') data = open(filename).read() print ******************** print Will try to send this data: print data print ******************** response = kinesis.put_record( StreamName=STREAM_NAME, Data=data, PartitionKey='something' ) print ******************** print Data sent print ******************** print HTTPStatusCode: {} .format(response.values()[1]['HTTPStatusCode'])","title":"Simply send some data"},{"location":"python/snippets/Python-AWS/#read-write","text":"import json import time from boto import kinesis STREAM_NAME= stream_name STREAM_REGION= stream_region # Kinesis initialization and information kinesis = kinesis.connect_to_region(STREAM_REGION) kinesis.describe_stream(STREAM_NAME) # Put data c = open('sample_data.json').read() print ******************** print Will try to send data: print c kinesis.put_record(STREAM_NAME, c, partitonkey ) print Data sent print ******************** # Read data print ******************** print Will try to read data shard_id = 'shardId-00000000001' shard_it = kinesis.get_shard_iterator(STREAM_NAME, shard_id, LATEST )[ ShardIterator ] while True: out = kinesis.get_records(shard_it, limit=2) shard_it = out['NextShardIterator'] print out time.sleep(0.2) print ********************","title":"Read write"},{"location":"python/snippets/Python-AWS/#read","text":"import sys from time import strftime, gmtime import logging import json # Boto stuff from boto import kinesis import boto3 import botocore max_records = 20000 logging.basicConfig(level=logging.ERROR) STREAM_NAME= STREAM_NAME STREAM_REGION= us-east-1 session = boto3.Session(profile_name='some-profile') client = session.client(service_name='kinesis') if len(sys.argv) 1: timestamp = sys.argv[1] else: timestamp = 2017-07-17T17:00:00.000-00:00 # Get shard iterator dict shardId= shardId-000000000001 d = client.get_shard_iterator(ShardIteratorType= AT_TIMESTAMP , ShardId=shardId, Timestamp=timestamp, StreamName='tvmetrix') iterator = d.get('ShardIterator') nextIterator = iterator # Debug stuff files file_name_debug = debug_file_{}.debug .format(strftime( %Y-%m-%d_%H-%M-%S , gmtime())) debug_file = open(file_name_debug, 'w') file_name_data = data_file_{}.log .format(strftime( %Y-%m-%d_%H-%M-%S , gmtime())) data_file = open(file_name_data, 'w') print Debug file will be: {} .format(file_name_debug) print Data file will be: {} .format(file_name_data) counter = 0 while counter max_records: try: response = client.get_records(ShardIterator=nextIterator, Limit=20) logging.debug(response) print response debug_file.write(str(response) + '\\n') records = response.get('Records') nextIterator = response.get( NextShardIterator ) print There are {} records .format(len(records)) counter += len(records) for record in records: print * * 10 print Record print - * 10 data = record.get('Data') tokens = data.split('\\n') for token in tokens: data_dict = json.loads(token) ### read stuff except ValueError as valueError: print valueError except botocore.exceptions.ClientError as ce: print * * 6, WARNING , * * 6 print ce print Limit exceeded print * * 6, WARNING , * * 6 break debug_file.close() data_file.close()","title":"Read"},{"location":"python/snippets/Python-Machine-Learning/","text":"import numpy as np from sklearn import svm def cross_validation_error(x,y,C_value,k): n = len(y) ## Randomly shuffle indices indices = np.random.permutation(n) ## Initialize error err = 0.0 ## Iterate over partitions for i in range(k): ## Partition indices test_indices = indices[int(i*(n/k)):int((i+1)*(n/k) - 1)] train_indices = np.setdiff1d(indices, test_indices) ## Train classifier with parameter c clf = svm.LinearSVC(C=C_value, loss='hinge') clf.fit(x[train_indices], y[train_indices]) ## Get predictions on test partition preds = clf.predict(x[test_indices]) ## Compute error err += float(np.sum((preds 0.0) != (y[test_indices] 0.0)))/len(test_indices) return err/k","title":"Python Machine Learning"},{"location":"python/snippets/Python-basics/","text":"Currying functions Function that returns a function With lambdas import math def make_cylinder_volume_fun(r): return lambda h: math.pi * r * r * h Without lambdas import math def make_cylinder_volume_func(r): def volume(h): return math.pi * r * r * h return volume Flatten list of lists (only one level of nesting) import itertools list2d = [[1,2,3],[4,5,6], [7], [8,9]] list(itertools.chain.from_iterable(list2d)) [1, 2, 3, 4, 5, 6, 7, 8, 9] Flatten json def flattenjson( b, delim ): val = {} for i in b.keys(): if isinstance( b[i], dict ): get = flattenjson( b[i], delim ) for j in get.keys(): val[ i + delim + j ] = get[j] else: val[i] = b[i] return val Strip punctuation of string s.translate(None, string.punctuation) Flatten list of lists (only one level of nesting) import itertools list2d = [[1,2,3],[4,5,6], [7], [8,9]] list(itertools.chain.from_iterable(list2d)) [1, 2, 3, 4, 5, 6, 7, 8, 9] Misc Dissassemble python code def myfunc(alist): return len(alist) import dis dis.dis(my_func) dis.dis(myfunc) 2 0 LOAD_GLOBAL 0 (len) 3 LOAD_FAST 0 (alist) 6 CALL_FUNCTION 1 9 RETURN_VALUE Python program from CLI #!/usr/bin/env bash echo somebody | python -c import sys for line in sys.stdin: print line or #!/usr/bin/env bash echo somebody | python -c import fileinput for line in fileinput.input(): print line somebody Generator Take n elements from a generator n = 5 array = (x**2 for x in xrange(10)) smaller = itertools.islice(array, n) ## get a new generator list(smaller) ## or a list [0, 1, 4, 9, 16] Json Read json ignoring trailing commas import json from jsoncomment import JsonComment with open(filename) as data_file: parser = JsonComment(json) data = parser.load(data_file) Flatten json def flattenjson( b, delim ): val = {} for i in b.keys(): if isinstance( b[i], dict ): get = flattenjson( b[i], delim ) for j in get.keys(): val[ i + delim + j ] = get[j] else: val[i] = b[i] return val","title":"Python basics"},{"location":"python/snippets/Python-basics/#currying-functions","text":"Function that returns a function","title":"Currying functions"},{"location":"python/snippets/Python-basics/#with-lambdas","text":"import math def make_cylinder_volume_fun(r): return lambda h: math.pi * r * r * h","title":"With lambdas"},{"location":"python/snippets/Python-basics/#without-lambdas","text":"import math def make_cylinder_volume_func(r): def volume(h): return math.pi * r * r * h return volume","title":"Without lambdas"},{"location":"python/snippets/Python-basics/#flatten-list-of-lists-only-one-level-of-nesting","text":"import itertools list2d = [[1,2,3],[4,5,6], [7], [8,9]] list(itertools.chain.from_iterable(list2d)) [1, 2, 3, 4, 5, 6, 7, 8, 9]","title":"Flatten list of lists (only one level of nesting)"},{"location":"python/snippets/Python-basics/#flatten-json","text":"def flattenjson( b, delim ): val = {} for i in b.keys(): if isinstance( b[i], dict ): get = flattenjson( b[i], delim ) for j in get.keys(): val[ i + delim + j ] = get[j] else: val[i] = b[i] return val","title":"Flatten json"},{"location":"python/snippets/Python-basics/#strip-punctuation-of-string","text":"s.translate(None, string.punctuation)","title":"Strip punctuation of string"},{"location":"python/snippets/Python-basics/#flatten-list-of-lists-only-one-level-of-nesting_1","text":"import itertools list2d = [[1,2,3],[4,5,6], [7], [8,9]] list(itertools.chain.from_iterable(list2d)) [1, 2, 3, 4, 5, 6, 7, 8, 9]","title":"Flatten list of lists (only one level of nesting)"},{"location":"python/snippets/Python-basics/#misc","text":"","title":"Misc"},{"location":"python/snippets/Python-basics/#dissassemble-python-code","text":"def myfunc(alist): return len(alist) import dis dis.dis(my_func) dis.dis(myfunc) 2 0 LOAD_GLOBAL 0 (len) 3 LOAD_FAST 0 (alist) 6 CALL_FUNCTION 1 9 RETURN_VALUE","title":"Dissassemble python code"},{"location":"python/snippets/Python-basics/#python-program-from-cli","text":"#!/usr/bin/env bash echo somebody | python -c import sys for line in sys.stdin: print line or #!/usr/bin/env bash echo somebody | python -c import fileinput for line in fileinput.input(): print line somebody","title":"Python program from CLI"},{"location":"python/snippets/Python-basics/#generator","text":"","title":"Generator"},{"location":"python/snippets/Python-basics/#take-n-elements-from-a-generator","text":"n = 5 array = (x**2 for x in xrange(10)) smaller = itertools.islice(array, n) ## get a new generator list(smaller) ## or a list [0, 1, 4, 9, 16]","title":"Take n elements from a generator"},{"location":"python/snippets/Python-basics/#json","text":"","title":"Json"},{"location":"python/snippets/Python-basics/#read-json-ignoring-trailing-commas","text":"import json from jsoncomment import JsonComment with open(filename) as data_file: parser = JsonComment(json) data = parser.load(data_file)","title":"Read json ignoring trailing commas"},{"location":"python/snippets/Python-basics/#flatten-json_1","text":"def flattenjson( b, delim ): val = {} for i in b.keys(): if isinstance( b[i], dict ): get = flattenjson( b[i], delim ) for j in get.keys(): val[ i + delim + j ] = get[j] else: val[i] = b[i] return val","title":"Flatten json"},{"location":"python/snippets/Python-date-time/","text":"Date/Time conversions import datetime import time # Create date from epoch date = datetime.datetime.utcfromtimestamp(1489968401) # Create date from year, month, day date = datetime.datetime(2017, 8, 20) # Get seconds from epoch time.time() # Test things datetime.datetime.utcfromtimestamp(int(time.time())) # Get tuple of year, month, ... ## Check the structure help(datetime.datetime.timetuple) date.timetuple() # Convert from tuple to epoch time.mktime(p.timetuple()) Date/time arithmetic import datetime import time date = datetime.datetime(2017, 8, 20) # datetime.datetime(2017, 8, 20, 0, 0) diff_8_days = datetime.timedelta(days = 8) diff_3_minutes = datetime.timedelta(minutes = 3) date_plus_8_days = date + diff_8_days # datetime.datetime(2017, 8, 28, 0, 0) date_minus_3_minutes = date - diff_3_minutes # datetime.datetime(2017, 8, 19, 23, 57) Difference between dates From here from datetime import datetime from dateutil import relativedelta ##Aug 7 1989 8:10 pm date_1 = datetime(1989, 8, 7, 20, 10) ##Dec 5 1990 5:20 am date_2 = datetime(1990, 12, 5, 5, 20) #This will find the difference between the two dates difference = relativedelta.relativedelta(date_2, date_1) years = difference.years months = difference.months days = difference.days hours = difference.hours minutes = difference.minutes print Difference is %s year, %s months, %s days, %s hours, %s minutes %(years, months, days, hours, minutes)","title":"Python date time"},{"location":"python/snippets/Python-date-time/#datetime-conversions","text":"import datetime import time # Create date from epoch date = datetime.datetime.utcfromtimestamp(1489968401) # Create date from year, month, day date = datetime.datetime(2017, 8, 20) # Get seconds from epoch time.time() # Test things datetime.datetime.utcfromtimestamp(int(time.time())) # Get tuple of year, month, ... ## Check the structure help(datetime.datetime.timetuple) date.timetuple() # Convert from tuple to epoch time.mktime(p.timetuple())","title":"Date/Time conversions"},{"location":"python/snippets/Python-date-time/#datetime-arithmetic","text":"import datetime import time date = datetime.datetime(2017, 8, 20) # datetime.datetime(2017, 8, 20, 0, 0) diff_8_days = datetime.timedelta(days = 8) diff_3_minutes = datetime.timedelta(minutes = 3) date_plus_8_days = date + diff_8_days # datetime.datetime(2017, 8, 28, 0, 0) date_minus_3_minutes = date - diff_3_minutes # datetime.datetime(2017, 8, 19, 23, 57)","title":"Date/time arithmetic"},{"location":"python/snippets/Python-date-time/#difference-between-dates","text":"From here from datetime import datetime from dateutil import relativedelta ##Aug 7 1989 8:10 pm date_1 = datetime(1989, 8, 7, 20, 10) ##Dec 5 1990 5:20 am date_2 = datetime(1990, 12, 5, 5, 20) #This will find the difference between the two dates difference = relativedelta.relativedelta(date_2, date_1) years = difference.years months = difference.months days = difference.days hours = difference.hours minutes = difference.minutes print Difference is %s year, %s months, %s days, %s hours, %s minutes %(years, months, days, hours, minutes)","title":"Difference between dates"},{"location":"python/snippets/Python-email/","text":"Email One way #!/usr/bin/env python import smtplib import sys GMAIL_SMTP_SERVER = smtp.gmail.com GMAIL_SMTP_PORT = 587 GMAIL_EMAIL = GMAIL_ADDRESS GMAIL_PASSWORD = GMAIL_PW def initialize_smtp_server(): ''' This function initializes and greets the smtp server. It logs in using the provided credentials and returns the smtp server object as a result. ''' smtpserver = smtplib.SMTP(GMAIL_SMTP_SERVER, GMAIL_SMTP_PORT) smtpserver.ehlo() smtpserver.starttls() smtpserver.ehlo() smtpserver.login(GMAIL_EMAIL, GMAIL_PASSWORD) return smtpserver def send_thank_you_mail(email): to_email = email from_email = GMAIL_EMAIL subj = Thanks for being an active commenter # The header consists of the To and From and Subject lines # separated using a newline character header = To:%s\\nFrom:%s\\nSubject:%s \\n % (to_email, from_email, subj) # Hard-coded templates are not best practice. msg_body = Hi %s, Thank you very much for your repeated comments on our service. The interaction is much appreciated. Thank You. % email content = msg_body smtpserver = initialize_smtp_server() smtpserver.sendmail(from_email, to_email, content) smtpserver.close() if __name__ == __main__ : # for every line of input. for email in sys.stdin.readlines(): send_thank_you_mail(email) or another, more CLI #!/usr/bin/env python import smtplib import sys from optparse import OptionParser def initialize_smtp_server(smtpserver, smtpport, email, pwd): ''' This function initializes and greets the SMTP server. It logs in using the provided credentials and returns the SMTP server object as a result. ''' smtpserver = smtplib.SMTP(smtpserver, smtpport) smtpserver.ehlo() smtpserver.starttls() smtpserver.ehlo() smtpserver.login(email, pwd) return smtpserver def send_thank_you_mail(email, smtpserver): to_email = email from_email = GMAIL_EMAIL subj = Thanks for being an active commenter # The header consists of the To and From and Subject lines # separated using a newline character. header = To:%s\\nFrom:%s\\nSubject:%s \\n % (to_email, from_email, subj) # Hard-coded templates are not best practice. msg_body = Hi %s, Thank you very much for your repeated comments on our service. The interaction is much appreciated. Thank You. % email content = header + \\n + msg_body smtpserver.sendmail(from_email, to_email, content) if __name__ == __main__ : usage = usage: %prog [options] parser = OptionParser(usage=usage) parser.add_option( --email , dest= email , help= email to login to smtp server ) parser.add_option( --pwd , dest= pwd , help= password to login to smtp server ) parser.add_option( --smtp-server , dest= smtpserver , help= smtp server url , default= smtp.gmail.com ) parser.add_option( --smtp-port , dest= smtpserverport , help= smtp server port , default=587) options, args = parser.parse_args() if not (options.email or options.pwd): parser.error( Must provide both an email and a password ) smtpserver = initialize_smtp_server(options.stmpserver, options.smtpserverport, options.email, options.pwd) # for every line of input. for email in sys.stdin.readlines(): send_thank_you_mail(email, smtpserver) smtpserver.close()","title":"Python email"},{"location":"python/snippets/Python-email/#email","text":"","title":"Email"},{"location":"python/snippets/Python-email/#one-way","text":"#!/usr/bin/env python import smtplib import sys GMAIL_SMTP_SERVER = smtp.gmail.com GMAIL_SMTP_PORT = 587 GMAIL_EMAIL = GMAIL_ADDRESS GMAIL_PASSWORD = GMAIL_PW def initialize_smtp_server(): ''' This function initializes and greets the smtp server. It logs in using the provided credentials and returns the smtp server object as a result. ''' smtpserver = smtplib.SMTP(GMAIL_SMTP_SERVER, GMAIL_SMTP_PORT) smtpserver.ehlo() smtpserver.starttls() smtpserver.ehlo() smtpserver.login(GMAIL_EMAIL, GMAIL_PASSWORD) return smtpserver def send_thank_you_mail(email): to_email = email from_email = GMAIL_EMAIL subj = Thanks for being an active commenter # The header consists of the To and From and Subject lines # separated using a newline character header = To:%s\\nFrom:%s\\nSubject:%s \\n % (to_email, from_email, subj) # Hard-coded templates are not best practice. msg_body = Hi %s, Thank you very much for your repeated comments on our service. The interaction is much appreciated. Thank You. % email content = msg_body smtpserver = initialize_smtp_server() smtpserver.sendmail(from_email, to_email, content) smtpserver.close() if __name__ == __main__ : # for every line of input. for email in sys.stdin.readlines(): send_thank_you_mail(email)","title":"One way"},{"location":"python/snippets/Python-email/#or-another-more-cli","text":"#!/usr/bin/env python import smtplib import sys from optparse import OptionParser def initialize_smtp_server(smtpserver, smtpport, email, pwd): ''' This function initializes and greets the SMTP server. It logs in using the provided credentials and returns the SMTP server object as a result. ''' smtpserver = smtplib.SMTP(smtpserver, smtpport) smtpserver.ehlo() smtpserver.starttls() smtpserver.ehlo() smtpserver.login(email, pwd) return smtpserver def send_thank_you_mail(email, smtpserver): to_email = email from_email = GMAIL_EMAIL subj = Thanks for being an active commenter # The header consists of the To and From and Subject lines # separated using a newline character. header = To:%s\\nFrom:%s\\nSubject:%s \\n % (to_email, from_email, subj) # Hard-coded templates are not best practice. msg_body = Hi %s, Thank you very much for your repeated comments on our service. The interaction is much appreciated. Thank You. % email content = header + \\n + msg_body smtpserver.sendmail(from_email, to_email, content) if __name__ == __main__ : usage = usage: %prog [options] parser = OptionParser(usage=usage) parser.add_option( --email , dest= email , help= email to login to smtp server ) parser.add_option( --pwd , dest= pwd , help= password to login to smtp server ) parser.add_option( --smtp-server , dest= smtpserver , help= smtp server url , default= smtp.gmail.com ) parser.add_option( --smtp-port , dest= smtpserverport , help= smtp server port , default=587) options, args = parser.parse_args() if not (options.email or options.pwd): parser.error( Must provide both an email and a password ) smtpserver = initialize_smtp_server(options.stmpserver, options.smtpserverport, options.email, options.pwd) # for every line of input. for email in sys.stdin.readlines(): send_thank_you_mail(email, smtpserver) smtpserver.close()","title":"or another, more CLI"},{"location":"python/snippets/Python-file-management/","text":"Walk the tree Returns a tuple consisting of: * the folder being traversed * a list of the files immediately beneath the folder being traversed * a list of the folders immediately beneath the folder being traversed Quicktest import os for item in os.walk( . ): print item Traverse all the tree from the current folder folder_tree_generator = os.walk( . ) for dirpath, dirnames, filenames in gen: if len(filenames) 0: print * * 9 print Files contained in dirpath: {} .format(dirpath) print * * 9 for filename in filenames: full_file_name = dirpath + os.path.sep + filename print {} (full path is {}) .format(filename, full_file_name) if len(dirnames) 0: print * * 9 print Subdirs of dirpath: {} .format(dirpath) print * * 9 for dirname in dirnames: full_folder_name = dirpath + os.path.sep + dirname print {} (full path is: {}) .format(dirname, full_folder_name) if os.path.isdir(full_folder_name): print And it is! else: print But it's not","title":"Python file management"},{"location":"python/snippets/Python-file-management/#walk-the-tree","text":"Returns a tuple consisting of: * the folder being traversed * a list of the files immediately beneath the folder being traversed * a list of the folders immediately beneath the folder being traversed","title":"Walk the tree"},{"location":"python/snippets/Python-file-management/#quicktest","text":"import os for item in os.walk( . ): print item","title":"Quicktest"},{"location":"python/snippets/Python-file-management/#traverse-all-the-tree-from-the-current-folder","text":"folder_tree_generator = os.walk( . ) for dirpath, dirnames, filenames in gen: if len(filenames) 0: print * * 9 print Files contained in dirpath: {} .format(dirpath) print * * 9 for filename in filenames: full_file_name = dirpath + os.path.sep + filename print {} (full path is {}) .format(filename, full_file_name) if len(dirnames) 0: print * * 9 print Subdirs of dirpath: {} .format(dirpath) print * * 9 for dirname in dirnames: full_folder_name = dirpath + os.path.sep + dirname print {} (full path is: {}) .format(dirname, full_folder_name) if os.path.isdir(full_folder_name): print And it is! else: print But it's not","title":"Traverse all the tree from the current folder"},{"location":"python/snippets/Python-input-output/","text":"Read/write file import sys # Read with open('../first.js', 'r') as reading_file: remove_newlines = lambda x: x.replace('\\n', '') lines = list(reading_file) formatted_lines = [remove_newlines(line) for line in lines] # Write with open('output_file', 'w') as output_file: for line in lines: output_file.write(line) or with open('output_file', 'w') as output_file: output_file.writelines(lines) Standard input/output read and write #### Write to stdout import sys sys.stdout.write(str(last_answer )) or import sys with sys.stdout as stdout: sdout.write(str(last_answer)) Read from stdin import sys with sys.stdin as stdin: remove_newlines = lambda x: x.replace('\\n', '') lines = [remove_newlines(line) for line in stdin] or lines = sys.stdin.readlines() Remove trailing and beginning newlines from string remove_newlines = lambda x: x.trim('\\r\\n') Gzip read compressed file import gzip with gzip.open('file.txt.gz', 'rb') as f: file_content = f.read() compress file import gzip content = Lots of content here with gzip.open('file.txt.gz', 'wb') as f: f.write(content) Misc Blink led of caps key import fcntl,os,time; exec fcntl.ioctl(os.open('/dev/console',os.O_NOCTTY),19250,%d);time.sleep(.5); *2%(4,0)","title":"Python input output"},{"location":"python/snippets/Python-input-output/#readwrite-file","text":"import sys # Read with open('../first.js', 'r') as reading_file: remove_newlines = lambda x: x.replace('\\n', '') lines = list(reading_file) formatted_lines = [remove_newlines(line) for line in lines] # Write with open('output_file', 'w') as output_file: for line in lines: output_file.write(line) or with open('output_file', 'w') as output_file: output_file.writelines(lines)","title":"Read/write file"},{"location":"python/snippets/Python-input-output/#standard-inputoutput-read-and-write","text":"#### Write to stdout import sys sys.stdout.write(str(last_answer )) or import sys with sys.stdout as stdout: sdout.write(str(last_answer))","title":"Standard input/output read and write"},{"location":"python/snippets/Python-input-output/#read-from-stdin","text":"import sys with sys.stdin as stdin: remove_newlines = lambda x: x.replace('\\n', '') lines = [remove_newlines(line) for line in stdin] or lines = sys.stdin.readlines()","title":"Read from stdin"},{"location":"python/snippets/Python-input-output/#remove-trailing-and-beginning-newlines-from-string","text":"remove_newlines = lambda x: x.trim('\\r\\n')","title":"Remove trailing and beginning newlines from string"},{"location":"python/snippets/Python-input-output/#gzip","text":"","title":"Gzip"},{"location":"python/snippets/Python-input-output/#read-compressed-file","text":"import gzip with gzip.open('file.txt.gz', 'rb') as f: file_content = f.read()","title":"read compressed file"},{"location":"python/snippets/Python-input-output/#compress-file","text":"import gzip content = Lots of content here with gzip.open('file.txt.gz', 'wb') as f: f.write(content)","title":"compress file"},{"location":"python/snippets/Python-input-output/#misc","text":"","title":"Misc"},{"location":"python/snippets/Python-input-output/#blink-led-of-caps-key","text":"import fcntl,os,time; exec fcntl.ioctl(os.open('/dev/console',os.O_NOCTTY),19250,%d);time.sleep(.5); *2%(4,0)","title":"Blink led of caps key"},{"location":"python/snippets/Python-misc/","text":"Create matrix Create matrix of None A = [[ None for _ in xrange(M)] for _ in xrange(N)] Create matrix of random numbers import random A = [[ random.random() for _ in xrange(M)] for _ in xrange(N)] Generator for lists of M random elements import random A = ([ random.random() for _ in xrange(M)] for _ in iter(int, 1)) for i in A: print i sleep(0.2) Flatten list of lists (only one level of nesting) import itertools list2d = [[1,2,3],[4,5,6], [7], [8,9]] list(itertools.chain.from_iterable(list2d)) [1, 2, 3, 4, 5, 6, 7, 8, 9] Strip punctuation of string s.translate(None, string.punctuation) Permutations From python lexical analysis docs def perm(l): # Compute the list of all permutations of l if len(l) = 1: return [l] r = [] for i in range(len(l)): s = l[:i] + l[i+1:] p = perm(s) for x in p: r.append(l[i:i+1] + x) return r Print literal curly-braces p = {{}} {} p.format(7) Random string taken from here import string, random N = 7 ''.join(random.choices(string.ascii_uppercase + string.digits, k=N)) cryptographically more secure version ''.join(random.SystemRandom().choice(string.ascii_uppercase + string.digits) for _ in range(N))","title":"Python misc"},{"location":"python/snippets/Python-misc/#create-matrix","text":"","title":"Create matrix"},{"location":"python/snippets/Python-misc/#create-matrix-of-none","text":"A = [[ None for _ in xrange(M)] for _ in xrange(N)]","title":"Create matrix of None"},{"location":"python/snippets/Python-misc/#create-matrix-of-random-numbers","text":"import random A = [[ random.random() for _ in xrange(M)] for _ in xrange(N)]","title":"Create matrix of random numbers"},{"location":"python/snippets/Python-misc/#generator-for-lists-of-m-random-elements","text":"import random A = ([ random.random() for _ in xrange(M)] for _ in iter(int, 1)) for i in A: print i sleep(0.2)","title":"Generator for lists of M random elements"},{"location":"python/snippets/Python-misc/#flatten-list-of-lists-only-one-level-of-nesting","text":"import itertools list2d = [[1,2,3],[4,5,6], [7], [8,9]] list(itertools.chain.from_iterable(list2d)) [1, 2, 3, 4, 5, 6, 7, 8, 9]","title":"Flatten list of lists (only one level of nesting)"},{"location":"python/snippets/Python-misc/#strip-punctuation-of-string","text":"s.translate(None, string.punctuation)","title":"Strip punctuation of string"},{"location":"python/snippets/Python-misc/#permutations","text":"From python lexical analysis docs def perm(l): # Compute the list of all permutations of l if len(l) = 1: return [l] r = [] for i in range(len(l)): s = l[:i] + l[i+1:] p = perm(s) for x in p: r.append(l[i:i+1] + x) return r","title":"Permutations"},{"location":"python/snippets/Python-misc/#print-literal-curly-braces","text":"p = {{}} {} p.format(7)","title":"Print literal curly-braces"},{"location":"python/snippets/Python-misc/#random-string","text":"taken from here import string, random N = 7 ''.join(random.choices(string.ascii_uppercase + string.digits, k=N)) cryptographically more secure version ''.join(random.SystemRandom().choice(string.ascii_uppercase + string.digits) for _ in range(N))","title":"Random string"},{"location":"python/snippets/Python-parse-cli-options/","text":"See this page","title":"Python parse cli options"},{"location":"python/snippets/Python-randomness/","text":"Create matrix Create matrix of None A = [[ None for _ in xrange(M)] for _ in xrange(N)] Create matrix of random numbers import random A = [[ random.random() for _ in xrange(M)] for _ in xrange(N)] Generator for lists of M random elements import random A = ([ random.random() for _ in xrange(M)] for _ in iter(int, 1)) for i in A: print i sleep(0.2)","title":"Python randomness"},{"location":"python/snippets/Python-randomness/#create-matrix","text":"","title":"Create matrix"},{"location":"python/snippets/Python-randomness/#create-matrix-of-none","text":"A = [[ None for _ in xrange(M)] for _ in xrange(N)]","title":"Create matrix of None"},{"location":"python/snippets/Python-randomness/#create-matrix-of-random-numbers","text":"import random A = [[ random.random() for _ in xrange(M)] for _ in xrange(N)]","title":"Create matrix of random numbers"},{"location":"python/snippets/Python-randomness/#generator-for-lists-of-m-random-elements","text":"import random A = ([ random.random() for _ in xrange(M)] for _ in iter(int, 1)) for i in A: print i sleep(0.2)","title":"Generator for lists of M random elements"},{"location":"python/snippets/Python-strings/","text":"Source Positional args '{1} {0}'.format('one', 'two') Keyword args '{first} {last}'.format(first='Hodor', last='Hodor!') Getitem person = {'first': 'Jean-Luc', 'last': 'Picard'} '{p[first]} {p[last]}'.format(p=person) Value conversion class Data(object): def __str__(self): return 'str' def __repr__(self): return 'repr' '{0!s} {0!r}'.format(Data()) Padding and aligning strings where _ is the padding characer. default is space align right '{:_ 10}'.format('test') ______test align left '{:10}'.format('test') center align '{:^10}'.format('test') truncate string '{:.5}'.format('xylophone') Date time '{:%Y-%m-%d %H:%M}'.format(datetime(2001, 2, 3, 4, 5))","title":"Python strings"},{"location":"python/snippets/Python-strings/#positional-args","text":"'{1} {0}'.format('one', 'two')","title":"Positional args"},{"location":"python/snippets/Python-strings/#keyword-args","text":"'{first} {last}'.format(first='Hodor', last='Hodor!')","title":"Keyword args"},{"location":"python/snippets/Python-strings/#getitem","text":"person = {'first': 'Jean-Luc', 'last': 'Picard'} '{p[first]} {p[last]}'.format(p=person)","title":"Getitem"},{"location":"python/snippets/Python-strings/#value-conversion","text":"class Data(object): def __str__(self): return 'str' def __repr__(self): return 'repr' '{0!s} {0!r}'.format(Data())","title":"Value conversion"},{"location":"python/snippets/Python-strings/#padding-and-aligning-strings","text":"where _ is the padding characer. default is space","title":"Padding and aligning strings"},{"location":"python/snippets/Python-strings/#align-right","text":"'{:_ 10}'.format('test') ______test","title":"align right"},{"location":"python/snippets/Python-strings/#align-left","text":"'{:10}'.format('test')","title":"align left"},{"location":"python/snippets/Python-strings/#center-align","text":"'{:^10}'.format('test')","title":"center align"},{"location":"python/snippets/Python-strings/#truncate-string","text":"'{:.5}'.format('xylophone')","title":"truncate string"},{"location":"python/snippets/Python-strings/#date-time","text":"'{:%Y-%m-%d %H:%M}'.format(datetime(2001, 2, 3, 4, 5))","title":"Date time"}]}