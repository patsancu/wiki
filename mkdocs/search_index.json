{
    "docs": [
        {
            "location": "/", 
            "text": "About me\n\n\nHi there! I'm Patrick and this is my wiki. Hope you find something useful.\n\n\n\n\nIf you want to contact me, feel free take a look at my \nLinkedIn profile", 
            "title": "Home"
        }, 
        {
            "location": "/#about-me", 
            "text": "Hi there! I'm Patrick and this is my wiki. Hope you find something useful.   If you want to contact me, feel free take a look at my  LinkedIn profile", 
            "title": "About me"
        }, 
        {
            "location": "/OS/Raspberry-Pi/", 
            "text": "Enable ssh on startup\n\n\n\n\nSource\n\n\nChange default user and password first!\n\n\n$ sudo touch /boot/ssh", 
            "title": "Raspberry Pi"
        }, 
        {
            "location": "/OS/Raspberry-Pi/#enable-ssh-on-startup", 
            "text": "Source  Change default user and password first!  $ sudo touch /boot/ssh", 
            "title": "Enable ssh on startup"
        }, 
        {
            "location": "/OS/Tips/", 
            "text": "", 
            "title": "Tips"
        }, 
        {
            "location": "/OS/Linux-Unix/General/", 
            "text": "Systemd\n\n\nvim /etc/systemd/system/service_name.service\n\n\n\n\n[Unit]\nDescription = making network connection up\nAfter = network.target\n[Service]\n# ExecStart can point to any executable file\nExecStart = /root/scripts/conup.sh\n[Install]\nWantedBy = multi-user.target\n\n\n\n\nCreate executable script\n\n\nvim /root/scripts/conup.sh;\nchmod +x /root/scripts/conup.sh;\n\n\n\n\nEnable service\n\n\n# systemctl enable connection.service\n\n\n\n\nBasic operations\n\n\n# systemctl start connection.service\n# systemctl stop connection.service\n\n\n\n\nGrub\n\n\nChange grub boot order\n\n\nsudo vim /etc/default/grub\n\n\n\n\nChange \nGRUB_DEFAULT\n to one of [number of entry (zero-based), 'Title'subindex]\nExamples:\n\n\n'Advanced options for Ubuntu\n'3\n2\n\n\n\n\nThen, update the grub menu\n\n\nsudo update-grub\n\n\n\n\nCheck the file \n/boot/grub/grub.cfg\n for reference\n\n\nReinstall grub\n\n\n\n\nboot from livecd\n\n\nmount partition where grub was contained (usually OS's partition)\n\n\nsudo tune2fs -L \"partition_name\" /dev/sdXX ( e.g.: /dev/sda6/ )\n\n\nsudo os-prober\n\n\nsudo grub-install --root-directory=/media/partition_name/ /dev/sda\n\n\nreboot\n\n\n\n\nCreate passwordless user programmatically\n\n\n# useradd -m -c \nSamwise the Brave\n sam  -s /bin/bash\n\n\n\n\nCreates user with home /home/sam and shell /bin/bash\n\n\nFind\n\n\n# Search all files with .old extension and delete them:\nfind / -name \n*.old\n -exec /bin/rm {} \\;\n# Search all files with size \n of 100 MB and delete them:\nfind / -size +100M -exec /bin/rm {} \\;\n# Recursively change the permissions of all directories\nfind . -type d -exec chmod 755 {} \\;\n\n\n\n\nTop\n\n\n\n\nW\n writes config changes to .toprc\n\n\nE\n cycles through memory units in the total memory info\n\n\n\n\nConfigure stuff\n\n\nChange locale\n\n\nWith \n/usr/bin/tzselect\n you can check what is the timezone your computer should be using\n\n\nsudo dpkg-reconfigure tzdata\n\nIf it doesn't work, try the following:\n\n\nWith that timezone, paste the timezone to \n~/.profile\n or \n~/.bash_profile\n, depending on your use case.\nOne of those files (it'll probably work with any sourced file at login) should have one line such as:\n\n\nTZ='Europe/London'; export TZ\n\n\n\n\nor just execute\n\n\nInsert unicode characters\n\n\nHold down the shift and control keys while typing the letter u and the hex values of the Unicode character you wish to enter. \nExample: \nHold control and shift and type U1F60F \u200d\ud83d\ude0f\n\n\nAdd dictionaries to /usr/share/dict/\n\n\n$ sudo apt-cache search --names-only swedish\n$ sudo apt-get install wswedish\n\n\n\n\nMouse - Third button\n\n\nsudo vim /usr/share/X11/xorg.conf.d/middle-mouse-button.conf \n\n\n\n\nAnd paste this\n\n\nSection \nInputClass\n\n    Identifier \nmiddle button emulation class\n\n    MatchIsPointer \non\n\n    Option \nEmulate3Buttons\n \non\n\nEndSection\n\n\n\n\nor check this\n\nwiki ubuntu\n\n\nWebcam\n\n\nList video devices\n\n\n\n\nv4l2-ctl --list-formats-ext\n\n\nv4l2-ctl --list-devices\n\n\n\n\nFind resolution of webcam\n\n\n\n\nlsusb\n list usb devices, get params of webcam\n\n\nlsusb -s 003:074 -v | egrep \"Width|Height\"\n\n\n\n\ndown vote\naccepted\nI had the same problem and managed to fix it by setting the defaults for both gvfs as well as xdg.\n\n\ncheck defaults with:\n\n\nChange default app for magnet links\n\n\nThis probably will only work with gnome, kde and xfce\n\n\n#Check currently available apps\nxdg-mime query default x-scheme-handler/magnet\ngvfs-mime --query x-scheme-handler/magnet\n\n\n\n\n# Set new app\nxdg-mime default qBittorent.desktop x-scheme-handler/magnet\ngvfs-mime --set x-scheme-handler/magnet qBittorrent.desktop\n\n\n\n\nNotifications\n\n\nnotify-send -u critical \nThe potato finished cooking\n\n\n\n\n\nMotion\n\n\nMake folders accessible\n\n\nsudo mkdir -p /var/run/motion; sudo chown -R $USER:$USER /var/run/motion; \nsudo mkdir -p /etc/motion/; sudo chown -R $USER:$USER /etc/motion/; \nsudo mkdir -p /var/log/motion/; sudo chown -R $USER:$USER /var/log/motion/;\n\n\n\n\nConfiguration file\n\n\n/etc/motion/motion.conf\n\n\nGenerate random chars\n\n\ntr -c -d '0123456789abcdefghijklmnopqrstuvwxyz'  \n /dev/urandom | dd bs=32 count=1 2\n/dev/null; echo\n\n\n\n\nMonitor screen locking\n\n\nexit_report(){\necho \n$(date) Monitoring Terminated.\n\n}\ntrap \nexit_report; exit;\n 0\nlockmon() {\nadddate() {\n    while IFS= read \u00adr line; do\n      echo \n$(date) $line\n | grep \nboolean\n | sed 's/   boolean true/Screen Locked/' \n| sed 's/   boolean false/Screen Unlocked/'\n    done\n}\necho \n$(date) Monitoring Started.\n\ndbus\u00admonitor \u00ad\u00adsession \ntype='signal',interface='org.gnome.ScreenSaver'\n | adddate\n}\nlockmon \n lock_screen.log\n\n\n\n\nHow to fix \u2018$MFTMirr does not match $MFT (record 0)\u2019\n\n\n\n\ninstall ntfsprogs\n\n\nsudo ntfsfix /dev/partitionName", 
            "title": "General"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#systemd", 
            "text": "vim /etc/systemd/system/service_name.service  [Unit]\nDescription = making network connection up\nAfter = network.target\n[Service]\n# ExecStart can point to any executable file\nExecStart = /root/scripts/conup.sh\n[Install]\nWantedBy = multi-user.target", 
            "title": "Systemd"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#create-executable-script", 
            "text": "vim /root/scripts/conup.sh;\nchmod +x /root/scripts/conup.sh;", 
            "title": "Create executable script"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#enable-service", 
            "text": "# systemctl enable connection.service", 
            "title": "Enable service"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#basic-operations", 
            "text": "# systemctl start connection.service\n# systemctl stop connection.service", 
            "title": "Basic operations"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#grub", 
            "text": "", 
            "title": "Grub"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#change-grub-boot-order", 
            "text": "sudo vim /etc/default/grub  Change  GRUB_DEFAULT  to one of [number of entry (zero-based), 'Title'subindex]\nExamples:  'Advanced options for Ubuntu '3\n2  Then, update the grub menu  sudo update-grub  Check the file  /boot/grub/grub.cfg  for reference", 
            "title": "Change grub boot order"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#reinstall-grub", 
            "text": "boot from livecd  mount partition where grub was contained (usually OS's partition)  sudo tune2fs -L \"partition_name\" /dev/sdXX ( e.g.: /dev/sda6/ )  sudo os-prober  sudo grub-install --root-directory=/media/partition_name/ /dev/sda  reboot", 
            "title": "Reinstall grub"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#create-passwordless-user-programmatically", 
            "text": "# useradd -m -c  Samwise the Brave  sam  -s /bin/bash  Creates user with home /home/sam and shell /bin/bash", 
            "title": "Create passwordless user programmatically"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#find", 
            "text": "# Search all files with .old extension and delete them:\nfind / -name  *.old  -exec /bin/rm {} \\;\n# Search all files with size   of 100 MB and delete them:\nfind / -size +100M -exec /bin/rm {} \\;\n# Recursively change the permissions of all directories\nfind . -type d -exec chmod 755 {} \\;", 
            "title": "Find"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#top", 
            "text": "W  writes config changes to .toprc  E  cycles through memory units in the total memory info", 
            "title": "Top"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#configure-stuff", 
            "text": "", 
            "title": "Configure stuff"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#change-locale", 
            "text": "With  /usr/bin/tzselect  you can check what is the timezone your computer should be using  sudo dpkg-reconfigure tzdata \nIf it doesn't work, try the following:  With that timezone, paste the timezone to  ~/.profile  or  ~/.bash_profile , depending on your use case.\nOne of those files (it'll probably work with any sourced file at login) should have one line such as:  TZ='Europe/London'; export TZ  or just execute", 
            "title": "Change locale"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#insert-unicode-characters", 
            "text": "Hold down the shift and control keys while typing the letter u and the hex values of the Unicode character you wish to enter. \nExample: \nHold control and shift and type U1F60F \u200d\ud83d\ude0f", 
            "title": "Insert unicode characters"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#add-dictionaries-to-usrsharedict", 
            "text": "$ sudo apt-cache search --names-only swedish\n$ sudo apt-get install wswedish", 
            "title": "Add dictionaries to /usr/share/dict/"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#mouse-third-button", 
            "text": "sudo vim /usr/share/X11/xorg.conf.d/middle-mouse-button.conf   And paste this  Section  InputClass \n    Identifier  middle button emulation class \n    MatchIsPointer  on \n    Option  Emulate3Buttons   on \nEndSection  or check this wiki ubuntu", 
            "title": "Mouse - Third button"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#webcam", 
            "text": "", 
            "title": "Webcam"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#list-video-devices", 
            "text": "v4l2-ctl --list-formats-ext  v4l2-ctl --list-devices", 
            "title": "List video devices"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#find-resolution-of-webcam", 
            "text": "lsusb  list usb devices, get params of webcam  lsusb -s 003:074 -v | egrep \"Width|Height\"   down vote\naccepted\nI had the same problem and managed to fix it by setting the defaults for both gvfs as well as xdg.  check defaults with:", 
            "title": "Find resolution of webcam"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#change-default-app-for-magnet-links", 
            "text": "This probably will only work with gnome, kde and xfce  #Check currently available apps\nxdg-mime query default x-scheme-handler/magnet\ngvfs-mime --query x-scheme-handler/magnet  # Set new app\nxdg-mime default qBittorent.desktop x-scheme-handler/magnet\ngvfs-mime --set x-scheme-handler/magnet qBittorrent.desktop", 
            "title": "Change default app for magnet links"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#notifications", 
            "text": "notify-send -u critical  The potato finished cooking", 
            "title": "Notifications"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#motion", 
            "text": "", 
            "title": "Motion"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#make-folders-accessible", 
            "text": "sudo mkdir -p /var/run/motion; sudo chown -R $USER:$USER /var/run/motion; \nsudo mkdir -p /etc/motion/; sudo chown -R $USER:$USER /etc/motion/; \nsudo mkdir -p /var/log/motion/; sudo chown -R $USER:$USER /var/log/motion/;", 
            "title": "Make folders accessible"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#configuration-file", 
            "text": "/etc/motion/motion.conf", 
            "title": "Configuration file"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#generate-random-chars", 
            "text": "tr -c -d '0123456789abcdefghijklmnopqrstuvwxyz'    /dev/urandom | dd bs=32 count=1 2 /dev/null; echo", 
            "title": "Generate random chars"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#monitor-screen-locking", 
            "text": "exit_report(){\necho  $(date) Monitoring Terminated. \n}\ntrap  exit_report; exit;  0\nlockmon() {\nadddate() {\n    while IFS= read \u00adr line; do\n      echo  $(date) $line  | grep  boolean  | sed 's/   boolean true/Screen Locked/' \n| sed 's/   boolean false/Screen Unlocked/'\n    done\n}\necho  $(date) Monitoring Started. \ndbus\u00admonitor \u00ad\u00adsession  type='signal',interface='org.gnome.ScreenSaver'  | adddate\n}\nlockmon   lock_screen.log", 
            "title": "Monitor screen locking"
        }, 
        {
            "location": "/OS/Linux-Unix/General/#how-to-fix-mftmirr-does-not-match-mft-record-0", 
            "text": "install ntfsprogs  sudo ntfsfix /dev/partitionName", 
            "title": "How to fix \u2018$MFTMirr does not match $MFT (record 0)\u2019"
        }, 
        {
            "location": "/OS/Linux-Unix/Gnome/", 
            "text": "Set monday as first day of week in Gnome\n\n\nEdit the file ~/.xsessionrc (or bashrc or whatever)\nto contain the line \n\n\"export LC_TIME=en_GB.utf8\"\n\n\nAssign/unassign keyboard's sleep button\n\n\nAssign\n\n\ngsettings set org.gnome.settings-daemon.plugins.power button-suspend \nnothing\n\n\n\n\n\nUnassign\n\n\ngsettings set org.gnome.settings-daemon.plugins.power button-suspend \nsuspend\n\n\n\n\n\nCustom launchers\n\n\nThe applications launchers Gnome knows about are .desktop files in /usr/share/applications, and \n~/.local/share/applications\n. You can create custom launchers for whatever is in your home folder, by either manually creating and editing a custom .desktop file, or by using Alacarte, the old Gnome menu editor.\n\n\nThe Gnome desktop file documentation can be of help: https://developer.gnome.org/integration-guide/stable/desktop-files.html.en\n\n\nThe custom launcher is just a text file, named, for example, EclipseEE.desktop, with the following content:\n\n\n[Desktop Entry]\nName=Eclipse EE\nExec=/home/mrPeterson/path_to_executable\nStartupNotify=true\nTerminal=false\nType=Application\nIcon=/optional/path/to/icon.png", 
            "title": "Gnome"
        }, 
        {
            "location": "/OS/Linux-Unix/Gnome/#set-monday-as-first-day-of-week-in-gnome", 
            "text": "Edit the file ~/.xsessionrc (or bashrc or whatever)\nto contain the line  \"export LC_TIME=en_GB.utf8\"", 
            "title": "Set monday as first day of week in Gnome"
        }, 
        {
            "location": "/OS/Linux-Unix/Gnome/#assignunassign-keyboards-sleep-button", 
            "text": "", 
            "title": "Assign/unassign keyboard's sleep button"
        }, 
        {
            "location": "/OS/Linux-Unix/Gnome/#assign", 
            "text": "gsettings set org.gnome.settings-daemon.plugins.power button-suspend  nothing", 
            "title": "Assign"
        }, 
        {
            "location": "/OS/Linux-Unix/Gnome/#unassign", 
            "text": "gsettings set org.gnome.settings-daemon.plugins.power button-suspend  suspend", 
            "title": "Unassign"
        }, 
        {
            "location": "/OS/Linux-Unix/Gnome/#custom-launchers", 
            "text": "The applications launchers Gnome knows about are .desktop files in /usr/share/applications, and  ~/.local/share/applications . You can create custom launchers for whatever is in your home folder, by either manually creating and editing a custom .desktop file, or by using Alacarte, the old Gnome menu editor.  The Gnome desktop file documentation can be of help: https://developer.gnome.org/integration-guide/stable/desktop-files.html.en  The custom launcher is just a text file, named, for example, EclipseEE.desktop, with the following content:  [Desktop Entry]\nName=Eclipse EE\nExec=/home/mrPeterson/path_to_executable\nStartupNotify=true\nTerminal=false\nType=Application\nIcon=/optional/path/to/icon.png", 
            "title": "Custom launchers"
        }, 
        {
            "location": "/OS/Linux-Unix/Monitor-Linux-Performance/", 
            "text": "vmstat\n\n\nLinux VmStat command used to display statistics of virtual memory, kernerl threads, disks, system processes, I/O blocks, interrupts, CPU activity and much more. By default vmstat command is not available under Linux systems you need to install a package called sysstat that includes a vmstat program. The common usage of command format is.\n\n\nlsof\n\n\nLsof command used in many Linux/Unix like system that is used to display list of all the open files and the  processes. The open files included are disk files, network sockets, pipes,\ndevices and processes. One of the main reason for using this command is when a disk cannot be unmounted and displays the error that files are being used or opened. With this commmand you can easily identify which files are in use. The most common format for this command is:\n\n\nlsof\n\n\n\n\nTcpdump\n\n\nTcpdump is one of the most widely used command- line network packet analyzer or packets sniffer program that is used capture or filter TCP/IP packets that received or transferred on a specific interface over a network. It option to save captured packages in a file for later analysis. tcpdump is almost available in all major Linux distributions.\n\n\ntcpdump -i eth0\n\n\n\n\nNetstat\n\n\nNetstat is a command line tool for monitoring incoming and outgoing network packets statistics as well as interface statistics. It is very useful tool for every system administrator to monitor network performance and troubleshoot network related problems.\n\n\nnetstat -a | more\n\n\n\n\nHtop \u2013 Linux Process Monitoring\n\n\nHtop is a much advanced interactive and real time Linux process monitoring tool.  This is much similar to Linux top command but it has some rich features like user friendly interface to manage process, shortcut keys, vertical and horizontal view of the processes and much more. \n\n\nIotop \u2013 Monitor Linux Disk I/O\n\n\nIotop is also much similar to top command and Htop program, but it has accounting function to monitor and display real time Disk I/O and processes. This tool is much useful for finding the exact process and high used disk read/writes of the processes.\n\n\nIostat \u2013 Input/Output Statistics\n\n\nIoStat is simple tool that will collect and show system input and output storage device statistics.  This tool is often used to trace storage device performance issues including devices, local disks, remote disks such as NFS.\n\n\nIPTraf \u2013 Real Time IP LAN Monitoring\n\n\nIPTraf is an open source console- based real time network (IP LAN) monitoring utility for Linux. It collects a variety of information such as IP traffic monitor that passes over the network, including TCP flag information, ICMP details, TCP/UDP traffic breakdowns, TCP connection packet and byne counts. It also gathers information of general and detaled interface statistics of TCP, UDP, IP, ICMP, non-IP, IP checksum errors, interface activity etc.\n\n\nPsacct or Acct \u2013 Monitor User Activity\n\n\npsacct or acct tools are very useful for monitoring each users activity on the system. Both daemons runs in the background and keeps a close watch on the overall activity of each user on the system and also what resources are being consumed by them.  These tools are very useful for system administrators to track each users activity like what they are doing, what commands they issued, how much resources are used by them, how long they are active on the system etc.\n\n\nMonit \u2013 Linux Process and Services Monitoring\n\n\nMonit is a free open source and web based process supervision utility that automatically monitors and managers system processes, programs, files, directories, permissions, checksums and filesystems.  It monitors services like Apache, MySQL, Mail, FTP, ProFTP, Nginx, SSH and so on. The system status can be viewed from the command line or using it own web interface.\n\n\nNetHogs \u2013 Monitor Per Process Network Bandwidth\n\n\nNetHogs is an open source nice small program (similar to Linux top command) that keeps a tab on each process network activity on your system. It also keeps a track of real time network traffic bandwidth used by each program or application.\n\n\niftop \u2013 Network Bandwidth Monitoring\n\n\niftop is another terminal-based free open source system monitoring utility that displays a frequently updated list of network bandwidth utilization (source and destination hosts) that passing through the network interface on your system. iftop is considered for network usage, what \u2018top\u2018 does for CPU usage. iftop is a \u2018top\u2018 family tool that monitor a selected interface and displays a current bandwidth usage betwee\n\n\nMonitorix \u2013 System and Network Monitoring\n\n\nMonitorix is a free lightweight utility that is designed to run and monitor system and network resources as many as possible in Linux/Unix servers. It has a built in HTTP web server that regularly collects system and network information and display them in graphs. It Monitors system load average and usage, memory allocation, disk driver health, system services, network ports, mail statistics\n\n\nSArpwatch \u2013 Ethernet Activity Monitor\n\n\nArpwatch is a kind of program that is designed to monitor Address Resolution (MAC and IP address changes) of Ethernet network traffic on a Linux network. It continuously keeps watch on Ethernet traffic and produces a log of IP and MAC address pair changes along with a timestamps on a network. It also has a feature to send an email alerts to administrator, when a pairing added or changes.  It is very useful in detecting ARP spoofing on a network.\n\n\nSuricata \u2013 Network Security Monitoring\n\n\nSuricata is an high performance open source Network Security and Intrusion Detection and Prevention Monitoring System for Linux, FreeBSD and Windows.It was designed and owned by a non- profit foundation OISF (Open Information Security Foundation).", 
            "title": "Monitor Linux Performance"
        }, 
        {
            "location": "/OS/Linux-Unix/Monitor-Linux-Performance/#vmstat", 
            "text": "Linux VmStat command used to display statistics of virtual memory, kernerl threads, disks, system processes, I/O blocks, interrupts, CPU activity and much more. By default vmstat command is not available under Linux systems you need to install a package called sysstat that includes a vmstat program. The common usage of command format is.", 
            "title": "vmstat"
        }, 
        {
            "location": "/OS/Linux-Unix/Monitor-Linux-Performance/#lsof", 
            "text": "Lsof command used in many Linux/Unix like system that is used to display list of all the open files and the  processes. The open files included are disk files, network sockets, pipes,\ndevices and processes. One of the main reason for using this command is when a disk cannot be unmounted and displays the error that files are being used or opened. With this commmand you can easily identify which files are in use. The most common format for this command is:  lsof", 
            "title": "lsof"
        }, 
        {
            "location": "/OS/Linux-Unix/Monitor-Linux-Performance/#tcpdump", 
            "text": "Tcpdump is one of the most widely used command- line network packet analyzer or packets sniffer program that is used capture or filter TCP/IP packets that received or transferred on a specific interface over a network. It option to save captured packages in a file for later analysis. tcpdump is almost available in all major Linux distributions.  tcpdump -i eth0", 
            "title": "Tcpdump"
        }, 
        {
            "location": "/OS/Linux-Unix/Monitor-Linux-Performance/#netstat", 
            "text": "Netstat is a command line tool for monitoring incoming and outgoing network packets statistics as well as interface statistics. It is very useful tool for every system administrator to monitor network performance and troubleshoot network related problems.  netstat -a | more", 
            "title": "Netstat"
        }, 
        {
            "location": "/OS/Linux-Unix/Monitor-Linux-Performance/#htop-linux-process-monitoring", 
            "text": "Htop is a much advanced interactive and real time Linux process monitoring tool.  This is much similar to Linux top command but it has some rich features like user friendly interface to manage process, shortcut keys, vertical and horizontal view of the processes and much more.", 
            "title": "Htop \u2013 Linux Process Monitoring"
        }, 
        {
            "location": "/OS/Linux-Unix/Monitor-Linux-Performance/#iotop-monitor-linux-disk-io", 
            "text": "Iotop is also much similar to top command and Htop program, but it has accounting function to monitor and display real time Disk I/O and processes. This tool is much useful for finding the exact process and high used disk read/writes of the processes.", 
            "title": "Iotop \u2013 Monitor Linux Disk I/O"
        }, 
        {
            "location": "/OS/Linux-Unix/Monitor-Linux-Performance/#iostat-inputoutput-statistics", 
            "text": "IoStat is simple tool that will collect and show system input and output storage device statistics.  This tool is often used to trace storage device performance issues including devices, local disks, remote disks such as NFS.", 
            "title": "Iostat \u2013 Input/Output Statistics"
        }, 
        {
            "location": "/OS/Linux-Unix/Monitor-Linux-Performance/#iptraf-real-time-ip-lan-monitoring", 
            "text": "IPTraf is an open source console- based real time network (IP LAN) monitoring utility for Linux. It collects a variety of information such as IP traffic monitor that passes over the network, including TCP flag information, ICMP details, TCP/UDP traffic breakdowns, TCP connection packet and byne counts. It also gathers information of general and detaled interface statistics of TCP, UDP, IP, ICMP, non-IP, IP checksum errors, interface activity etc.", 
            "title": "IPTraf \u2013 Real Time IP LAN Monitoring"
        }, 
        {
            "location": "/OS/Linux-Unix/Monitor-Linux-Performance/#psacct-or-acct-monitor-user-activity", 
            "text": "psacct or acct tools are very useful for monitoring each users activity on the system. Both daemons runs in the background and keeps a close watch on the overall activity of each user on the system and also what resources are being consumed by them.  These tools are very useful for system administrators to track each users activity like what they are doing, what commands they issued, how much resources are used by them, how long they are active on the system etc.", 
            "title": "Psacct or Acct \u2013 Monitor User Activity"
        }, 
        {
            "location": "/OS/Linux-Unix/Monitor-Linux-Performance/#monit-linux-process-and-services-monitoring", 
            "text": "Monit is a free open source and web based process supervision utility that automatically monitors and managers system processes, programs, files, directories, permissions, checksums and filesystems.  It monitors services like Apache, MySQL, Mail, FTP, ProFTP, Nginx, SSH and so on. The system status can be viewed from the command line or using it own web interface.", 
            "title": "Monit \u2013 Linux Process and Services Monitoring"
        }, 
        {
            "location": "/OS/Linux-Unix/Monitor-Linux-Performance/#nethogs-monitor-per-process-network-bandwidth", 
            "text": "NetHogs is an open source nice small program (similar to Linux top command) that keeps a tab on each process network activity on your system. It also keeps a track of real time network traffic bandwidth used by each program or application.", 
            "title": "NetHogs \u2013 Monitor Per Process Network Bandwidth"
        }, 
        {
            "location": "/OS/Linux-Unix/Monitor-Linux-Performance/#iftop-network-bandwidth-monitoring", 
            "text": "iftop is another terminal-based free open source system monitoring utility that displays a frequently updated list of network bandwidth utilization (source and destination hosts) that passing through the network interface on your system. iftop is considered for network usage, what \u2018top\u2018 does for CPU usage. iftop is a \u2018top\u2018 family tool that monitor a selected interface and displays a current bandwidth usage betwee", 
            "title": "iftop \u2013 Network Bandwidth Monitoring"
        }, 
        {
            "location": "/OS/Linux-Unix/Monitor-Linux-Performance/#monitorix-system-and-network-monitoring", 
            "text": "Monitorix is a free lightweight utility that is designed to run and monitor system and network resources as many as possible in Linux/Unix servers. It has a built in HTTP web server that regularly collects system and network information and display them in graphs. It Monitors system load average and usage, memory allocation, disk driver health, system services, network ports, mail statistics", 
            "title": "Monitorix \u2013 System and Network Monitoring"
        }, 
        {
            "location": "/OS/Linux-Unix/Monitor-Linux-Performance/#sarpwatch-ethernet-activity-monitor", 
            "text": "Arpwatch is a kind of program that is designed to monitor Address Resolution (MAC and IP address changes) of Ethernet network traffic on a Linux network. It continuously keeps watch on Ethernet traffic and produces a log of IP and MAC address pair changes along with a timestamps on a network. It also has a feature to send an email alerts to administrator, when a pairing added or changes.  It is very useful in detecting ARP spoofing on a network.", 
            "title": "SArpwatch \u2013 Ethernet Activity Monitor"
        }, 
        {
            "location": "/OS/Linux-Unix/Monitor-Linux-Performance/#suricata-network-security-monitoring", 
            "text": "Suricata is an high performance open source Network Security and Intrusion Detection and Prevention Monitoring System for Linux, FreeBSD and Windows.It was designed and owned by a non- profit foundation OISF (Open Information Security Foundation).", 
            "title": "Suricata \u2013 Network Security Monitoring"
        }, 
        {
            "location": "/OS/Linux-Unix/Ubuntu/", 
            "text": "Show notification window\n\n\nzenity --error --text=\nHellow\n --title=\nPatata\n --timeout=2\n\n\n\n\nRebuild font cache\n\n\n$ fc-cache -f -v", 
            "title": "Ubuntu"
        }, 
        {
            "location": "/OS/Linux-Unix/Ubuntu/#show-notification-window", 
            "text": "zenity --error --text= Hellow  --title= Patata  --timeout=2", 
            "title": "Show notification window"
        }, 
        {
            "location": "/OS/Linux-Unix/Ubuntu/#rebuild-font-cache", 
            "text": "$ fc-cache -f -v", 
            "title": "Rebuild font cache"
        }, 
        {
            "location": "/OS/MacOS/MacOS-Apps/", 
            "text": "", 
            "title": "MacOS Apps"
        }, 
        {
            "location": "/OS/MacOS/macOS-config/", 
            "text": "Mac OS X: ValueError: unknown locale: UTF-8 in Python\n\n\nIf you have faced the error on MacOS X, here's the quick fix - add these lines to your ~/.bash_profile:\n\n\n$ export LC_ALL=en_US.UTF-8\n$ export LANG=en_US.UTF-8\n\n\n\n\nGit completion\n\n\n\n\ndownload https://raw.githubusercontent.com/git/git/master/contrib/completion/git-completion.bash\n\n\nadd \n\n\n\n\nsource ~/git-completion.bash\n\n\n\n\nto ~/.bashrc\n\n\nBasic stuff that should be included, but it's not\n\n\n$ brew install coreutils", 
            "title": "macOS config"
        }, 
        {
            "location": "/OS/MacOS/macOS-config/#mac-os-x-valueerror-unknown-locale-utf-8-in-python", 
            "text": "If you have faced the error on MacOS X, here's the quick fix - add these lines to your ~/.bash_profile:  $ export LC_ALL=en_US.UTF-8\n$ export LANG=en_US.UTF-8", 
            "title": "Mac OS X: ValueError: unknown locale: UTF-8 in Python"
        }, 
        {
            "location": "/OS/MacOS/macOS-config/#git-completion", 
            "text": "download https://raw.githubusercontent.com/git/git/master/contrib/completion/git-completion.bash  add    source ~/git-completion.bash  to ~/.bashrc", 
            "title": "Git completion"
        }, 
        {
            "location": "/OS/MacOS/macOS-config/#basic-stuff-that-should-be-included-but-its-not", 
            "text": "$ brew install coreutils", 
            "title": "Basic stuff that should be included, but it's not"
        }, 
        {
            "location": "/OS/MacOS/macOS/", 
            "text": "Restart ssh daemon\n\n\nsudo launchctl stop com.openssh.sshd\nsudo launchctl start com.openssh.sshd\n\n\n\n\nHow to Refresh Control Strip\n\n\nkillall ControlStrip\n\n\nRefresh touch bar\n\n\npkill \"Touch Bar agent\"", 
            "title": "macOS"
        }, 
        {
            "location": "/OS/MacOS/macOS/#restart-ssh-daemon", 
            "text": "sudo launchctl stop com.openssh.sshd\nsudo launchctl start com.openssh.sshd", 
            "title": "Restart ssh daemon"
        }, 
        {
            "location": "/OS/MacOS/macOS/#how-to-refresh-control-strip", 
            "text": "killall ControlStrip", 
            "title": "How to Refresh Control Strip"
        }, 
        {
            "location": "/OS/MacOS/macOS/#refresh-touch-bar", 
            "text": "pkill \"Touch Bar agent\"", 
            "title": "Refresh touch bar"
        }, 
        {
            "location": "/OS/encryption-and-hashing/GPG-PGP/", 
            "text": "Generate keys\n\n\n$ gpg --gen-key\n\n\n\n\nEncryption\n\n\n$ gpg --encrypt --sign --armor -r recipient_email -r my@email.com file_to_encrypt\n\n\n\n\nDecrypt\n\n\n$ gpg --output path/to/decrypted/file file_to_encrypt.asc\n\n\n\n\nCreate subkey\n\n\nBackup files\n\n\n$ umask 077; tar -cf $HOME/gnupg-backup.tar -C $HOME .gnupg\n\n\n\n\nFind key and edit it\n\n\ngpg --list-keys yourname\ngpg --edit-key \ngpg\n addkey\n\n\nChoose the \"RSA (sign only)\"\n\n\nentropy stuff\n\n\ngpg\n save", 
            "title": "GPG PGP"
        }, 
        {
            "location": "/OS/encryption-and-hashing/GPG-PGP/#generate-keys", 
            "text": "$ gpg --gen-key", 
            "title": "Generate keys"
        }, 
        {
            "location": "/OS/encryption-and-hashing/GPG-PGP/#encryption", 
            "text": "$ gpg --encrypt --sign --armor -r recipient_email -r my@email.com file_to_encrypt", 
            "title": "Encryption"
        }, 
        {
            "location": "/OS/encryption-and-hashing/GPG-PGP/#decrypt", 
            "text": "$ gpg --output path/to/decrypted/file file_to_encrypt.asc", 
            "title": "Decrypt"
        }, 
        {
            "location": "/OS/encryption-and-hashing/GPG-PGP/#create-subkey", 
            "text": "", 
            "title": "Create subkey"
        }, 
        {
            "location": "/OS/encryption-and-hashing/GPG-PGP/#backup-files", 
            "text": "$ umask 077; tar -cf $HOME/gnupg-backup.tar -C $HOME .gnupg", 
            "title": "Backup files"
        }, 
        {
            "location": "/OS/encryption-and-hashing/GPG-PGP/#find-key-and-edit-it", 
            "text": "gpg --list-keys yourname\ngpg --edit-key \ngpg  addkey", 
            "title": "Find key and edit it"
        }, 
        {
            "location": "/OS/encryption-and-hashing/GPG-PGP/#choose-the-rsa-sign-only", 
            "text": "", 
            "title": "Choose the \"RSA (sign only)\""
        }, 
        {
            "location": "/OS/encryption-and-hashing/GPG-PGP/#entropy-stuff", 
            "text": "gpg  save", 
            "title": "entropy stuff"
        }, 
        {
            "location": "/OS/encryption-and-hashing/sha/", 
            "text": "Checksum\n\n\nsha256 example\n\n\n$ cat p.txt\n3c06434c09bb354df6c3f8ec12fbea253a89c7d694e888009841a74d4e1c271a  p.json\n$ sha256sum -c p.txt\np.json: OK", 
            "title": "Sha"
        }, 
        {
            "location": "/OS/encryption-and-hashing/sha/#checksum", 
            "text": "", 
            "title": "Checksum"
        }, 
        {
            "location": "/OS/encryption-and-hashing/sha/#sha256-example", 
            "text": "$ cat p.txt\n3c06434c09bb354df6c3f8ec12fbea253a89c7d694e888009841a74d4e1c271a  p.json\n$ sha256sum -c p.txt\np.json: OK", 
            "title": "sha256 example"
        }, 
        {
            "location": "/Ops/Docker/", 
            "text": "Delete exited containers\n\n\ndocker rm -v $(docker ps -a -q -f status=exited)\n\n\n\n\nRemove dangling images\n\n\n$ docker rmi $(docker images -f \ndangling=true\n -q)", 
            "title": "Docker"
        }, 
        {
            "location": "/Ops/Docker/#delete-exited-containers", 
            "text": "docker rm -v $(docker ps -a -q -f status=exited)", 
            "title": "Delete exited containers"
        }, 
        {
            "location": "/Ops/Docker/#remove-dangling-images", 
            "text": "$ docker rmi $(docker images -f  dangling=true  -q)", 
            "title": "Remove dangling images"
        }, 
        {
            "location": "/Ops/Encrypt-a-partition-with-DM-Crypt-LUKS/", 
            "text": "Encrypt partition\n\n\n$ sudo cryptsetup -y -v luksFormat /dev/xvdc \nWARNING!\n========\nThis will overwrite data on /dev/xvdc irrevocably.\n\nAre you sure? (Type uppercase yes): YES\nEnter passphrase: \nVerify passphrase: \nCommand successful.\n\n\n\n\nCreate mapping\n\n\ncryptsetup luksOpen /dev/xvdc backup2\n\n\n\n\nFormat partition\n\n\npv -tpreb /dev/zero | dd of=/dev/mapper/backup2 bs=128M\nmkfs.ext4 /dev/mapper/backup2\n\n\n\n\nUnmount\n\n\numount /backup2\ncryptsetup luksClose backup2\n\n\n\n\nMount\n\n\ncryptsetup luksOpen /dev/xvdc backup2\nmount /dev/mapper/backup2 /backup2", 
            "title": "Encrypt a partition with DM Crypt LUKS"
        }, 
        {
            "location": "/Ops/Encrypt-a-partition-with-DM-Crypt-LUKS/#encrypt-partition", 
            "text": "$ sudo cryptsetup -y -v luksFormat /dev/xvdc \nWARNING!\n========\nThis will overwrite data on /dev/xvdc irrevocably.\n\nAre you sure? (Type uppercase yes): YES\nEnter passphrase: \nVerify passphrase: \nCommand successful.", 
            "title": "Encrypt partition"
        }, 
        {
            "location": "/Ops/Encrypt-a-partition-with-DM-Crypt-LUKS/#create-mapping", 
            "text": "cryptsetup luksOpen /dev/xvdc backup2", 
            "title": "Create mapping"
        }, 
        {
            "location": "/Ops/Encrypt-a-partition-with-DM-Crypt-LUKS/#format-partition", 
            "text": "pv -tpreb /dev/zero | dd of=/dev/mapper/backup2 bs=128M\nmkfs.ext4 /dev/mapper/backup2", 
            "title": "Format partition"
        }, 
        {
            "location": "/Ops/Encrypt-a-partition-with-DM-Crypt-LUKS/#unmount", 
            "text": "umount /backup2\ncryptsetup luksClose backup2", 
            "title": "Unmount"
        }, 
        {
            "location": "/Ops/Encrypt-a-partition-with-DM-Crypt-LUKS/#mount", 
            "text": "cryptsetup luksOpen /dev/xvdc backup2\nmount /dev/mapper/backup2 /backup2", 
            "title": "Mount"
        }, 
        {
            "location": "/Ops/Kubernetes/", 
            "text": "Config\n\n\nDifferent configs\n\n\nIf one wants to specify a config other than the default,you may want to run \nkubectl\n with the \n--kubeconfig\n option\n\n\nkubectl --kubeconfig ~/.kube/miniconfig get nodes\n\n\n\n\nThe default being the one stored in \n~/.kube/config\n\n\nChange default namespace\n\n\nEdit \n~/.kube/config/\n\nand change \ncontexts.context.namespace\n\n\nChanging namespace programmatically\n\n\n\n\nYou can permanently save the namespace for all subsequent kubectl commands in that context.\n\n\n\n\nkubectl config set-context $(kubectl config current-context) --namespace=\ninsert-namespace-name-here\n\n\n\n\n\nCurl the api\n\n\nMore info\n\n\nAPISERVER=$(kubectl config view | grep server | cut -f 2- -d \n:\n | tr -d \n \n)\nTOKEN=$(kubectl describe secret $(kubectl get secrets | grep default | cut -f1 -d ' ') | grep -E '^token' | cut -f2 -d':' | tr -d '\\t')\ncurl $APISERVER/api --header \nAuthorization: Bearer $TOKEN\n --insecure\n\n\n\n\nCheck what API endpoints the kubectl command is using\n\n\nv param is configurable\n\n\n$ ./kubectl get pods -v=6\n[...]\nGET https://subdomain.domain.com/api/v1/namespaces/default/pods\n[...]\n\n\n\n\nEnable autocompletion\n\n\nFrom \ncheatsheet\n\n\n$ source \n(kubectl completion bash) # setup autocomplete in bash, bash-completion package should be installed first.\n$ source \n(kubectl completion zsh)  # setup autocomplete in zsh\n\n\n\n\nExecute app on pod\n\n\nkubectl exec -ti drill-alluxio-0 -c drill -- command_path_in_remote_machine -u \njdbc:drill:drillbit=localhost;user=ps\n\n\n\n\n\nActions\n\n\nGet most of the info\n\n\nkubectl get po,svc,rc,rs,pvc --all-namespaces; \necho \nPV--No namespace for them\n; \nkubectl get pv\n\n\n\n\nGet cronjob's yaml\n\n\n# kubectl get cronjob reports-daily -n tvmetrix -o yam\n\n\nLive-edit cronjob\n\n\n# kubectl edit cronjob reports-daily -n tvmetrix\n\n\n\n\nGet logs\n\n\n$ kubectl logs --tail=1000 -f -n monitoring podname prometheus\n\n\n\n\nGet list of pods\n\n\n$ kubectl get pods\n\n\n\n\nGet list of nodes\n\n\n$ kubectl get nodes\n\n\n\n\nGet info about specific pod\n\n\n$ kubectl describe pod storm-nimbus\n\n\n\n\nKubectl remote command execution examples\n\n\nRead line 166 from json gzipped file available in an alluxio mount at /some/path/to folder\n\n\nkubectl exec -ti alluxio-master-0 -- bash -c 'alluxio fs cat /some/path/to/file.json.gz | gzip -d' | sed -n -e 166p | jq '.'", 
            "title": "Kubernetes"
        }, 
        {
            "location": "/Ops/Kubernetes/#config", 
            "text": "", 
            "title": "Config"
        }, 
        {
            "location": "/Ops/Kubernetes/#different-configs", 
            "text": "If one wants to specify a config other than the default,you may want to run  kubectl  with the  --kubeconfig  option  kubectl --kubeconfig ~/.kube/miniconfig get nodes  The default being the one stored in  ~/.kube/config", 
            "title": "Different configs"
        }, 
        {
            "location": "/Ops/Kubernetes/#change-default-namespace", 
            "text": "Edit  ~/.kube/config/ \nand change  contexts.context.namespace", 
            "title": "Change default namespace"
        }, 
        {
            "location": "/Ops/Kubernetes/#changing-namespace-programmatically", 
            "text": "You can permanently save the namespace for all subsequent kubectl commands in that context.   kubectl config set-context $(kubectl config current-context) --namespace= insert-namespace-name-here", 
            "title": "Changing namespace programmatically"
        }, 
        {
            "location": "/Ops/Kubernetes/#curl-the-api", 
            "text": "More info  APISERVER=$(kubectl config view | grep server | cut -f 2- -d  :  | tr -d    )\nTOKEN=$(kubectl describe secret $(kubectl get secrets | grep default | cut -f1 -d ' ') | grep -E '^token' | cut -f2 -d':' | tr -d '\\t')\ncurl $APISERVER/api --header  Authorization: Bearer $TOKEN  --insecure", 
            "title": "Curl the api"
        }, 
        {
            "location": "/Ops/Kubernetes/#check-what-api-endpoints-the-kubectl-command-is-using", 
            "text": "v param is configurable  $ ./kubectl get pods -v=6\n[...]\nGET https://subdomain.domain.com/api/v1/namespaces/default/pods\n[...]", 
            "title": "Check what API endpoints the kubectl command is using"
        }, 
        {
            "location": "/Ops/Kubernetes/#enable-autocompletion", 
            "text": "From  cheatsheet  $ source  (kubectl completion bash) # setup autocomplete in bash, bash-completion package should be installed first.\n$ source  (kubectl completion zsh)  # setup autocomplete in zsh", 
            "title": "Enable autocompletion"
        }, 
        {
            "location": "/Ops/Kubernetes/#execute-app-on-pod", 
            "text": "kubectl exec -ti drill-alluxio-0 -c drill -- command_path_in_remote_machine -u  jdbc:drill:drillbit=localhost;user=ps", 
            "title": "Execute app on pod"
        }, 
        {
            "location": "/Ops/Kubernetes/#actions", 
            "text": "", 
            "title": "Actions"
        }, 
        {
            "location": "/Ops/Kubernetes/#get-most-of-the-info", 
            "text": "kubectl get po,svc,rc,rs,pvc --all-namespaces; \necho  PV--No namespace for them ; \nkubectl get pv", 
            "title": "Get most of the info"
        }, 
        {
            "location": "/Ops/Kubernetes/#get-cronjobs-yaml", 
            "text": "# kubectl get cronjob reports-daily -n tvmetrix -o yam", 
            "title": "Get cronjob's yaml"
        }, 
        {
            "location": "/Ops/Kubernetes/#live-edit-cronjob", 
            "text": "# kubectl edit cronjob reports-daily -n tvmetrix", 
            "title": "Live-edit cronjob"
        }, 
        {
            "location": "/Ops/Kubernetes/#get-logs", 
            "text": "$ kubectl logs --tail=1000 -f -n monitoring podname prometheus", 
            "title": "Get logs"
        }, 
        {
            "location": "/Ops/Kubernetes/#get-list-of-pods", 
            "text": "$ kubectl get pods", 
            "title": "Get list of pods"
        }, 
        {
            "location": "/Ops/Kubernetes/#get-list-of-nodes", 
            "text": "$ kubectl get nodes", 
            "title": "Get list of nodes"
        }, 
        {
            "location": "/Ops/Kubernetes/#get-info-about-specific-pod", 
            "text": "$ kubectl describe pod storm-nimbus", 
            "title": "Get info about specific pod"
        }, 
        {
            "location": "/Ops/Kubernetes/#kubectl-remote-command-execution-examples", 
            "text": "", 
            "title": "Kubectl remote command execution examples"
        }, 
        {
            "location": "/Ops/Kubernetes/#read-line-166-from-json-gzipped-file-available-in-an-alluxio-mount-at-somepathto-folder", 
            "text": "kubectl exec -ti alluxio-master-0 -- bash -c 'alluxio fs cat /some/path/to/file.json.gz | gzip -d' | sed -n -e 166p | jq '.'", 
            "title": "Read line 166 from json gzipped file available in an alluxio mount at /some/path/to folder"
        }, 
        {
            "location": "/Ops/Mount-a-remote-file-system-through-ssh-Using-sshfs/", 
            "text": "Install\n\n\nsudo apt-get install -y sshfs\n\n\n\n\nmake sure the following condition is met. In the local system, type (as root)\n\n\nShould return nothing\n\n\n# sudo modprobe fuse\n\n\n\n\ncreate the mount point\n\n\n$ sudo mkdir /mnt/remote\n$ sudo chown [user-name]:[group-name] /mnt/remote/\n\n\n\n\nAdd yourself to the fuse group\n\n\nadduser [your-user] fuse\n\n\n\n\nswitch to your user and mount the remote filesystem.\n\n\nsshfs remote-user@remote.server:/remote/directory /mnt/remote/\n\n\n\n\nIf you want to mount a directory other than the home directory, you can specify it after the colon. Actually, a generic sshfs command looks like this:\n\n\n$ sshfs [user@]host:[dir] mountpoint [options]\n\n\n\n\nUnmount Your Directory\n\n\nTry:\n\n\nsudo umount /mnt/remote\n\n\n\n\nor\n\n\nfusermount -u mountpoint", 
            "title": "Mount a remote file system through ssh Using sshfs"
        }, 
        {
            "location": "/Ops/Mount-a-remote-file-system-through-ssh-Using-sshfs/#install", 
            "text": "sudo apt-get install -y sshfs", 
            "title": "Install"
        }, 
        {
            "location": "/Ops/Mount-a-remote-file-system-through-ssh-Using-sshfs/#make-sure-the-following-condition-is-met-in-the-local-system-type-as-root", 
            "text": "Should return nothing  # sudo modprobe fuse", 
            "title": "make sure the following condition is met. In the local system, type (as root)"
        }, 
        {
            "location": "/Ops/Mount-a-remote-file-system-through-ssh-Using-sshfs/#create-the-mount-point", 
            "text": "$ sudo mkdir /mnt/remote\n$ sudo chown [user-name]:[group-name] /mnt/remote/", 
            "title": "create the mount point"
        }, 
        {
            "location": "/Ops/Mount-a-remote-file-system-through-ssh-Using-sshfs/#add-yourself-to-the-fuse-group", 
            "text": "adduser [your-user] fuse", 
            "title": "Add yourself to the fuse group"
        }, 
        {
            "location": "/Ops/Mount-a-remote-file-system-through-ssh-Using-sshfs/#switch-to-your-user-and-mount-the-remote-filesystem", 
            "text": "sshfs remote-user@remote.server:/remote/directory /mnt/remote/", 
            "title": "switch to your user and mount the remote filesystem."
        }, 
        {
            "location": "/Ops/Mount-a-remote-file-system-through-ssh-Using-sshfs/#if-you-want-to-mount-a-directory-other-than-the-home-directory-you-can-specify-it-after-the-colon-actually-a-generic-sshfs-command-looks-like-this", 
            "text": "$ sshfs [user@]host:[dir] mountpoint [options]", 
            "title": "If you want to mount a directory other than the home directory, you can specify it after the colon. Actually, a generic sshfs command looks like this:"
        }, 
        {
            "location": "/Ops/Mount-a-remote-file-system-through-ssh-Using-sshfs/#unmount-your-directory", 
            "text": "Try:  sudo umount /mnt/remote  or  fusermount -u mountpoint", 
            "title": "Unmount Your Directory"
        }, 
        {
            "location": "/Ops/Network-stuff/", 
            "text": "Set static IP\n\n\nEdit the following file\n\n\n/etc/dhcpcd.conf\n\n\n\n\nwith the following contents (adapted of course)\n\n\ninterface eth0\n\nstatic ip_address=192.168.0.10/24\nstatic routers=192.168.0.1\nstatic domain_name_servers=192.168.0.1\n\ninterface wlan0\n\nstatic ip_address=192.168.0.200/24\nstatic routers=192.168.0.1\nstatic domain_name_servers=192.168.0.1\n\n\n\n\n\nGet listening ports without netstat\n\n\nss -aut\n\n\n\n\nScan ip range\n\n\nsudo nmap -sP 192.168.*.*\n\n\n\n\nForward packets\n\n\necho 1 \n /proc/sys/net/ipv4/ip_forward", 
            "title": "Network stuff"
        }, 
        {
            "location": "/Ops/Network-stuff/#set-static-ip", 
            "text": "Edit the following file  /etc/dhcpcd.conf  with the following contents (adapted of course)  interface eth0\n\nstatic ip_address=192.168.0.10/24\nstatic routers=192.168.0.1\nstatic domain_name_servers=192.168.0.1\n\ninterface wlan0\n\nstatic ip_address=192.168.0.200/24\nstatic routers=192.168.0.1\nstatic domain_name_servers=192.168.0.1", 
            "title": "Set static IP"
        }, 
        {
            "location": "/Ops/Network-stuff/#get-listening-ports-without-netstat", 
            "text": "ss -aut", 
            "title": "Get listening ports without netstat"
        }, 
        {
            "location": "/Ops/Network-stuff/#scan-ip-range", 
            "text": "sudo nmap -sP 192.168.*.*", 
            "title": "Scan ip range"
        }, 
        {
            "location": "/Ops/Network-stuff/#forward-packets", 
            "text": "echo 1   /proc/sys/net/ipv4/ip_forward", 
            "title": "Forward packets"
        }, 
        {
            "location": "/Ops/New-environment-from-scratch/", 
            "text": "~/.bash_aliases\n\n\nalias ll='ls -l --color'\nalias instalar='sudo apt-get install -y'\n\n\n\n\nPackages\n\n\npython-pip\nvim\npostgresql\n\n\nPython\n\n\nsudo -H pip install virtualenv virtualenvwrapper\n\n\n\n\n\n\nadd \nsource /usr/local/bin/virtualenvwrapper.sh\n to ~/.bashrc\n\n\n\n\ntig\n\n\nUseful git tool", 
            "title": "New environment from scratch"
        }, 
        {
            "location": "/Ops/New-environment-from-scratch/#bash_aliases", 
            "text": "alias ll='ls -l --color'\nalias instalar='sudo apt-get install -y'", 
            "title": "~/.bash_aliases"
        }, 
        {
            "location": "/Ops/New-environment-from-scratch/#packages", 
            "text": "python-pip\nvim\npostgresql", 
            "title": "Packages"
        }, 
        {
            "location": "/Ops/New-environment-from-scratch/#python", 
            "text": "sudo -H pip install virtualenv virtualenvwrapper   add  source /usr/local/bin/virtualenvwrapper.sh  to ~/.bashrc", 
            "title": "Python"
        }, 
        {
            "location": "/Ops/New-environment-from-scratch/#tig", 
            "text": "Useful git tool", 
            "title": "tig"
        }, 
        {
            "location": "/Ops/SSH/", 
            "text": "Basics\n\n\nCreate a new SSH Key\n\n\nssh-keygen -t rsa -C \nyour-email-address\n\n\n\n\n\nBe careful that you don't over-write your existing key for your personal account. Instead, when prompted, save the file as id_rsa_key. In my case, I've saved the file to ~/.ssh/id_rsa_other_key\n\n\nSSH config\n\n\nTaken From \nhere\n\n\nAdd aliases\n\n\nedit\n~/.ssh/config\nand put this contents of $HOME/.ssh/config\n\n\nHost dev\n    HostName dev.example.com\n    Port 22000\n    User fooey\n\n\n\n\nWith this setup, simply\n\n\nssh dev\n\n\n\n\nand the rest will go fine\n\n\nAliases with redirection and more\n\n\nInstead of\n\n\nssh -f -N -L 9906:127.0.0.1:3306 coolio@database.example.com\n\n\n\n\nyou can add an entry to\n\n\n~/.ssh/config\n\n\n\n\nas the following one:\n\n\nHost tunnel\n    HostName database.example.com\n    IdentityFile ~/.ssh/path_to_PRIVATE_key\n    LocalForward 9906 127.0.0.1:3306\n    User coolio\n\n\n\n\nAnd just\n\n\nssh -f -N tunnel\n\n\n\n\nWhich will make it easier to manage\n\n\nCheck key fingerprint\n\n\nSHA-256\n\n\nssh-keygen -lf ~/.ssh/id_rsa.pub\n1024 SHA256:19n6fkdz0qqmowiBy6XEaA87EuG/jgWUr44ZSBhJl6Y (DSA)\n\n\n\n\nMD5\n\n\nssh-keygen -E md5 -lf ~/.ssh/id_rsa.pub\n2048 MD5:4d:5b:97:19:8c:fe:06:f0:29:e7:f5:96:77:cb:3c:71 (DSA)\n\n\n\n\nPasswordless login to machine via SSH\n\n\nssh-keygen -t rsa (Optional)\n\n\nssh b@B mkdir -p ~/.ssh\n\n\ncat ~/.ssh/id_rsa.pub | ssh b@B 'cat \n ~/.ssh/authorized_keys'\n\n\nssh b@B\n(should not ask for pw anymore)\n\n\nwhere B is the host and b is the user\n\n\nExecute graphical command in remote computer\n\n\nssh user@host \nDISPLAY=:0 nohup vlc /path/to/media/movie.mp4\n\n\n\n\n\nDisable SSH password authentication\n\n\nedit \n/etc/ssh/sshd_config\n\nwith contents\n\n\nChallengeResponseAuthentication no\nPasswordAuthentication no\nUsePAM no\n\n\n\n\nRestart daemon\n\n# /etc/init.d/sshd restart\n\n\nAdd private key\n\n\nssh-add public_key_folder/public_key_file\n\n\nIdentity added: public_key_folder/public_key_file (public_key_folder/public_key_file)\n\n\nSSH Config File\n\n\ninstructions", 
            "title": "SSH"
        }, 
        {
            "location": "/Ops/SSH/#basics", 
            "text": "", 
            "title": "Basics"
        }, 
        {
            "location": "/Ops/SSH/#create-a-new-ssh-key", 
            "text": "ssh-keygen -t rsa -C  your-email-address   Be careful that you don't over-write your existing key for your personal account. Instead, when prompted, save the file as id_rsa_key. In my case, I've saved the file to ~/.ssh/id_rsa_other_key", 
            "title": "Create a new SSH Key"
        }, 
        {
            "location": "/Ops/SSH/#ssh-config", 
            "text": "Taken From  here", 
            "title": "SSH config"
        }, 
        {
            "location": "/Ops/SSH/#add-aliases", 
            "text": "edit\n~/.ssh/config\nand put this contents of $HOME/.ssh/config  Host dev\n    HostName dev.example.com\n    Port 22000\n    User fooey  With this setup, simply  ssh dev  and the rest will go fine", 
            "title": "Add aliases"
        }, 
        {
            "location": "/Ops/SSH/#aliases-with-redirection-and-more", 
            "text": "Instead of  ssh -f -N -L 9906:127.0.0.1:3306 coolio@database.example.com  you can add an entry to  ~/.ssh/config  as the following one:  Host tunnel\n    HostName database.example.com\n    IdentityFile ~/.ssh/path_to_PRIVATE_key\n    LocalForward 9906 127.0.0.1:3306\n    User coolio  And just  ssh -f -N tunnel  Which will make it easier to manage", 
            "title": "Aliases with redirection and more"
        }, 
        {
            "location": "/Ops/SSH/#check-key-fingerprint", 
            "text": "", 
            "title": "Check key fingerprint"
        }, 
        {
            "location": "/Ops/SSH/#sha-256", 
            "text": "ssh-keygen -lf ~/.ssh/id_rsa.pub\n1024 SHA256:19n6fkdz0qqmowiBy6XEaA87EuG/jgWUr44ZSBhJl6Y (DSA)", 
            "title": "SHA-256"
        }, 
        {
            "location": "/Ops/SSH/#md5", 
            "text": "ssh-keygen -E md5 -lf ~/.ssh/id_rsa.pub\n2048 MD5:4d:5b:97:19:8c:fe:06:f0:29:e7:f5:96:77:cb:3c:71 (DSA)", 
            "title": "MD5"
        }, 
        {
            "location": "/Ops/SSH/#passwordless-login-to-machine-via-ssh", 
            "text": "ssh-keygen -t rsa (Optional)  ssh b@B mkdir -p ~/.ssh  cat ~/.ssh/id_rsa.pub | ssh b@B 'cat   ~/.ssh/authorized_keys'  ssh b@B (should not ask for pw anymore)  where B is the host and b is the user", 
            "title": "Passwordless login to machine via SSH"
        }, 
        {
            "location": "/Ops/SSH/#execute-graphical-command-in-remote-computer", 
            "text": "ssh user@host  DISPLAY=:0 nohup vlc /path/to/media/movie.mp4", 
            "title": "Execute graphical command in remote computer"
        }, 
        {
            "location": "/Ops/SSH/#disable-ssh-password-authentication", 
            "text": "edit  /etc/ssh/sshd_config \nwith contents  ChallengeResponseAuthentication no\nPasswordAuthentication no\nUsePAM no  Restart daemon # /etc/init.d/sshd restart", 
            "title": "Disable SSH password authentication"
        }, 
        {
            "location": "/Ops/SSH/#add-private-key", 
            "text": "ssh-add public_key_folder/public_key_file  Identity added: public_key_folder/public_key_file (public_key_folder/public_key_file)", 
            "title": "Add private key"
        }, 
        {
            "location": "/Ops/SSH/#ssh-config-file", 
            "text": "instructions", 
            "title": "SSH Config File"
        }, 
        {
            "location": "/Ops/AWS/AWS-Cli-Config/", 
            "text": "Add new profile named new_profile_name\n\n\naws configure --profile new_profile_name", 
            "title": "AWS Cli Config"
        }, 
        {
            "location": "/Ops/AWS/AWS-Cli-Config/#add-new-profile-named-new_profile_name", 
            "text": "aws configure --profile new_profile_name", 
            "title": "Add new profile named new_profile_name"
        }, 
        {
            "location": "/Ops/AWS/AWS-EC2/", 
            "text": "Get list of info aobut EBS volumes\n\n\naws ec2 describe-volumes --profile profile-name", 
            "title": "AWS EC2"
        }, 
        {
            "location": "/Ops/AWS/AWS-EC2/#get-list-of-info-aobut-ebs-volumes", 
            "text": "aws ec2 describe-volumes --profile profile-name", 
            "title": "Get list of info aobut EBS volumes"
        }, 
        {
            "location": "/Ops/AWS/AWS-Kinesis/", 
            "text": "AWS-CLI\n\n\nPython\n\n\n\n\nAWS CLI\n\n\nWarning\n Before using check that you have properly set the \nAWS_PROFILE\n env variable to some profile existing in \n~/.aws/credentials\n, or comfortable using the aws default profile\nas \n\n\n$ export AWS_PROFILE=analytics-storm\n\n\n\n\nGet kinesis decoded data\n\n\naws kinesis get-records --shard-iterator some_shard_hash --profile some-profile | jq \".Records [] .Data\" | tr -d '\n\"' | base64 -d\n\n\n$ aws kinesis describe-stream --stream-name stream_name --profile user2\n\n{\n    \nStreamDescription\n: {\n        \nRetentionPeriodHours\n: 24, \n        \nStreamName\n: \nstream_name\n, \n        \nShards\n: [\n            {\n                \nShardId\n: \nshardId-000000000000\n, \n                \nHashKeyRange\n: {\n                    \nEndingHashKey\n: \nwhateverhashkey\n, \n                    \nStartingHashKey\n: \n0\n\n                }, \n                \nSequenceNumberRange\n: {\n                    \nStartingSequenceNumber\n: \nwhateversequencenumber\n\n                }\n            }, \n            {\n                \nShardId\n: \nshardId-000000000001\n, \n                \nHashKeyRange\n: {\n                    \nEndingHashKey\n: \nwhateverhashke\n, \n                    \nStartingHashKey\n: \nwhatevernumber\n\n                }, \n                \nSequenceNumberRange\n: {\n                    \nStartingSequenceNumber\n: \nsomenumber\n\n                }\n            }\n        ], \n        \nStreamARN\n: \narn:aws:kinesis:region:accountNumber:stream/stream_name\n, \n        \nEnhancedMonitoring\n: [\n            {\n                \nShardLevelMetrics\n: []\n            }\n        ], \n        \nStreamStatus\n: \nACTIVE\n\n    }\n}\n\n\n\n\n$ aws kinesis get-shard-iterator --stream-name tvmetrix --shard-id shardId-000000000001 --shard-iterator-type LATEST\n{\n    \nShardIterator\n: \nwhateversharditeratorwithnumberslettersandslashes \n\n}\n\n\n\n\n\nget shard iterator for specific date (take into account the retention policy for your kinesis service)\n\n\n$ aws kinesis get-shard-iterator --stream-name tvmetrix --shard-id shardId-000000000001 --shard-iterator-type AT_TIMESTAMP --timestamp \n2017-05-25 08:00:00\n\n\n\n\n\n\n\n\n\nshardId is one appearing in the describe-stream command above  \n\n\n\n\n\n\nfor more info about shard-iterator-type\nhttp://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html#API_GetShardIterator_RequestSyntax\n\n\n\n\n\n\n$ aws kinesis get-records --shard-iterator whateversharditeratorwithnumberslettersandslashes --limit 1 --profile user2\n{\n    \nRecords\n: [\n        {\n            \nData\n: \nsome_encoded_data\n, \n            \nPartitionKey\n: \nsome_numbers\n, \n            \nApproximateArrivalTimestamp\n: 1490964900.808, \n            \nSequenceNumber\n: \nsome_very_long_number\n\n        }\n    ], \n    \nNextShardIterator\n: \nsome_sequence_of_letters_and_numbers_and_slashes\n, \n    \nMillisBehindLatest\n: 0\n}\n\n\n\n\n\nPython\n\n\nimport json\nimport time\nfrom boto import kinesis\n\nSTREAM_NAME=\nstream_name\n\nSTREAM_REGION=\nstream_region\n\n\n# Kinesis initialization and information\nkinesis = kinesis.connect_to_region(STREAM_REGION)\nkinesis.describe_stream(STREAM_NAME)\n\n# Put data\nc = open('sample_data.json').read()\nprint \n********************\n\nprint \nWill try to send data: \n\nprint c\nkinesis.put_record(STREAM_NAME, c, \npartitonkey\n)\nprint \nData sent\n\nprint \n********************\n\n\n# Read data\nprint \n********************\n\nprint \nWill try to read data\n\nshard_id = 'shardId-00000000001'\nshard_it = kinesis.get_shard_iterator(STREAM_NAME, shard_id, \nLATEST\n)[\nShardIterator\n]\nwhile True:\n    out = kinesis.get_records(shard_it, limit=2)\n    shard_it = out['NextShardIterator']\n    print out\n    time.sleep(0.2)\nprint \n********************\n\n\n\n\n\nimport sys\nfrom time import strftime, gmtime\nimport logging\nimport json\n\n# Boto stuff\nfrom boto import kinesis\nimport boto3\nimport botocore\n\nmax_records = 20000\n\nlogging.basicConfig(level=logging.ERROR)\n\nSTREAM_NAME=\nSTREAM_NAME\n\nSTREAM_REGION=\nus-east-1\n\n\nsession = boto3.Session(profile_name='some-profile')\nclient = session.client(service_name='kinesis')\n\nif len(sys.argv) \n 1:\n    timestamp = sys.argv[1]\nelse:\n    timestamp = \n2017-07-17T17:00:00.000-00:00\n\n\n# Get shard iterator dict\nshardId=\nshardId-000000000001\n\nd = client.get_shard_iterator(ShardIteratorType=\nAT_TIMESTAMP\n, ShardId=shardId, Timestamp=timestamp, StreamName='tvmetrix')\niterator = d.get('ShardIterator')\nnextIterator = iterator\n\n# Debug stuff files\nfile_name_debug = \ndebug_file_{}.debug\n.format(strftime(\n%Y-%m-%d_%H-%M-%S\n, gmtime()))\ndebug_file = open(file_name_debug, 'w')\nfile_name_data = \ndata_file_{}.log\n.format(strftime(\n%Y-%m-%d_%H-%M-%S\n, gmtime()))\ndata_file = open(file_name_data, 'w')\nprint \nDebug file will be: {}\n.format(file_name_debug)\nprint \nData file will be: {}\n.format(file_name_data)\n\ncounter = 0\nwhile counter \n max_records:\n    try:\n        response = client.get_records(ShardIterator=nextIterator, Limit=20)\n        logging.debug(response)\n        print response\n        debug_file.write(str(response) + '\\n')\n        records = response.get('Records')\n        nextIterator = response.get(\nNextShardIterator\n)\n        print \nThere are {} records\n.format(len(records))\n        counter += len(records)\n        for record in records:\n            print \n*\n * 10\n            print \nRecord\n\n            print \n-\n * 10\n            data = record.get('Data')\n            tokens = data.split('\\n')\n            for token in tokens:\n                data_dict = json.loads(token)\n                ### read stuff\n    except ValueError as valueError:\n        print valueError\n    except botocore.exceptions.ClientError as ce:\n        print \n*\n * 6, \nWARNING\n, \n*\n * 6\n        print ce\n        print \nLimit exceeded\n\n        print \n*\n * 6, \nWARNING\n, \n*\n * 6\n        break\ndebug_file.close()\ndata_file.close()", 
            "title": "AWS Kinesis"
        }, 
        {
            "location": "/Ops/AWS/AWS-Kinesis/#aws-cli", 
            "text": "Warning  Before using check that you have properly set the  AWS_PROFILE  env variable to some profile existing in  ~/.aws/credentials , or comfortable using the aws default profile\nas   $ export AWS_PROFILE=analytics-storm", 
            "title": "AWS CLI"
        }, 
        {
            "location": "/Ops/AWS/AWS-Kinesis/#get-kinesis-decoded-data", 
            "text": "aws kinesis get-records --shard-iterator some_shard_hash --profile some-profile | jq \".Records [] .Data\" | tr -d '\n\"' | base64 -d  $ aws kinesis describe-stream --stream-name stream_name --profile user2\n\n{\n     StreamDescription : {\n         RetentionPeriodHours : 24, \n         StreamName :  stream_name , \n         Shards : [\n            {\n                 ShardId :  shardId-000000000000 , \n                 HashKeyRange : {\n                     EndingHashKey :  whateverhashkey , \n                     StartingHashKey :  0 \n                }, \n                 SequenceNumberRange : {\n                     StartingSequenceNumber :  whateversequencenumber \n                }\n            }, \n            {\n                 ShardId :  shardId-000000000001 , \n                 HashKeyRange : {\n                     EndingHashKey :  whateverhashke , \n                     StartingHashKey :  whatevernumber \n                }, \n                 SequenceNumberRange : {\n                     StartingSequenceNumber :  somenumber \n                }\n            }\n        ], \n         StreamARN :  arn:aws:kinesis:region:accountNumber:stream/stream_name , \n         EnhancedMonitoring : [\n            {\n                 ShardLevelMetrics : []\n            }\n        ], \n         StreamStatus :  ACTIVE \n    }\n}  $ aws kinesis get-shard-iterator --stream-name tvmetrix --shard-id shardId-000000000001 --shard-iterator-type LATEST\n{\n     ShardIterator :  whateversharditeratorwithnumberslettersandslashes  \n}  get shard iterator for specific date (take into account the retention policy for your kinesis service)  $ aws kinesis get-shard-iterator --stream-name tvmetrix --shard-id shardId-000000000001 --shard-iterator-type AT_TIMESTAMP --timestamp  2017-05-25 08:00:00     shardId is one appearing in the describe-stream command above      for more info about shard-iterator-type\nhttp://docs.aws.amazon.com/kinesis/latest/APIReference/API_GetShardIterator.html#API_GetShardIterator_RequestSyntax    $ aws kinesis get-records --shard-iterator whateversharditeratorwithnumberslettersandslashes --limit 1 --profile user2\n{\n     Records : [\n        {\n             Data :  some_encoded_data , \n             PartitionKey :  some_numbers , \n             ApproximateArrivalTimestamp : 1490964900.808, \n             SequenceNumber :  some_very_long_number \n        }\n    ], \n     NextShardIterator :  some_sequence_of_letters_and_numbers_and_slashes , \n     MillisBehindLatest : 0\n}", 
            "title": "Get kinesis decoded data"
        }, 
        {
            "location": "/Ops/AWS/AWS-Kinesis/#python", 
            "text": "import json\nimport time\nfrom boto import kinesis\n\nSTREAM_NAME= stream_name \nSTREAM_REGION= stream_region \n\n# Kinesis initialization and information\nkinesis = kinesis.connect_to_region(STREAM_REGION)\nkinesis.describe_stream(STREAM_NAME)\n\n# Put data\nc = open('sample_data.json').read()\nprint  ******************** \nprint  Will try to send data:  \nprint c\nkinesis.put_record(STREAM_NAME, c,  partitonkey )\nprint  Data sent \nprint  ******************** \n\n# Read data\nprint  ******************** \nprint  Will try to read data \nshard_id = 'shardId-00000000001'\nshard_it = kinesis.get_shard_iterator(STREAM_NAME, shard_id,  LATEST )[ ShardIterator ]\nwhile True:\n    out = kinesis.get_records(shard_it, limit=2)\n    shard_it = out['NextShardIterator']\n    print out\n    time.sleep(0.2)\nprint  ********************   import sys\nfrom time import strftime, gmtime\nimport logging\nimport json\n\n# Boto stuff\nfrom boto import kinesis\nimport boto3\nimport botocore\n\nmax_records = 20000\n\nlogging.basicConfig(level=logging.ERROR)\n\nSTREAM_NAME= STREAM_NAME \nSTREAM_REGION= us-east-1 \n\nsession = boto3.Session(profile_name='some-profile')\nclient = session.client(service_name='kinesis')\n\nif len(sys.argv)   1:\n    timestamp = sys.argv[1]\nelse:\n    timestamp =  2017-07-17T17:00:00.000-00:00 \n\n# Get shard iterator dict\nshardId= shardId-000000000001 \nd = client.get_shard_iterator(ShardIteratorType= AT_TIMESTAMP , ShardId=shardId, Timestamp=timestamp, StreamName='tvmetrix')\niterator = d.get('ShardIterator')\nnextIterator = iterator\n\n# Debug stuff files\nfile_name_debug =  debug_file_{}.debug .format(strftime( %Y-%m-%d_%H-%M-%S , gmtime()))\ndebug_file = open(file_name_debug, 'w')\nfile_name_data =  data_file_{}.log .format(strftime( %Y-%m-%d_%H-%M-%S , gmtime()))\ndata_file = open(file_name_data, 'w')\nprint  Debug file will be: {} .format(file_name_debug)\nprint  Data file will be: {} .format(file_name_data)\n\ncounter = 0\nwhile counter   max_records:\n    try:\n        response = client.get_records(ShardIterator=nextIterator, Limit=20)\n        logging.debug(response)\n        print response\n        debug_file.write(str(response) + '\\n')\n        records = response.get('Records')\n        nextIterator = response.get( NextShardIterator )\n        print  There are {} records .format(len(records))\n        counter += len(records)\n        for record in records:\n            print  *  * 10\n            print  Record \n            print  -  * 10\n            data = record.get('Data')\n            tokens = data.split('\\n')\n            for token in tokens:\n                data_dict = json.loads(token)\n                ### read stuff\n    except ValueError as valueError:\n        print valueError\n    except botocore.exceptions.ClientError as ce:\n        print  *  * 6,  WARNING ,  *  * 6\n        print ce\n        print  Limit exceeded \n        print  *  * 6,  WARNING ,  *  * 6\n        break\ndebug_file.close()\ndata_file.close()", 
            "title": "Python"
        }, 
        {
            "location": "/Ops/AWS/AWS-Redshift/", 
            "text": "Check the \npostgresql wiki page\n out:\n\n\nCheck out \nredshift developer's guide\n\n\n\n\n[List databases] (https://gist.github.com/patsancu/50ea9416c0c7ba5746d045e9b047955d)\n\n\nLoad data into redsfhit from s3\n\n\nData can be loaded recursively.\nIf there's a folder with this structure\n\n\na/\n  b/\n    p.json.gz\n  c/\n    q.json.gz\n    r.json.gz\n\n\n\n\nCalling the copy sentence with the folder \na\n as source will copy all files under the folder recursively\n\n\ncopy schema.table_name\nfrom 's3://bucket-name/some_folder/some_file.json.gz'\n-- from 's3://bucket-name/a'\nwith credentials 'aws_access_key_id=some_access_key;ws_secret_access_key=supersupersecretkey'\n[gzip]\nformat as json 'auto'\n[region 'us-east-1']\n-- If the Amazon S3 buckets that hold the data files do not reside in the same region as your cluster, you must use the REGION parameter to specify the region in which the data is located.\n\n\n\n\nEscape strings with Escape\n\n\nRemove\n the format as csv thing\n\n\ncopy analyticsmodel.playback\nfrom :sql:source\nwith credentials :sql:redshift-credentials\ndelimiter '~'\nignoreheader as 1\n[escape]\n[truncatecolumns Truncates data in columns to the appropriate number of characters it has been specified]\n\n\n\n\nLoad into redshift with custom field ordering\n\n\nYou can specify a comma-separated list of column names to load source data fields into specific target columns.\n\nDocs\n\n\ncopy schema.table (column_a, column_b, column_c, column_d, column_e, colummn_f)\nfrom 's3://some_file.csv'\nwith credentials 'aws_access_key_id=some_access_key;ws_secret_access_key=supersupersecretkey'\nformat as csv\nignoreheader as 1\nTRUNCATECOLUMNS\n\n\n\n\nCheck errors\n\n\nselect * from stl_load_errors\norder by starttime desc;\n\n\n\n\nCheck info about permanent tables\n\n\nThe STV_TBL_PERM table contains information about the permanent tables in Amazon Redshift. More info \nhere\n\n\nselect * FROM stv_tbl_perm ;\n\n\n\n\nSize info about tables\n\n\nFirst method\n\n\nselect \ndatabase\n,\n\nschema\n || '.' || \ntable\n, \nsize\n as \nsize in Mb\n, \ntbl_rows\n as \nrows\n\nfrom svv_table_info\n\n\n\n\nSecond method\n\n\nThe query below's info  is \nnot exhaustive nor complete\n\n\nSELECT TRIM(pgdb.datname) AS DATABASE,\n      TRIM(pgn.nspname) AS SCHEMA,\n      TRIM(a.name) AS TABLE,\n      b.mbytes,\n      a.rows\nFROM (SELECT db_id,\n            id,\n            name,\n            SUM(ROWS) AS ROWS\n     FROM stv_tbl_perm a\n     GROUP BY db_id,\n              id,\n              name) AS a\n JOIN pg_class AS pgc ON pgc.oid = a.id\n JOIN pg_namespace AS pgn ON pgn.oid = pgc.relnamespace\n JOIN pg_database AS pgdb ON pgdb.oid = a.db_id\n JOIN (SELECT tbl, COUNT(*) AS mbytes FROM stv_blocklist GROUP BY tbl) b ON a.id = b.tbl\nORDER BY a.db_id,\n        a.name;\n\n\n\n\nGenerate date series\n\n\n\n\nGenerate series using \nany\n table as a dummy table.\n\n\n\n\ncreate table fechas as\nselect (\n    date('2017-06-30') + row_number() over (order by true)\n  )::date as fecha\nfrom ibc.playback limit 40\n\n\n\n\nWarning\n. The date_series function thing doesn't work that well on redshift when doing joins and stuff like that. For more info, check redshift's developer guide.\n\n\nWITH date_series_bounds AS (\n    SELECT date('2012-12-21') as start, date('2013-08-23') as end\n), date_series AS (\n    select date(days.start + days.interval)\n    from (\n        select bounds.start, generate_series(0, bounds.end - bounds.start) AS interval from date_series_bounds bounds\n    ) as days\n)\nselect * from date_series\n\n\n\n\nor\n\n\nselect current_date - (n*30 || ' minutes')::interval\nfrom generate_series (0, 100*5-1) n\n\n\n\n\nor\n\n\nselect substr(to_date('2017-06-22', 'YYYY-MM-DD') + (n || ' days')::interval, 1,10)\nfrom generate_series (0, 6) n\n\n\n\n\nList schemas\n\n\nselect *\nfrom information_schema.schemata\n\n\n\n\nCreate schema\n\n\nCREATE SCHEMA IF NOT EXISTS schema_name\n\n\nCheck data load\n\n\nselect * from STL_FILE_SCAN\nwhere name like '%screentime%'\norder by curtime desc", 
            "title": "AWS Redshift"
        }, 
        {
            "location": "/Ops/AWS/AWS-Redshift/#load-data-into-redsfhit-from-s3", 
            "text": "Data can be loaded recursively.\nIf there's a folder with this structure  a/\n  b/\n    p.json.gz\n  c/\n    q.json.gz\n    r.json.gz  Calling the copy sentence with the folder  a  as source will copy all files under the folder recursively  copy schema.table_name\nfrom 's3://bucket-name/some_folder/some_file.json.gz'\n-- from 's3://bucket-name/a'\nwith credentials 'aws_access_key_id=some_access_key;ws_secret_access_key=supersupersecretkey'\n[gzip]\nformat as json 'auto'\n[region 'us-east-1']\n-- If the Amazon S3 buckets that hold the data files do not reside in the same region as your cluster, you must use the REGION parameter to specify the region in which the data is located.", 
            "title": "Load data into redsfhit from s3"
        }, 
        {
            "location": "/Ops/AWS/AWS-Redshift/#escape-strings-with-escape", 
            "text": "Remove  the format as csv thing  copy analyticsmodel.playback\nfrom :sql:source\nwith credentials :sql:redshift-credentials\ndelimiter '~'\nignoreheader as 1\n[escape]\n[truncatecolumns Truncates data in columns to the appropriate number of characters it has been specified]", 
            "title": "Escape strings with Escape"
        }, 
        {
            "location": "/Ops/AWS/AWS-Redshift/#load-into-redshift-with-custom-field-ordering", 
            "text": "You can specify a comma-separated list of column names to load source data fields into specific target columns. Docs  copy schema.table (column_a, column_b, column_c, column_d, column_e, colummn_f)\nfrom 's3://some_file.csv'\nwith credentials 'aws_access_key_id=some_access_key;ws_secret_access_key=supersupersecretkey'\nformat as csv\nignoreheader as 1\nTRUNCATECOLUMNS", 
            "title": "Load into redshift with custom field ordering"
        }, 
        {
            "location": "/Ops/AWS/AWS-Redshift/#check-errors", 
            "text": "select * from stl_load_errors\norder by starttime desc;", 
            "title": "Check errors"
        }, 
        {
            "location": "/Ops/AWS/AWS-Redshift/#check-info-about-permanent-tables", 
            "text": "The STV_TBL_PERM table contains information about the permanent tables in Amazon Redshift. More info  here  select * FROM stv_tbl_perm ;", 
            "title": "Check info about permanent tables"
        }, 
        {
            "location": "/Ops/AWS/AWS-Redshift/#size-info-about-tables", 
            "text": "", 
            "title": "Size info about tables"
        }, 
        {
            "location": "/Ops/AWS/AWS-Redshift/#first-method", 
            "text": "select  database , schema  || '.' ||  table ,  size  as  size in Mb ,  tbl_rows  as  rows \nfrom svv_table_info", 
            "title": "First method"
        }, 
        {
            "location": "/Ops/AWS/AWS-Redshift/#second-method", 
            "text": "The query below's info  is  not exhaustive nor complete  SELECT TRIM(pgdb.datname) AS DATABASE,\n      TRIM(pgn.nspname) AS SCHEMA,\n      TRIM(a.name) AS TABLE,\n      b.mbytes,\n      a.rows\nFROM (SELECT db_id,\n            id,\n            name,\n            SUM(ROWS) AS ROWS\n     FROM stv_tbl_perm a\n     GROUP BY db_id,\n              id,\n              name) AS a\n JOIN pg_class AS pgc ON pgc.oid = a.id\n JOIN pg_namespace AS pgn ON pgn.oid = pgc.relnamespace\n JOIN pg_database AS pgdb ON pgdb.oid = a.db_id\n JOIN (SELECT tbl, COUNT(*) AS mbytes FROM stv_blocklist GROUP BY tbl) b ON a.id = b.tbl\nORDER BY a.db_id,\n        a.name;", 
            "title": "Second method"
        }, 
        {
            "location": "/Ops/AWS/AWS-Redshift/#generate-date-series", 
            "text": "Generate series using  any  table as a dummy table.   create table fechas as\nselect (\n    date('2017-06-30') + row_number() over (order by true)\n  )::date as fecha\nfrom ibc.playback limit 40  Warning . The date_series function thing doesn't work that well on redshift when doing joins and stuff like that. For more info, check redshift's developer guide.  WITH date_series_bounds AS (\n    SELECT date('2012-12-21') as start, date('2013-08-23') as end\n), date_series AS (\n    select date(days.start + days.interval)\n    from (\n        select bounds.start, generate_series(0, bounds.end - bounds.start) AS interval from date_series_bounds bounds\n    ) as days\n)\nselect * from date_series  or  select current_date - (n*30 || ' minutes')::interval\nfrom generate_series (0, 100*5-1) n  or  select substr(to_date('2017-06-22', 'YYYY-MM-DD') + (n || ' days')::interval, 1,10)\nfrom generate_series (0, 6) n", 
            "title": "Generate date series"
        }, 
        {
            "location": "/Ops/AWS/AWS-Redshift/#list-schemas", 
            "text": "select *\nfrom information_schema.schemata", 
            "title": "List schemas"
        }, 
        {
            "location": "/Ops/AWS/AWS-Redshift/#create-schema", 
            "text": "CREATE SCHEMA IF NOT EXISTS schema_name", 
            "title": "Create schema"
        }, 
        {
            "location": "/Ops/AWS/AWS-Redshift/#check-data-load", 
            "text": "select * from STL_FILE_SCAN\nwhere name like '%screentime%'\norder by curtime desc", 
            "title": "Check data load"
        }, 
        {
            "location": "/Ops/AWS/S3/", 
            "text": "Sync folders\n\n\n$ aws s3 sync s3://bucketname1/path/to/folder/2017-04-05 s3://bucketname1/path/to/folder/2017-04-05", 
            "title": "S3"
        }, 
        {
            "location": "/Ops/AWS/S3/#sync-folders", 
            "text": "$ aws s3 sync s3://bucketname1/path/to/folder/2017-04-05 s3://bucketname1/path/to/folder/2017-04-05", 
            "title": "Sync folders"
        }, 
        {
            "location": "/Ops/Shell/Script-building/", 
            "text": "Simple stop\n\n\necho \nPress enter to continue\n; read noing\n\n\n\n\nColorize cat output of source files\n\n\n$ pip install Pygments\n\n\nhttp://pygments.org/\n\n\nwith pygmentize -g filename\n\n\nYes no answer\n\n\ntestFile=/home/patrick/dev/master.properties\nsampleService='iris-cms-metadata-management-service'\nif [ ! -f $testFile ]; then\n  tput setaf 2\n  echo \ntest properties file $testFile is missing\n\n  tput sgr0else  tput setaf 1;\n  echo \nWill delete all data from the CMS db.\n;\n  tput sgr0  ;\n  read -r -p \nAre you sure? [y/N] \n response\n  case $response in      [yY][eE][sS]|[yY])\n    cd $sampleService;\n    gradle dropDatabase -Parchaius.url=file:$testFile ;\n    cd -;\n    ;;\n    *)\n    echo \nOK, no harm done\n;\n    ;;\n  esac\nfi\n\n\n\n\nArgument parsing\n\n\nvflag=off\nfilename=\nwhile getopts vf: opt\ndo\n    case \n$opt\n in\n      v)  vflag=on;;\n      f)  filename=\n$OPTARG\n;;\n      \\?)       # unknown flag\n          echo \n2 \\\n      \nusage: $0 [-v] [-f filename] [file ...]\n\n      exit 1;;\n    esac\ndone\nshift `expr $OPTIND - 1`\n\n\n\n\nArrays\n\n\ndistro=(\nredhat\n \ndebian\n \ngentoo\n)\necho ${distro[2]} # will print gentoo\necho ${#distro[@]} # will print array length: 3", 
            "title": "Script building"
        }, 
        {
            "location": "/Ops/Shell/Script-building/#simple-stop", 
            "text": "echo  Press enter to continue ; read noing", 
            "title": "Simple stop"
        }, 
        {
            "location": "/Ops/Shell/Script-building/#colorize-cat-output-of-source-files", 
            "text": "$ pip install Pygments  http://pygments.org/  with pygmentize -g filename", 
            "title": "Colorize cat output of source files"
        }, 
        {
            "location": "/Ops/Shell/Script-building/#yes-no-answer", 
            "text": "testFile=/home/patrick/dev/master.properties\nsampleService='iris-cms-metadata-management-service'\nif [ ! -f $testFile ]; then\n  tput setaf 2\n  echo  test properties file $testFile is missing \n  tput sgr0else  tput setaf 1;\n  echo  Will delete all data from the CMS db. ;\n  tput sgr0  ;\n  read -r -p  Are you sure? [y/N]   response\n  case $response in      [yY][eE][sS]|[yY])\n    cd $sampleService;\n    gradle dropDatabase -Parchaius.url=file:$testFile ;\n    cd -;\n    ;;\n    *)\n    echo  OK, no harm done ;\n    ;;\n  esac\nfi", 
            "title": "Yes no answer"
        }, 
        {
            "location": "/Ops/Shell/Script-building/#argument-parsing", 
            "text": "vflag=off\nfilename=\nwhile getopts vf: opt\ndo\n    case  $opt  in\n      v)  vflag=on;;\n      f)  filename= $OPTARG ;;\n      \\?)       # unknown flag\n          echo  2 \\\n       usage: $0 [-v] [-f filename] [file ...] \n      exit 1;;\n    esac\ndone\nshift `expr $OPTIND - 1`", 
            "title": "Argument parsing"
        }, 
        {
            "location": "/Ops/Shell/Script-building/#arrays", 
            "text": "distro=( redhat   debian   gentoo )\necho ${distro[2]} # will print gentoo\necho ${#distro[@]} # will print array length: 3", 
            "title": "Arrays"
        }, 
        {
            "location": "/Ops/Shell/Scripts/", 
            "text": "Put in ~/bin\n\n\ngeneral\n\n\nbyzanz-record-window\n\n\nrecords screen as a gif\n\n\nwork\n\n\nproxymetrix", 
            "title": "Scripts"
        }, 
        {
            "location": "/Ops/Shell/Scripts/#general", 
            "text": "", 
            "title": "general"
        }, 
        {
            "location": "/Ops/Shell/Scripts/#byzanz-record-window", 
            "text": "records screen as a gif", 
            "title": "byzanz-record-window"
        }, 
        {
            "location": "/Ops/Shell/Scripts/#work", 
            "text": "", 
            "title": "work"
        }, 
        {
            "location": "/Ops/Shell/Scripts/#proxymetrix", 
            "text": "", 
            "title": "proxymetrix"
        }, 
        {
            "location": "/Ops/Shell/Shell/", 
            "text": "Setup a local smtpserver\n\n\n$ python -m smtpd -n -c DebuggingServer localhost:1025\n\n\n\n\nChange shell\n\n\nchsh -s /usr/local/bin/bash [username]\n\n\n\n\nExecute command without any env variable or with just a few\n\n\nzsh $ P=\nZZZ\n; echo $P\nZZZ\nzsh $ echo $PATATA\n\n$ env -i PATATA=\npatatina\n PAT=\nata\n bash\necho $ZZZ\n\n$ echo $PATATA\npatatina\n\n\n\n\nSuper simple text file creation\n\n\nDON'T USE IN EXISTING FILES, IT WILL OVERWRITE THEM\n\n\nWrite to file until EOF is written (in a single line)\n\n\n$ cat \nEOF \n p.c\nsome line\nanother line\nEOF\n$ cat p.c\nsome line\nanother line\n\n\n\n\nDouble substution\n\n\n$ foo=\nwhatever\n\n$ i=foo\n$ echo $echo ${!i}\nwhatever\n\n\n\n\nExecute process in background with lock\n\n\nExecutes process with nohup and flock\n\n\nSee \ngist\n\n\nShutdown process above\n\n\nSee \ngist\n\n\nFlock\n\n\nUse flock as in \nhere\n\n\nGet url for git repo\n\n\nxdg-open `git remote -v | grep fetch | head -1 | cut -f2 | cut -d' ' -f1 | sed -e's/git@/http:\\/\\//' -e's/\\.git$//' | sed -E 's/(\\/\\/[^:]*):/\\1\\//'`\n\n\n\n\nWget\n\n\nDownload all pdfs linked in a website\n\n\nWarning:\n Even if it recreates only the pdfs, it will download \nevery\n file referenced by links\n\n\n$ wget -r -A.pdf http://people.seas.harvard.edu/~minilek/cs229r/fall15/lec.html\n\n\n\n\nDownload all pdfs linked in a website, including linked websites (1 level)\n\n\n$ wget -r -l1 -A.pdf http://people.seas.harvard.edu/~minilek/cs229r/fall15/lec.html\n\n\n\n\nBash-erize cli any Python object\n\n\npython-fire\n\n\nSet bash variable default value\n\n\n${parameter=default}, ${parameter:=default}\n\nThe \n:\n makes a difference only when \n$parameter\n has been declared and is null\n\n\n$ echo $var\n\n$ echo ${var:=abc}   # abc\nabc\n$ echo ${var}   # abc\nabc\n\n\n\n\n\nhttp://www.tldp.org/LDP/abs/html/parameter-substitution.html#PARAMSUBREF\n\n\nOne line to pretty separate jsons\n\n\ncurl -s localhost:7080/mappings  |  python -mjson.tool\n\n\nXargs with files with spaces on path\n\n\nls *mp3 | xargs -d '\\n' mplayer\n\n\nWord frequency of text file\n\n\ncat ~/filename.txt | tr ' ' '\\n' | sort | uniq -c | awk '{print $2\"@\"$1}'\n\n\nEgrep\n\n\n\n\nGiven a file with json lines having a field \"parentalRating\" and a number (e.g. '\"parentalRating\":\"17\"') , the following command will get the set of unique parental ratings, along with their frequencies in (frequency, key) pairs.\n\n\nThe \no\n option is to output only the strings matching the egrep regex\n\n\n\n\n$ egrep \nparentalRating\\\n:\\\n[0-9]+\n file.json -o | cut -d ':' -f 2 | tr -d '\n' | sort | uniq -c\n   1314 0\n   6209 13\n   1525 15\n   4518 17\n      3 18\n   3564 7\n\n\n\n\n\nDiff folders\n\n\nhttps://gist.github.com/37b660b98f6d29ecd1af87ffb426f380\n\n\nRecord Your Command Line Session\n\n\n\n\n$ script\n\n\nExit typing \n$ exit\n\n\nAll of your typings (and their reults) will be saved to a file named \ntypescript\n\n\n\n\nGlobstar\n\n\nTo allow double \"*\" as a recursive filepath parameter, eg\n\n\nls **/*.xml\n\n\n\n\nadd\n\n\nshopt -s globstar\n\n\n\n\nto \n.bashrc\n\n\nSubstring Removal\n\n\nDeletes shortest match of $substring from front of $string.\n\n\n${string#substring}\n\n\n\n\nDeletes longest match of $substring from front of $string.\n\n\n${string##substring}\n\n\n\n\nGet last folder of current working directoy\n\n\n$ pwd\n/home/patrick/dev/python\n$ echo ${PWD##*/}\npython\n\n\n\n\nBasic integer sequence loop\n\n\n#!/bin/bash\nfor i in `seq 1 10`;\n   do\n     echo $i\n   done\n\n\n\n\nDisplay Output as a Table\n\n\ncat /etc/passwd | column -t -s\n\n\n\n\nRepeat a Command Until It Runs Successfully\n\n\nwhile true; do ping -c 1 8.8.8.8 \n /dev/null 2\n1 \n break; done\n\n\n\n\nSuspend machine\n\n\nAs root,\n\n\n# pm-suspend\n\n\n\n\nConvert a File to Upper or Lower Case\n\n\ncat myfile | tr a-z A-Z \n output.txt\n\n\n\n\nSort Processes by Memory Usage\n\n\nps aux | sort -rnk 4\n\n\n\n\nSort Processes by CPU Usage\n\n\nps aux | sort -nk 3\n\n\n\n\nXargs example\n\n\nls /etc/*.conf | xargs -i cp {} /home/likegeeks/Desktop/out\n\n\n\n\ndd\n\n\nBasic syntax\n\n\ndd bs=4M if=/dev/sdd of=from-sd-card.img\n\n\n\n\nSee progress of dd\n\n\nsudo pkill -USR1 -n -x dd\n\n\n\n\nThis will show the progess \nin the same terminal dd was executed\n\n\nCreate File With a Specific Size\n\n\ndd if=/dev/zero of=out.txt bs=1M count=10\n\n\n\n\nShorten url with goo.gl\n\n\nThe \n$GOOGLE_SHORTEN_API_KEY\n variable needs to be set, and jq needs to be installed\n\n\nshorten(){\n    curl \nhttps://www.googleapis.com/urlshortener/v1/url?key=$GOOGLE_SHORTEN_API_KEY\n -H 'Content-Type: application/json' -d \n{'longUrl': \\\n$1\\\n}\n | jq '.id'\n}\n\n\n\n\nAutomatically press keys when condition is met\n\n\nUse expect as in \nhere\n\n\nConvert windows-encoded text file to unix-encoded\n\n\nawk 'BEGIN{RS=\n^$\n;ORS=\n;getline;gsub(\n\\r\n,\n);print\nARGV[1]}' file_name\n\n\n\n\nRead lines from file in a for loop\n\n\nFS=$'\\n'       # make newlines the only separator\nfor j in $(cat ./file_wget_med)\ndo\n    echo \n$j\n\ndone\n\n\n\n\nor\n\n\ninput=\n/path/to/txt/file\n\nwhile IFS= read -r var\ndo\n  echo \n$var\n\ndone \n \n$input\n\n\n\n\n\nDisplay info about memory\n\n\n$ sudo lshw -C memory\n\n\nOpen the current repo on a specific web repo\n\n\nmy_hgweb() {\n         if [ -d .hg ]; then\n            xdg-open http://web-repo-address/hg/${PWD##*/} \n /dev/null\n         else\n            echo Not mercurial directory\n         fi\n}\nalias hgweb=my_hgweb\n\n\n\n\nColors\n\n\nWith tput\n\n\nColors\n\n\n\n\n0 \u2013 Black.\n\n\n1 \u2013 Red.\n\n\n2 \u2013 Green.\n\n\n3 \u2013 Yellow.\n\n\n4 \u2013 Blue.\n\n\n5 \u2013 Magenta.\n\n\n6 \u2013 Cyan.\n\n\n7 \u2013 White.\nClear all options\n\n\n\n\ntput setab clear\n\n\n\n\nSet foreground color\n\n\ntput setab 6; # turquoise\n\n\n\n\nSet background color\n\n\ntput setab 2; # green\n\n\n\n\nSet bold\n\n\ntput bold;\n\n\n\n\n\n\n\n\nMore info: http://linuxcommand.org/lc3_adv_tput.php\n\n\n\n\n\n\nShow all color combinations\nhttps://gist.github.com/patsancu/44fcdb7d7d195add5bc87e4aa5df88c6\n\n\n\n\n\n\nUseful snippets\n\n\nFile management\n\n\nRename files in folder to sorted files\n\n\nc=0; for i in `ls`;do echo \n$i\n; c=$((c+1)); mv \n$i\n \n$c.txt\n; done\n\n\n\n\nRename files, change extesion\n\n\nfor file in *.html\ndo\n mv \n$file\n \n${file%.html}.txt\n\ndone\n\n\n\n\nGet extension of file\n\n\nfilename=$(basename \n$fullfile\n)\nextension=\n${filename##*.}\n\nfilename=\n${filename%.*}\n\n\n\n\n\nChange mac address\n\n\nsudo ifconfig eth0 down\nsudo ifconfig eth0 hw ether  xx:xx:xx:xx:xx:xx\nsudo ifconfig eth0 up\n\n\n\n\nDate\n\n\nFormat current date\n\n\n$ date +'%Y%m%d'\n\n\n\n\nAdd days to date\n\n\ndate -d +\n2 days\n\ndate -d +\n3 minutes\n\ndate -d +\n4 months\n\n\n\n\n\nFrom epoch \nseconds\n to date\n\n\n$ date -d @1463234960\nsamedi 14 mai 2016, 16:09:20 (UTC+0200)\n\n\n\n\nCombine\n\n\n$ date -d @1463234960 +\n%Y-%m-%d\n\n2016-05-14\n$ date -d \n1492/10/12 14:00:02\n +\n%Y-%m-%d %H:%M\n\n1492-10-12 14:00\n\n\n\n\nFor more info about \ndate input formats\n\n\nUseful commands\n\n\n\n\npv\n \nshow progress of command\n\n\n\n\ndd bs=4M if=/media/somedrive/raspbian-jessie.img | pv | dd of=/dev/mmcblk0\n\n\n\n\n\n\npgrep\n \nget PID by name\n\n\npkill\n \nkill process by name\n\n\ntimeout n command\n \nexecute command for n seconds\n\n\n\n\nSee calendar for previous month, next month, and three months from now\n\n\n$ ncal -3 -A 2\n\n\nEncode/decode base64 data\n\n\n$ echo patata | base64\ncGF0YXRhCg==\n$ echo patata | base64 | base64 -d\n\n\n\n\nExit traps\n\n\nReference\n\n\nExample:\n\n\n#!/bin/bash\nscratch=$(mktemp -d -t tmp.XXXXXXXXXX)\nfunction finish {\n  rm -rf \n$scratch\n\n}\ntrap finish EXIT\n\n\n\n\nCheck OS type\n\n\nif [[ \n$OSTYPE\n == \nlinux-gnu\n ]]; then\n        # ...\nelif [[ \n$OSTYPE\n == \ndarwin\n* ]]; then\n        # Mac OSX\nelif [[ \n$OSTYPE\n == \ncygwin\n ]]; then\n        # POSIX compatibility layer and Linux environment emulation for Windows\nelif [[ \n$OSTYPE\n == \nmsys\n ]]; then\n        # Lightweight shell and GNU utilities compiled for Windows (part of MinGW)\nelif [[ \n$OSTYPE\n == \nwin32\n ]]; then\n        # I'm not sure this can happen.\nelif [[ \n$OSTYPE\n == \nfreebsd\n* ]]; then\n        # ...\nelse\n        #\n\n\n\n\nFlatten directory\n\n\nMoves recursively all files under folder \"dir1\" (at any level of depth) to the \"dir1\" folder.\n\n\nfind dir1 -type f -exec mv {} dir1 \\;\n\n\n\n\nGet duplicate lines and count\n\n\nprints duplicate lines only\n\n\ncat some_file.csv | uniq -cd\n\n\n\n\nGeotag pictures\n\n\n#!/bin/bash\nlat=$(curl \nhttp://nominatim.openstreetmap.org/search?\ncity=$1\ncountry=$2\nformat=json\n | jq '.[0] | .lat' | tr \u00add '\n')\nlon=$(curl \nhttp://nominatim.openstreetmap.org/search?\ncity=$1\ncountry=$2\nformat=json\n | jq '.[0] | .lon' | tr \u00add '\n')\nexiftool \u00adGPSLongitude=$lon \u00adGPSLatitude=$lat \u00adext jpg .\n\n\n\n\nr## Prettify json\n\n\ncurl -s localhost:7080/mappings | python -mjson.tool", 
            "title": "Shell"
        }, 
        {
            "location": "/Ops/Shell/Shell/#setup-a-local-smtpserver", 
            "text": "$ python -m smtpd -n -c DebuggingServer localhost:1025", 
            "title": "Setup a local smtpserver"
        }, 
        {
            "location": "/Ops/Shell/Shell/#change-shell", 
            "text": "chsh -s /usr/local/bin/bash [username]", 
            "title": "Change shell"
        }, 
        {
            "location": "/Ops/Shell/Shell/#execute-command-without-any-env-variable-or-with-just-a-few", 
            "text": "zsh $ P= ZZZ ; echo $P\nZZZ\nzsh $ echo $PATATA\n\n$ env -i PATATA= patatina  PAT= ata  bash\necho $ZZZ\n\n$ echo $PATATA\npatatina", 
            "title": "Execute command without any env variable or with just a few"
        }, 
        {
            "location": "/Ops/Shell/Shell/#super-simple-text-file-creation", 
            "text": "", 
            "title": "Super simple text file creation"
        }, 
        {
            "location": "/Ops/Shell/Shell/#dont-use-in-existing-files-it-will-overwrite-them", 
            "text": "Write to file until EOF is written (in a single line)  $ cat  EOF   p.c\nsome line\nanother line\nEOF\n$ cat p.c\nsome line\nanother line", 
            "title": "DON'T USE IN EXISTING FILES, IT WILL OVERWRITE THEM"
        }, 
        {
            "location": "/Ops/Shell/Shell/#double-substution", 
            "text": "$ foo= whatever \n$ i=foo\n$ echo $echo ${!i}\nwhatever", 
            "title": "Double substution"
        }, 
        {
            "location": "/Ops/Shell/Shell/#execute-process-in-background-with-lock", 
            "text": "", 
            "title": "Execute process in background with lock"
        }, 
        {
            "location": "/Ops/Shell/Shell/#executes-process-with-nohup-and-flock", 
            "text": "See  gist", 
            "title": "Executes process with nohup and flock"
        }, 
        {
            "location": "/Ops/Shell/Shell/#shutdown-process-above", 
            "text": "See  gist", 
            "title": "Shutdown process above"
        }, 
        {
            "location": "/Ops/Shell/Shell/#flock", 
            "text": "Use flock as in  here", 
            "title": "Flock"
        }, 
        {
            "location": "/Ops/Shell/Shell/#get-url-for-git-repo", 
            "text": "xdg-open `git remote -v | grep fetch | head -1 | cut -f2 | cut -d' ' -f1 | sed -e's/git@/http:\\/\\//' -e's/\\.git$//' | sed -E 's/(\\/\\/[^:]*):/\\1\\//'`", 
            "title": "Get url for git repo"
        }, 
        {
            "location": "/Ops/Shell/Shell/#wget", 
            "text": "", 
            "title": "Wget"
        }, 
        {
            "location": "/Ops/Shell/Shell/#download-all-pdfs-linked-in-a-website", 
            "text": "Warning:  Even if it recreates only the pdfs, it will download  every  file referenced by links  $ wget -r -A.pdf http://people.seas.harvard.edu/~minilek/cs229r/fall15/lec.html", 
            "title": "Download all pdfs linked in a website"
        }, 
        {
            "location": "/Ops/Shell/Shell/#download-all-pdfs-linked-in-a-website-including-linked-websites-1-level", 
            "text": "$ wget -r -l1 -A.pdf http://people.seas.harvard.edu/~minilek/cs229r/fall15/lec.html", 
            "title": "Download all pdfs linked in a website, including linked websites (1 level)"
        }, 
        {
            "location": "/Ops/Shell/Shell/#bash-erize-cli-any-python-object", 
            "text": "python-fire", 
            "title": "Bash-erize cli any Python object"
        }, 
        {
            "location": "/Ops/Shell/Shell/#set-bash-variable-default-value", 
            "text": "${parameter=default}, ${parameter:=default} \nThe  :  makes a difference only when  $parameter  has been declared and is null  $ echo $var\n\n$ echo ${var:=abc}   # abc\nabc\n$ echo ${var}   # abc\nabc  http://www.tldp.org/LDP/abs/html/parameter-substitution.html#PARAMSUBREF", 
            "title": "Set bash variable default value"
        }, 
        {
            "location": "/Ops/Shell/Shell/#one-line-to-pretty-separate-jsons", 
            "text": "curl -s localhost:7080/mappings  |  python -mjson.tool", 
            "title": "One line to pretty separate jsons"
        }, 
        {
            "location": "/Ops/Shell/Shell/#xargs-with-files-with-spaces-on-path", 
            "text": "ls *mp3 | xargs -d '\\n' mplayer", 
            "title": "Xargs with files with spaces on path"
        }, 
        {
            "location": "/Ops/Shell/Shell/#word-frequency-of-text-file", 
            "text": "cat ~/filename.txt | tr ' ' '\\n' | sort | uniq -c | awk '{print $2\"@\"$1}'", 
            "title": "Word frequency of text file"
        }, 
        {
            "location": "/Ops/Shell/Shell/#egrep", 
            "text": "Given a file with json lines having a field \"parentalRating\" and a number (e.g. '\"parentalRating\":\"17\"') , the following command will get the set of unique parental ratings, along with their frequencies in (frequency, key) pairs.  The  o  option is to output only the strings matching the egrep regex   $ egrep  parentalRating\\ :\\ [0-9]+  file.json -o | cut -d ':' -f 2 | tr -d ' ' | sort | uniq -c\n   1314 0\n   6209 13\n   1525 15\n   4518 17\n      3 18\n   3564 7", 
            "title": "Egrep"
        }, 
        {
            "location": "/Ops/Shell/Shell/#diff-folders", 
            "text": "https://gist.github.com/37b660b98f6d29ecd1af87ffb426f380", 
            "title": "Diff folders"
        }, 
        {
            "location": "/Ops/Shell/Shell/#record-your-command-line-session", 
            "text": "$ script  Exit typing  $ exit  All of your typings (and their reults) will be saved to a file named  typescript", 
            "title": "Record Your Command Line Session"
        }, 
        {
            "location": "/Ops/Shell/Shell/#globstar", 
            "text": "To allow double \"*\" as a recursive filepath parameter, eg  ls **/*.xml  add  shopt -s globstar  to  .bashrc", 
            "title": "Globstar"
        }, 
        {
            "location": "/Ops/Shell/Shell/#substring-removal", 
            "text": "", 
            "title": "Substring Removal"
        }, 
        {
            "location": "/Ops/Shell/Shell/#deletes-shortest-match-of-substring-from-front-of-string", 
            "text": "${string#substring}", 
            "title": "Deletes shortest match of $substring from front of $string."
        }, 
        {
            "location": "/Ops/Shell/Shell/#deletes-longest-match-of-substring-from-front-of-string", 
            "text": "${string##substring}", 
            "title": "Deletes longest match of $substring from front of $string."
        }, 
        {
            "location": "/Ops/Shell/Shell/#get-last-folder-of-current-working-directoy", 
            "text": "$ pwd\n/home/patrick/dev/python\n$ echo ${PWD##*/}\npython", 
            "title": "Get last folder of current working directoy"
        }, 
        {
            "location": "/Ops/Shell/Shell/#basic-integer-sequence-loop", 
            "text": "#!/bin/bash\nfor i in `seq 1 10`;\n   do\n     echo $i\n   done", 
            "title": "Basic integer sequence loop"
        }, 
        {
            "location": "/Ops/Shell/Shell/#display-output-as-a-table", 
            "text": "cat /etc/passwd | column -t -s", 
            "title": "Display Output as a Table"
        }, 
        {
            "location": "/Ops/Shell/Shell/#repeat-a-command-until-it-runs-successfully", 
            "text": "while true; do ping -c 1 8.8.8.8   /dev/null 2 1   break; done", 
            "title": "Repeat a Command Until It Runs Successfully"
        }, 
        {
            "location": "/Ops/Shell/Shell/#suspend-machine", 
            "text": "As root,  # pm-suspend", 
            "title": "Suspend machine"
        }, 
        {
            "location": "/Ops/Shell/Shell/#convert-a-file-to-upper-or-lower-case", 
            "text": "cat myfile | tr a-z A-Z   output.txt", 
            "title": "Convert a File to Upper or Lower Case"
        }, 
        {
            "location": "/Ops/Shell/Shell/#sort-processes-by-memory-usage", 
            "text": "ps aux | sort -rnk 4", 
            "title": "Sort Processes by Memory Usage"
        }, 
        {
            "location": "/Ops/Shell/Shell/#sort-processes-by-cpu-usage", 
            "text": "ps aux | sort -nk 3", 
            "title": "Sort Processes by CPU Usage"
        }, 
        {
            "location": "/Ops/Shell/Shell/#xargs-example", 
            "text": "ls /etc/*.conf | xargs -i cp {} /home/likegeeks/Desktop/out", 
            "title": "Xargs example"
        }, 
        {
            "location": "/Ops/Shell/Shell/#dd", 
            "text": "", 
            "title": "dd"
        }, 
        {
            "location": "/Ops/Shell/Shell/#basic-syntax", 
            "text": "dd bs=4M if=/dev/sdd of=from-sd-card.img", 
            "title": "Basic syntax"
        }, 
        {
            "location": "/Ops/Shell/Shell/#see-progress-of-dd", 
            "text": "sudo pkill -USR1 -n -x dd  This will show the progess  in the same terminal dd was executed", 
            "title": "See progress of dd"
        }, 
        {
            "location": "/Ops/Shell/Shell/#create-file-with-a-specific-size", 
            "text": "dd if=/dev/zero of=out.txt bs=1M count=10", 
            "title": "Create File With a Specific Size"
        }, 
        {
            "location": "/Ops/Shell/Shell/#shorten-url-with-googl", 
            "text": "The  $GOOGLE_SHORTEN_API_KEY  variable needs to be set, and jq needs to be installed  shorten(){\n    curl  https://www.googleapis.com/urlshortener/v1/url?key=$GOOGLE_SHORTEN_API_KEY  -H 'Content-Type: application/json' -d  {'longUrl': \\ $1\\ }  | jq '.id'\n}", 
            "title": "Shorten url with goo.gl"
        }, 
        {
            "location": "/Ops/Shell/Shell/#automatically-press-keys-when-condition-is-met", 
            "text": "Use expect as in  here", 
            "title": "Automatically press keys when condition is met"
        }, 
        {
            "location": "/Ops/Shell/Shell/#convert-windows-encoded-text-file-to-unix-encoded", 
            "text": "awk 'BEGIN{RS= ^$ ;ORS= ;getline;gsub( \\r , );print ARGV[1]}' file_name", 
            "title": "Convert windows-encoded text file to unix-encoded"
        }, 
        {
            "location": "/Ops/Shell/Shell/#read-lines-from-file-in-a-for-loop", 
            "text": "FS=$'\\n'       # make newlines the only separator\nfor j in $(cat ./file_wget_med)\ndo\n    echo  $j \ndone  or  input= /path/to/txt/file \nwhile IFS= read -r var\ndo\n  echo  $var \ndone    $input", 
            "title": "Read lines from file in a for loop"
        }, 
        {
            "location": "/Ops/Shell/Shell/#display-info-about-memory", 
            "text": "$ sudo lshw -C memory", 
            "title": "Display info about memory"
        }, 
        {
            "location": "/Ops/Shell/Shell/#open-the-current-repo-on-a-specific-web-repo", 
            "text": "my_hgweb() {\n         if [ -d .hg ]; then\n            xdg-open http://web-repo-address/hg/${PWD##*/}   /dev/null\n         else\n            echo Not mercurial directory\n         fi\n}\nalias hgweb=my_hgweb", 
            "title": "Open the current repo on a specific web repo"
        }, 
        {
            "location": "/Ops/Shell/Shell/#colors", 
            "text": "", 
            "title": "Colors"
        }, 
        {
            "location": "/Ops/Shell/Shell/#with-tput", 
            "text": "", 
            "title": "With tput"
        }, 
        {
            "location": "/Ops/Shell/Shell/#colors_1", 
            "text": "0 \u2013 Black.  1 \u2013 Red.  2 \u2013 Green.  3 \u2013 Yellow.  4 \u2013 Blue.  5 \u2013 Magenta.  6 \u2013 Cyan.  7 \u2013 White.\nClear all options   tput setab clear  Set foreground color  tput setab 6; # turquoise  Set background color  tput setab 2; # green  Set bold  tput bold;    More info: http://linuxcommand.org/lc3_adv_tput.php    Show all color combinations\nhttps://gist.github.com/patsancu/44fcdb7d7d195add5bc87e4aa5df88c6", 
            "title": "Colors"
        }, 
        {
            "location": "/Ops/Shell/Shell/#useful-snippets", 
            "text": "", 
            "title": "Useful snippets"
        }, 
        {
            "location": "/Ops/Shell/Shell/#file-management", 
            "text": "", 
            "title": "File management"
        }, 
        {
            "location": "/Ops/Shell/Shell/#rename-files-in-folder-to-sorted-files", 
            "text": "c=0; for i in `ls`;do echo  $i ; c=$((c+1)); mv  $i   $c.txt ; done", 
            "title": "Rename files in folder to sorted files"
        }, 
        {
            "location": "/Ops/Shell/Shell/#rename-files-change-extesion", 
            "text": "for file in *.html\ndo\n mv  $file   ${file%.html}.txt \ndone", 
            "title": "Rename files, change extesion"
        }, 
        {
            "location": "/Ops/Shell/Shell/#get-extension-of-file", 
            "text": "filename=$(basename  $fullfile )\nextension= ${filename##*.} \nfilename= ${filename%.*}", 
            "title": "Get extension of file"
        }, 
        {
            "location": "/Ops/Shell/Shell/#change-mac-address", 
            "text": "sudo ifconfig eth0 down\nsudo ifconfig eth0 hw ether  xx:xx:xx:xx:xx:xx\nsudo ifconfig eth0 up", 
            "title": "Change mac address"
        }, 
        {
            "location": "/Ops/Shell/Shell/#date", 
            "text": "", 
            "title": "Date"
        }, 
        {
            "location": "/Ops/Shell/Shell/#format-current-date", 
            "text": "$ date +'%Y%m%d'", 
            "title": "Format current date"
        }, 
        {
            "location": "/Ops/Shell/Shell/#add-days-to-date", 
            "text": "date -d + 2 days \ndate -d + 3 minutes \ndate -d + 4 months", 
            "title": "Add days to date"
        }, 
        {
            "location": "/Ops/Shell/Shell/#from-epoch-seconds-to-date", 
            "text": "$ date -d @1463234960\nsamedi 14 mai 2016, 16:09:20 (UTC+0200)", 
            "title": "From epoch seconds to date"
        }, 
        {
            "location": "/Ops/Shell/Shell/#combine", 
            "text": "$ date -d @1463234960 + %Y-%m-%d \n2016-05-14\n$ date -d  1492/10/12 14:00:02  + %Y-%m-%d %H:%M \n1492-10-12 14:00  For more info about  date input formats", 
            "title": "Combine"
        }, 
        {
            "location": "/Ops/Shell/Shell/#useful-commands", 
            "text": "pv   show progress of command   dd bs=4M if=/media/somedrive/raspbian-jessie.img | pv | dd of=/dev/mmcblk0   pgrep   get PID by name  pkill   kill process by name  timeout n command   execute command for n seconds", 
            "title": "Useful commands"
        }, 
        {
            "location": "/Ops/Shell/Shell/#see-calendar-for-previous-month-next-month-and-three-months-from-now", 
            "text": "$ ncal -3 -A 2", 
            "title": "See calendar for previous month, next month, and three months from now"
        }, 
        {
            "location": "/Ops/Shell/Shell/#encodedecode-base64-data", 
            "text": "$ echo patata | base64\ncGF0YXRhCg==\n$ echo patata | base64 | base64 -d", 
            "title": "Encode/decode base64 data"
        }, 
        {
            "location": "/Ops/Shell/Shell/#exit-traps", 
            "text": "Reference  Example:  #!/bin/bash\nscratch=$(mktemp -d -t tmp.XXXXXXXXXX)\nfunction finish {\n  rm -rf  $scratch \n}\ntrap finish EXIT", 
            "title": "Exit traps"
        }, 
        {
            "location": "/Ops/Shell/Shell/#check-os-type", 
            "text": "if [[  $OSTYPE  ==  linux-gnu  ]]; then\n        # ...\nelif [[  $OSTYPE  ==  darwin * ]]; then\n        # Mac OSX\nelif [[  $OSTYPE  ==  cygwin  ]]; then\n        # POSIX compatibility layer and Linux environment emulation for Windows\nelif [[  $OSTYPE  ==  msys  ]]; then\n        # Lightweight shell and GNU utilities compiled for Windows (part of MinGW)\nelif [[  $OSTYPE  ==  win32  ]]; then\n        # I'm not sure this can happen.\nelif [[  $OSTYPE  ==  freebsd * ]]; then\n        # ...\nelse\n        #", 
            "title": "Check OS type"
        }, 
        {
            "location": "/Ops/Shell/Shell/#flatten-directory", 
            "text": "Moves recursively all files under folder \"dir1\" (at any level of depth) to the \"dir1\" folder.  find dir1 -type f -exec mv {} dir1 \\;", 
            "title": "Flatten directory"
        }, 
        {
            "location": "/Ops/Shell/Shell/#get-duplicate-lines-and-count", 
            "text": "prints duplicate lines only  cat some_file.csv | uniq -cd", 
            "title": "Get duplicate lines and count"
        }, 
        {
            "location": "/Ops/Shell/Shell/#geotag-pictures", 
            "text": "#!/bin/bash\nlat=$(curl  http://nominatim.openstreetmap.org/search?\ncity=$1 country=$2 format=json  | jq '.[0] | .lat' | tr \u00add ' ')\nlon=$(curl  http://nominatim.openstreetmap.org/search?\ncity=$1 country=$2 format=json  | jq '.[0] | .lon' | tr \u00add ' ')\nexiftool \u00adGPSLongitude=$lon \u00adGPSLatitude=$lat \u00adext jpg .  r## Prettify json  curl -s localhost:7080/mappings | python -mjson.tool", 
            "title": "Geotag pictures"
        }, 
        {
            "location": "/Software/Alluxio/", 
            "text": "Refresh cache\n\n\nroot@alluxio-master-0:/opt/alluxio# alluxio fs ls -Rf /raw\n\n\n\n\nRemount folder\n\n\nroot@alluxio-master-0:/opt/alluxio# alluxio fs unmount /sushi\nUnmounted /sushi\nroot@alluxio-master-0:/opt/alluxio# alluxio fs mount /sushi s3a://path-to-mount", 
            "title": "Alluxio"
        }, 
        {
            "location": "/Software/Alluxio/#refresh-cache", 
            "text": "root@alluxio-master-0:/opt/alluxio# alluxio fs ls -Rf /raw", 
            "title": "Refresh cache"
        }, 
        {
            "location": "/Software/Alluxio/#remount-folder", 
            "text": "root@alluxio-master-0:/opt/alluxio# alluxio fs unmount /sushi\nUnmounted /sushi\nroot@alluxio-master-0:/opt/alluxio# alluxio fs mount /sushi s3a://path-to-mount", 
            "title": "Remount folder"
        }, 
        {
            "location": "/Software/Apache-Drill/", 
            "text": "Before googling, check errors\n\n\n\n\nhttps://drill.apache.org/docs/troubleshooting/\n\n\nhttps://drill.apache.org/docs/alter-system/\n\n\n\n\nChange store format\n\n\nuse dfs.tmp;\nalter session set store.`format`='json';\n\n\n\n\nAfter that, \n\n\nCREATE TABLE movieRegions (region, title, purchases) as  SELECT region, title, count(*) as numberOfPurchases  FROM dfs.`/home/user/data/some/path/some_file.json` group by region, title;\n\n\n\n\nwill create table on \n/tmp/movieRegions/SOME_NUMBERS.json\n\n\nquery custom *sv file (fields delimited by another character)\n\n\nselect * from table(dfs.`/path/to/file/some_data.xsv` (type =\n 'text', fieldDelimiter =\n '~', extractHeader =\n true));\n\n\n\n\nQuery the system\n\n\nIdentify the Foreman\n\n\nIssue the following query to identify the Foreman node:\n\n\nSELECT hostname FROM sys.drillbits WHERE `current` = true\n\n\n\n\nGet drill version\n\n\nSELECT version FROM sys.version;\n\n\n\n\nGet a complete list of planning and execution options that are currently set at the system or session level\n\n\nSELECT name, type FROM sys.options WHERE type in ('SYSTEM','SESSION') order by name;\n\n\n\n\nChange system settings\n\n\nalter system set planner.enable_hashagg = true;\n\n\n\n\nalter system set planner.enable_multiphase_agg = false;\n\n\n\n\nChange port of web UI\n\n\n$ vim conf/drill-override.conf\n\n\n\n\ndrill.exec: {\n  cluster-id: \ndrillbits1\n\n  rpc: {\n        user: {\n          server: {\n            port: 31910\n            }\n        },\n        bit: {\n          server: {\n            port : 31911,\n            retry:{\n              count: 7200,\n              delay: 500\n            },\n            threads: 1\n          }\n        },\n    },\n    http: {\n          enabled: true,\n          ssl_enabled: false,\n          port: 8989\n          session_max_idle_secs: 3600, # Default value 1hr\n          cors: {\n            enabled: false,\n            allowedOrigins: [\nnull\n],\n            allowedMethods: [\nGET\n, \nPOST\n, \nHEAD\n, \nOPTIONS\n],\n            allowedHeaders: [\nX-Requested-With\n, \nContent-Type\n, \nAccept\n, \nOrigin\n],\n            credentials: true\n          }\n        },\n}\ndrill.logical.function.package+=[com.mapr.drill]\n\n\n\n\n\nChange log level\n\n\nEdit \n/conf/logback.xml", 
            "title": "Apache Drill"
        }, 
        {
            "location": "/Software/Apache-Drill/#change-store-format", 
            "text": "use dfs.tmp;\nalter session set store.`format`='json';  After that,   CREATE TABLE movieRegions (region, title, purchases) as  SELECT region, title, count(*) as numberOfPurchases  FROM dfs.`/home/user/data/some/path/some_file.json` group by region, title;  will create table on  /tmp/movieRegions/SOME_NUMBERS.json", 
            "title": "Change store format"
        }, 
        {
            "location": "/Software/Apache-Drill/#query-custom-sv-file-fields-delimited-by-another-character", 
            "text": "select * from table(dfs.`/path/to/file/some_data.xsv` (type =  'text', fieldDelimiter =  '~', extractHeader =  true));", 
            "title": "query custom *sv file (fields delimited by another character)"
        }, 
        {
            "location": "/Software/Apache-Drill/#query-the-system", 
            "text": "", 
            "title": "Query the system"
        }, 
        {
            "location": "/Software/Apache-Drill/#identify-the-foreman", 
            "text": "Issue the following query to identify the Foreman node:  SELECT hostname FROM sys.drillbits WHERE `current` = true", 
            "title": "Identify the Foreman"
        }, 
        {
            "location": "/Software/Apache-Drill/#get-drill-version", 
            "text": "SELECT version FROM sys.version;", 
            "title": "Get drill version"
        }, 
        {
            "location": "/Software/Apache-Drill/#get-a-complete-list-of-planning-and-execution-options-that-are-currently-set-at-the-system-or-session-level", 
            "text": "SELECT name, type FROM sys.options WHERE type in ('SYSTEM','SESSION') order by name;", 
            "title": "Get a complete list of planning and execution options that are currently set at the system or session level"
        }, 
        {
            "location": "/Software/Apache-Drill/#change-system-settings", 
            "text": "alter system set planner.enable_hashagg = true;  alter system set planner.enable_multiphase_agg = false;", 
            "title": "Change system settings"
        }, 
        {
            "location": "/Software/Apache-Drill/#change-port-of-web-ui", 
            "text": "$ vim conf/drill-override.conf  drill.exec: {\n  cluster-id:  drillbits1 \n  rpc: {\n        user: {\n          server: {\n            port: 31910\n            }\n        },\n        bit: {\n          server: {\n            port : 31911,\n            retry:{\n              count: 7200,\n              delay: 500\n            },\n            threads: 1\n          }\n        },\n    },\n    http: {\n          enabled: true,\n          ssl_enabled: false,\n          port: 8989\n          session_max_idle_secs: 3600, # Default value 1hr\n          cors: {\n            enabled: false,\n            allowedOrigins: [ null ],\n            allowedMethods: [ GET ,  POST ,  HEAD ,  OPTIONS ],\n            allowedHeaders: [ X-Requested-With ,  Content-Type ,  Accept ,  Origin ],\n            credentials: true\n          }\n        },\n}\ndrill.logical.function.package+=[com.mapr.drill]", 
            "title": "Change port of web UI"
        }, 
        {
            "location": "/Software/Apache-Drill/#change-log-level", 
            "text": "Edit  /conf/logback.xml", 
            "title": "Change log level"
        }, 
        {
            "location": "/Software/Atom/", 
            "text": "Atom\n\n\nChange background colour of selected text\n\n\n  atom-text-editor::shadow .selection .region {\n\n  background-color: LightGoldenRodYellow;\n}", 
            "title": "Atom"
        }, 
        {
            "location": "/Software/Atom/#atom", 
            "text": "Change background colour of selected text    atom-text-editor::shadow .selection .region {\n\n  background-color: LightGoldenRodYellow;\n}", 
            "title": "Atom"
        }, 
        {
            "location": "/Software/Guake-Terminal-\u2013-Dual-Monitor-Edits/", 
            "text": "Guake always defaults to the left monitor. It does a great job of determining the size of \u2018monitor 1\u2032. To get Guake on my right-side monitor I had to tweak the source code. Here\u2019s how you can do the same:\n\n\nMake a copy of theGuake program and put it in yourbin folder. I renamed mine toguake-dualmon but you can call it whatever you want.\n\n\n\n\ncp /usr/bin/guake ~/bin/guake-dualmon\n\n\nvim  ~/bin/guake-dualmon\n\n\nFind the method definition  \ndef get_final_window_rect(self):\n\n\nFirst we will correctly position the terminal on the right monitor. Add one line at the end, between \nwindow_rect.y = 0\n  and  \nreturn window_rect\n . The window_rect.x and window_rect.y variables tell the Guake window where to be located. Set \nwindow_rect.x\n to be the width of your left monitor and \nwindow_rect.y\n will depend on how offset the monitors are. I had to play with the \u2018y\u2019 setting to get it just right or the text starts off the top of the screen.\n\n\n\n\nwindow_rect.x = 1280\nwindow_rect.y = 24\n\n\n\n\n\n\nNow Guake will be positioned on your right monitor, but it will still be the size of the left one. In my case it was sized at 1280, and I needed it to be 1920. Divide your right monitor\u2019s width by the left monitor\u2019s width (ie. 1920/1280 = 150). Still within  \nget_final_window_rect(self):\n you will find the line \nwidth = 100\n . This setting is a percentage of your left monitor, so set it to the answer you got by dividing one width into the other. In my case it was:\n\n\n\n\nwidth = 150\n\n\n\n\nThat\u2019s it! Just make sure to always run your copy of the program, or better yet add it to your autostart so it runs automatically!", 
            "title": "Guake Terminal \u2013 Dual Monitor Edits"
        }, 
        {
            "location": "/Software/Latex/", 
            "text": "Latex\n\n\nForce new line\n\n\n\\newline\n\nor\n\n\\\\", 
            "title": "Latex"
        }, 
        {
            "location": "/Software/Latex/#latex", 
            "text": "", 
            "title": "Latex"
        }, 
        {
            "location": "/Software/Latex/#force-new-line", 
            "text": "\\newline \nor \\\\", 
            "title": "Force new line"
        }, 
        {
            "location": "/Software/Multimedia/", 
            "text": "Extract audio from video\n\n\n\n\nmplayer -dumpaudio -dumpfile clip_track.mp3 clip.avi\n or\n\n\navconv -i /input-file-name-with-path output-filename.mp3\n\n\n\n\nMerge pdfs into one\n\n\npdftk \nspace separated pdf files\n cat output CanterburyTales.pdf", 
            "title": "Multimedia"
        }, 
        {
            "location": "/Software/Multimedia/#extract-audio-from-video", 
            "text": "mplayer -dumpaudio -dumpfile clip_track.mp3 clip.avi  or  avconv -i /input-file-name-with-path output-filename.mp3", 
            "title": "Extract audio from video"
        }, 
        {
            "location": "/Software/Multimedia/#merge-pdfs-into-one", 
            "text": "pdftk  space separated pdf files  cat output CanterburyTales.pdf", 
            "title": "Merge pdfs into one"
        }, 
        {
            "location": "/Software/Skype/", 
            "text": "Skype\n\n\nSkype Web\n\n\nFormat text\n\n\nA * surrounding text (a) \nbolds\n.\n\n\nA _ surrounding text (a) \nitalics\n.\n\n\nA ~ surrounding text (~a~) \n~~strikethroughs~~\n.\n\n\nIf you start a message with \"@@ \" (two ats with a space), every formatting function in your message will be ignored except emoticons.\n\n\nIf you start a message with \"!! \" (two exclamations with a space), every formatting function in your message will be ignored and font will be switched to monospaced.\n\n\nSkype Desktop\n\n\nSkype complains about another session in the computer but there are none\n\n\nrm -rf ~/.Skype", 
            "title": "Skype"
        }, 
        {
            "location": "/Software/Skype/#skype", 
            "text": "", 
            "title": "Skype"
        }, 
        {
            "location": "/Software/Skype/#skype-web", 
            "text": "", 
            "title": "Skype Web"
        }, 
        {
            "location": "/Software/Skype/#format-text", 
            "text": "A * surrounding text (a)  bolds .  A _ surrounding text (a)  italics .  A ~ surrounding text (~a~)  ~~strikethroughs~~ .  If you start a message with \"@@ \" (two ats with a space), every formatting function in your message will be ignored except emoticons.  If you start a message with \"!! \" (two exclamations with a space), every formatting function in your message will be ignored and font will be switched to monospaced.", 
            "title": "Format text"
        }, 
        {
            "location": "/Software/Skype/#skype-desktop", 
            "text": "", 
            "title": "Skype Desktop"
        }, 
        {
            "location": "/Software/Skype/#skype-complains-about-another-session-in-the-computer-but-there-are-none", 
            "text": "rm -rf ~/.Skype", 
            "title": "Skype complains about another session in the computer but there are none"
        }, 
        {
            "location": "/Software/Tableau/", 
            "text": "Multiple data sources without joining or blending\n\n\n\n\nCreate a new Worksheet. \n\n\nUsing the top menu bar, select Data \n New Data Source. (This can also be done with Ctrl+D)\n\n\n\n\nShow measure on title, let everything else be empty\n\n\n\n\nDouble click on the sheet title, to edit it\n\n\nCreate calculated field with str(value to add) \n\n\ne.g. \nstr(avg(some_measure)) + \" minutes\"\n\n\nClick \nInsert\n and specify value to insert\n\n\nClick on the graph and select \nHide", 
            "title": "Tableau"
        }, 
        {
            "location": "/Software/Tableau/#multiple-data-sources-without-joining-or-blending", 
            "text": "Create a new Worksheet.   Using the top menu bar, select Data   New Data Source. (This can also be done with Ctrl+D)", 
            "title": "Multiple data sources without joining or blending"
        }, 
        {
            "location": "/Software/Tableau/#show-measure-on-title-let-everything-else-be-empty", 
            "text": "Double click on the sheet title, to edit it  Create calculated field with str(value to add)   e.g.  str(avg(some_measure)) + \" minutes\"  Click  Insert  and specify value to insert  Click on the graph and select  Hide", 
            "title": "Show measure on title, let everything else be empty"
        }, 
        {
            "location": "/Software/Useful-software/", 
            "text": "Dev\n\n\nJson lint\n\n\n\n\njsonlint-py\n\n\nsudo apt-get install python-demjson\n\n\n\n\nJava\n\n\njdk\n\n\nsudo apt-add-repository ppa:webupd8team/java\nsudo apt-get update\nsudo apt-get install oracle-java8-installer\n\n\nor\n\n\nsudo apt-get install oracle-java7-installer\n\n\nSOAP UI\n\n\nSDK man\n\n\ncurl -s get.sdkman.io | bash\n\n\nSTS - Spring Tool Suite\n\n\nCLI software\n\n\nNewsbeuter\n\n\nrss client\n\n\nMutt\n\n\nemail client. \nConfig info\n\n\nDB\n\n\nSquirrel\n\n\nSteps to add Oracle Driver\n\n\n\n\nOpen Driver list from left menu, scroll down till you find \"Oracle Thin Driver\", you will notice red x mark next to it denoting the driver is still not configured.\n\n\nAfter selecting \"Oracle Thin Driver\" click \"Modify the Selected Driver\" denoted by pencil.\n\n\nClick \"Extra Class Path\" tab.\n\n\nClick \"Add\" and select 1 jar file from %Oracle_DB_CLIENT_INSTALL%\\jdbc\\lib\\ojdbc6_g.jar\n\n\nClick Ok, and we are done defining the driver.\n\n\nNow create an alias for the DB using previous driver and providing URL, username, \n password.\n\n\n\n\nNote:\n\nNo need to have Oracle client for setup, all you need is just the driver jar files. You can download from this Oracle link.\n\n\nIf you are using JDK 5 while running Squirrel SQL, the jar file will be %Oracle_DB_CLIENT_INSTALL%\\jdbc\\lib\\ojdbc5_g.jar\n\n\nThin url would be something like (local db): jdbc:oracle:thin:@localhost:1521:xe\n\n\nOracle Database 11g Express Edition\n\n\nSQL developer\n\n\nDBeaver\n\n\nSoporte para Oracle, MySQL, PostgreSQL,... y \nDrill\n\n\nCommunications\n\n\nFranz\n\n\nIntegrate several messaging apps (skype, hangouts, slack,...). Capable of managing several accounts of the same app\n\n\nHangouts\n\n\nSkype\n\n\nSkype alpha\n\n\nSlack\n\n\nRemote\n\n\nGnome connection manager\n\n\nChange\n /home/patrick/.gcm/gcm.conf\n- Change \nlog-path\n option\n- Change console_close = CTRL+W (e.g. console_close = CTRL + M)\n\n\nCloud\n\n\nCross FTP\n\n\nFTP and S3 browser\n\n\nDragonDisk\n\n\nS3 browser\n\n\nCan get shareable URL via Right Click -\n Properties -\n Security Tab -\n Add (All users) -\n Check Download and Read permissions boxes\n\n\nTex\n\n\nInstall packages\n\n\nDownload package (e.g. \nclassicthesis\n ) and extract the sty file it to a folder named as the package under ~/texmf/tex/latex/packagename (e.g. \n/home/user/texmf/tex/latex/classicthesis\n )\n\n\nMisc\n\n\nsudo apt-get install nautilus-actions gnome-paint", 
            "title": "Useful software"
        }, 
        {
            "location": "/Software/Useful-software/#dev", 
            "text": "", 
            "title": "Dev"
        }, 
        {
            "location": "/Software/Useful-software/#json-lint", 
            "text": "jsonlint-py  sudo apt-get install python-demjson", 
            "title": "Json lint"
        }, 
        {
            "location": "/Software/Useful-software/#java", 
            "text": "", 
            "title": "Java"
        }, 
        {
            "location": "/Software/Useful-software/#jdk", 
            "text": "sudo apt-add-repository ppa:webupd8team/java\nsudo apt-get update\nsudo apt-get install oracle-java8-installer  or  sudo apt-get install oracle-java7-installer", 
            "title": "jdk"
        }, 
        {
            "location": "/Software/Useful-software/#soap-ui", 
            "text": "", 
            "title": "SOAP UI"
        }, 
        {
            "location": "/Software/Useful-software/#sdk-man", 
            "text": "curl -s get.sdkman.io | bash", 
            "title": "SDK man"
        }, 
        {
            "location": "/Software/Useful-software/#sts-spring-tool-suite", 
            "text": "", 
            "title": "STS - Spring Tool Suite"
        }, 
        {
            "location": "/Software/Useful-software/#cli-software", 
            "text": "", 
            "title": "CLI software"
        }, 
        {
            "location": "/Software/Useful-software/#newsbeuter", 
            "text": "rss client", 
            "title": "Newsbeuter"
        }, 
        {
            "location": "/Software/Useful-software/#mutt", 
            "text": "email client.  Config info", 
            "title": "Mutt"
        }, 
        {
            "location": "/Software/Useful-software/#db", 
            "text": "", 
            "title": "DB"
        }, 
        {
            "location": "/Software/Useful-software/#squirrel", 
            "text": "Steps to add Oracle Driver   Open Driver list from left menu, scroll down till you find \"Oracle Thin Driver\", you will notice red x mark next to it denoting the driver is still not configured.  After selecting \"Oracle Thin Driver\" click \"Modify the Selected Driver\" denoted by pencil.  Click \"Extra Class Path\" tab.  Click \"Add\" and select 1 jar file from %Oracle_DB_CLIENT_INSTALL%\\jdbc\\lib\\ojdbc6_g.jar  Click Ok, and we are done defining the driver.  Now create an alias for the DB using previous driver and providing URL, username,   password.   Note: \nNo need to have Oracle client for setup, all you need is just the driver jar files. You can download from this Oracle link.  If you are using JDK 5 while running Squirrel SQL, the jar file will be %Oracle_DB_CLIENT_INSTALL%\\jdbc\\lib\\ojdbc5_g.jar  Thin url would be something like (local db): jdbc:oracle:thin:@localhost:1521:xe", 
            "title": "Squirrel"
        }, 
        {
            "location": "/Software/Useful-software/#oracle-database-11g-express-edition", 
            "text": "", 
            "title": "Oracle Database 11g Express Edition"
        }, 
        {
            "location": "/Software/Useful-software/#sql-developer", 
            "text": "", 
            "title": "SQL developer"
        }, 
        {
            "location": "/Software/Useful-software/#dbeaver", 
            "text": "Soporte para Oracle, MySQL, PostgreSQL,... y  Drill", 
            "title": "DBeaver"
        }, 
        {
            "location": "/Software/Useful-software/#communications", 
            "text": "", 
            "title": "Communications"
        }, 
        {
            "location": "/Software/Useful-software/#franz", 
            "text": "Integrate several messaging apps (skype, hangouts, slack,...). Capable of managing several accounts of the same app", 
            "title": "Franz"
        }, 
        {
            "location": "/Software/Useful-software/#hangouts", 
            "text": "", 
            "title": "Hangouts"
        }, 
        {
            "location": "/Software/Useful-software/#skype", 
            "text": "", 
            "title": "Skype"
        }, 
        {
            "location": "/Software/Useful-software/#skype-alpha", 
            "text": "", 
            "title": "Skype alpha"
        }, 
        {
            "location": "/Software/Useful-software/#slack", 
            "text": "", 
            "title": "Slack"
        }, 
        {
            "location": "/Software/Useful-software/#remote", 
            "text": "", 
            "title": "Remote"
        }, 
        {
            "location": "/Software/Useful-software/#gnome-connection-manager", 
            "text": "Change  /home/patrick/.gcm/gcm.conf\n- Change  log-path  option\n- Change console_close = CTRL+W (e.g. console_close = CTRL + M)", 
            "title": "Gnome connection manager"
        }, 
        {
            "location": "/Software/Useful-software/#cloud", 
            "text": "", 
            "title": "Cloud"
        }, 
        {
            "location": "/Software/Useful-software/#cross-ftp", 
            "text": "FTP and S3 browser", 
            "title": "Cross FTP"
        }, 
        {
            "location": "/Software/Useful-software/#dragondisk", 
            "text": "S3 browser  Can get shareable URL via Right Click -  Properties -  Security Tab -  Add (All users) -  Check Download and Read permissions boxes", 
            "title": "DragonDisk"
        }, 
        {
            "location": "/Software/Useful-software/#tex", 
            "text": "", 
            "title": "Tex"
        }, 
        {
            "location": "/Software/Useful-software/#install-packages", 
            "text": "Download package (e.g.  classicthesis  ) and extract the sty file it to a folder named as the package under ~/texmf/tex/latex/packagename (e.g.  /home/user/texmf/tex/latex/classicthesis  )", 
            "title": "Install packages"
        }, 
        {
            "location": "/Software/Useful-software/#misc", 
            "text": "sudo apt-get install nautilus-actions gnome-paint", 
            "title": "Misc"
        }, 
        {
            "location": "/Software/Vim/", 
            "text": "Vimrc\n\n\n\n\nVimrc omorante\n or \nthis\n\n\nModularize vimrc\n\n\n\n\nRegex\n\n\n\n\n Is replaced with the entire text matched by the search pattern when used in a\nreplacement string. This is useful when you want to avoid retyping text:\n\n\n:%s/Yazstremski/\n, Carl/\n\n\n\n\nThe replacement will say Yazstremski, Carl. The \n can also replace a variable pattern\n(as specified by a regular expression). For example, to surround each line from\n1 to 10 with parentheses, type:\n\n\n:1,10s/.*/(\n)/\n\n\n\n\n\n\nfrom \nLearning the vi and Vim Editors, Seventh Edition by Arnold Robbins, Elbert Hannah, and Linda Lamb\n.\n\n\nInsert a space between \n#\n and the character that follows it\n\n\n:%s/#\\(\\w\\)/# \\1/g\n\n\n\n\ngeneral\n\n\n.  any character except new line\n\\s whitespace character\n\\S non-whitespace character\n\\d digit\n\\D non-digit\n\\x hex digit\n\\X non-hex digit\n\\o octal digit\n\\O non-octal digit\n\\h head of word character (a,b,c...z,A,B,C...Z and _)\n\\H non-head of word character\n\\p printable character\n\\P like \\p, but excluding digits\n\\w word character\n\\W non-word character\n\\a alphabetic character\n\\A non-alphabetic character\n\\l lowercase character\n\\L non-lowercase character\n\\u uppercase character\n\\U non-uppercase character\n\n\n\n\nQuickfix\n\n\nC-w\nEnter\n Open file from list\n\n\nVim cool fonts\n\n\nLinux\n\n\n$ mkdir -p ~/.local/share/fonts\n$ cd ~/.local/share/fonts \n curl -fLo \nDroid Sans Mono for Powerline Nerd Font Complete.otf\n https://raw.githubusercontent.com/ryanoasis/nerd-fonts/master/patched-fonts/DroidSansMono/complete/Droid%20Sans%20Mono%20for%20Powerline%20Nerd%20Font%20Complete.otf\n\n\n\n\n\n\nIn vimrc, set\n\n\n\n\nset guifont=Droid\\ Sans\\ Mono\\ for\\ Powerline\\ Plus\\ Nerd\\ File\\ Types\\ 11\n\n\n\n\nMacOS\n\n\ncd ~/Library/Fonts \n curl -fLo \nDroid Sans Mono for Powerline Nerd Font Complete.otf\n https://raw.githubusercontent.com/ryanoasis/nerd-fonts/master/patched-fonts/DroidSansMono/complete/Droid%20Sans%20Mono%20for%20Powerline%20Nerd%20Font%20Complete.otf\n\n\n\n\n\n\nIn .vimrc, \n\n\n\n\nset guifont=Droid\\ Sans\\ Mono\\ for\\ Powerline\\ Plus\\ Nerd\\ File\\ Types:h11\n\n\n\n\n\n\nInstall \nvim-devicons plugin\n, \nafter\n NERDTree and others\n\n\nRestart terminal\n\n\nChange font in terminal\n\n\n\n\nMake vim automatically read file as some filetype\n\n\nInsert this line in the file\n\n\n# vim: set filetype=sh\n\n\n\n\nMisc\n\n\n:echo expand('%:p')\n \nprint filename with full path\n\n\nVim diff\n\n\nturn on\n\n\n:windo diffthis\n\n\nturn off\n\n\n:windo diffoff\n\n\nmove between changes\n\n\n[c jump back\n\n\n]c  and forward\n\n\nMovements\n\n\n\n\ngg\n \nGo to beginning of file\n\n\nG\n \nGo to end of file\n\n\n\n\nWindows et al\n\n\n\n\n^w\n \nChange subwindow\n\n\n:q\n \nCommand history\n\n\n\n\nSearch and replace\n\n\n\n\n+?|\n must be escaped for special function\n\n\n\\r is new line (for replacing)\n\n\n\n\nnormal mode\n\n\n\n\n/wordtosearch\n + \nEnter\n \nSearch for word\n\n\n/\\cwortosearch\n + \nEnter\n  \nCase insensitive search for word\n\n\n:%s/foo/bar/gci\n \nReplaces all ocurrences (g) in all the text (%) of the word \nfoo\n by the word \nbar\n, ignoring cases (i) and asking confirmation (c) for each replacement\n\n\n:%s/patata//gn\n \ncounts ocurrences of patata in all the text\n\n\n\n\nBuffers\n\n\n\n\n:ls\n\n\n:b 2\n \ngo to buffer# 2\n\n\n:vsp filename\n \nvertical split\n\n\n:sp filename\n \nhorizontal split\n\n\n:bnext\n mapped to (Ctrl + \u2192 )  \nnext buffer\n\n\n:bprev\n mapped to (Ctrl + \u2190 ) \nprevious buffer\n\n\n:sb\n \nvertically split buffer on current file\n\n\n\n\nExternal commands and writing (vimtutor# 5)\n\n\n\n\n:!command\n  \nexecutes an external command.\n\n\n:w FILENAME\n  \nwrites the current Vim file to disk with name FILENAME.\n\n\nv  motion  :w FILENAME\n  \nsaves the Visually selected lines in file FILENAME.\n\n\n:r FILENAME\n  \nretrieves disk file FILENAME and puts it below the cursor position.\n\n\n:r !dir\n  \nreads the output of the dir command and puts it below the cursor position.\n\n\n\n\nEditing\n\n\nNormal mode\n\n\n\n\n:m .+1\n \nMove line down\n\n\n:m .-2\n \nMove line up\n\n\n`cw  \nchange word (deletes word and switches to insert mode)\n\n\nci\"\n \nchange insde \" (also, ([{, etc)\n\n\n55,60d \ndeleted lines 55-60 (can be applied to other actions)\n\n\ngg=G\n \nformat all file\n\n\n# ngg\n \ngo to line number # n\n\n\n:set list\n \nshow whitespaces\n\n\nu\n \nundo\n\n\nU\n \nundo changes on line\n\n\nCTRL + R\n \nredo\n\n\nA\n \ngoes to end of line and enters insert mode\n\n\n\n\n*\n \ngoes to next appearance of the word pointed by the cursor\n\n\n\n\n\n\nzb\n \ngoes to bottom of screen\n\n\n\n\nzz\n \ngoes to middle of screen\n\n\nzt\n \ngoes to top of screen\n\n\n\n\nScreen moving\n\n\n\n\n^f\n \nmove one screen forward\n\n\n^b\n \nmove one screen backwards\n\n\n\n\nInsert mode\n\n\n\n\nctrl+Space\n (was \nCtrl+N\n) \nAutocomplete\n\n\n\n\nVisual Mode\n\n\n\n\nv\n \nvisual mode\n\n\nV\n \nvisual line mode\n\n\nCTRL + v\n \nvisual block mode\n\n\n\n\nAdd text to multiple lines (at the same cursor position: column)\n\n\n\n\nEnter visual block mode\n\n\nSelect lines\n\n\nType \nI\n (capital i)\n\n\nWrite text\n\n\nPress \nEscape\n\n\n\n\nPlugins\n\n\nUltisnips\n\n\n\n\nFrom \nhere\n.\n\n\nConfigure custom snippets folder like this:\n\n\n\n\nlet g:UltiSnipsSnippetDirectories=[\n~/.vim/custom_snippets\n]\n\n\n\n\n\n\nAs noted in the docs, do NOT map tab to trigger:\n\n\n\n\nlet g:UltiSnipsExpandTrigger=\nc-e\n\n\n\n\n\n\n\nCheck \nPython interpolation\n\n\n\n\nNERDTree\n\n\n\n\nRTFM\n\n\nor\n\n\nRead this:\n\nFrom within NERDTree Window\n\n\nm\n \nbring up the NERDTree Filesystem Menu\n\n\na\n create new file\n\n\nt\n \nopen in tab\n\n\ni\n \nopen in h split\n\n\ns\n \nopen in v split\n\n\nO\n expand selected folder recursively_\n\n\nI\n \nshow/hide hidden files\n\n\nC\n \nchange root to highlighted folder", 
            "title": "Vim"
        }, 
        {
            "location": "/Software/Vim/#vimrc", 
            "text": "Vimrc omorante  or  this  Modularize vimrc", 
            "title": "Vimrc"
        }, 
        {
            "location": "/Software/Vim/#regex", 
            "text": "", 
            "title": "Regex"
        }, 
        {
            "location": "/Software/Vim/#_1", 
            "text": "Is replaced with the entire text matched by the search pattern when used in a\nreplacement string. This is useful when you want to avoid retyping text:  :%s/Yazstremski/ , Carl/  The replacement will say Yazstremski, Carl. The   can also replace a variable pattern\n(as specified by a regular expression). For example, to surround each line from\n1 to 10 with parentheses, type:  :1,10s/.*/( )/   from  Learning the vi and Vim Editors, Seventh Edition by Arnold Robbins, Elbert Hannah, and Linda Lamb .", 
            "title": "&amp;"
        }, 
        {
            "location": "/Software/Vim/#insert-a-space-between-and-the-character-that-follows-it", 
            "text": ":%s/#\\(\\w\\)/# \\1/g", 
            "title": "Insert a space between # and the character that follows it"
        }, 
        {
            "location": "/Software/Vim/#general", 
            "text": ".  any character except new line\n\\s whitespace character\n\\S non-whitespace character\n\\d digit\n\\D non-digit\n\\x hex digit\n\\X non-hex digit\n\\o octal digit\n\\O non-octal digit\n\\h head of word character (a,b,c...z,A,B,C...Z and _)\n\\H non-head of word character\n\\p printable character\n\\P like \\p, but excluding digits\n\\w word character\n\\W non-word character\n\\a alphabetic character\n\\A non-alphabetic character\n\\l lowercase character\n\\L non-lowercase character\n\\u uppercase character\n\\U non-uppercase character", 
            "title": "general"
        }, 
        {
            "location": "/Software/Vim/#quickfix", 
            "text": "C-w Enter  Open file from list", 
            "title": "Quickfix"
        }, 
        {
            "location": "/Software/Vim/#vim-cool-fonts", 
            "text": "Linux  $ mkdir -p ~/.local/share/fonts\n$ cd ~/.local/share/fonts   curl -fLo  Droid Sans Mono for Powerline Nerd Font Complete.otf  https://raw.githubusercontent.com/ryanoasis/nerd-fonts/master/patched-fonts/DroidSansMono/complete/Droid%20Sans%20Mono%20for%20Powerline%20Nerd%20Font%20Complete.otf   In vimrc, set   set guifont=Droid\\ Sans\\ Mono\\ for\\ Powerline\\ Plus\\ Nerd\\ File\\ Types\\ 11  MacOS  cd ~/Library/Fonts   curl -fLo  Droid Sans Mono for Powerline Nerd Font Complete.otf  https://raw.githubusercontent.com/ryanoasis/nerd-fonts/master/patched-fonts/DroidSansMono/complete/Droid%20Sans%20Mono%20for%20Powerline%20Nerd%20Font%20Complete.otf   In .vimrc,    set guifont=Droid\\ Sans\\ Mono\\ for\\ Powerline\\ Plus\\ Nerd\\ File\\ Types:h11   Install  vim-devicons plugin ,  after  NERDTree and others  Restart terminal  Change font in terminal", 
            "title": "Vim cool fonts"
        }, 
        {
            "location": "/Software/Vim/#make-vim-automatically-read-file-as-some-filetype", 
            "text": "Insert this line in the file  # vim: set filetype=sh", 
            "title": "Make vim automatically read file as some filetype"
        }, 
        {
            "location": "/Software/Vim/#misc", 
            "text": ":echo expand('%:p')   print filename with full path", 
            "title": "Misc"
        }, 
        {
            "location": "/Software/Vim/#vim-diff", 
            "text": "", 
            "title": "Vim diff"
        }, 
        {
            "location": "/Software/Vim/#turn-on", 
            "text": ":windo diffthis", 
            "title": "turn on"
        }, 
        {
            "location": "/Software/Vim/#turn-off", 
            "text": ":windo diffoff", 
            "title": "turn off"
        }, 
        {
            "location": "/Software/Vim/#move-between-changes", 
            "text": "[c jump back  ]c  and forward", 
            "title": "move between changes"
        }, 
        {
            "location": "/Software/Vim/#movements", 
            "text": "gg   Go to beginning of file  G   Go to end of file", 
            "title": "Movements"
        }, 
        {
            "location": "/Software/Vim/#windows-et-al", 
            "text": "^w   Change subwindow  :q   Command history", 
            "title": "Windows et al"
        }, 
        {
            "location": "/Software/Vim/#search-and-replace", 
            "text": "+?|  must be escaped for special function  \\r is new line (for replacing)", 
            "title": "Search and replace"
        }, 
        {
            "location": "/Software/Vim/#normal-mode", 
            "text": "/wordtosearch  +  Enter   Search for word  /\\cwortosearch  +  Enter    Case insensitive search for word  :%s/foo/bar/gci   Replaces all ocurrences (g) in all the text (%) of the word  foo  by the word  bar , ignoring cases (i) and asking confirmation (c) for each replacement  :%s/patata//gn   counts ocurrences of patata in all the text", 
            "title": "normal mode"
        }, 
        {
            "location": "/Software/Vim/#buffers", 
            "text": ":ls  :b 2   go to buffer# 2  :vsp filename   vertical split  :sp filename   horizontal split  :bnext  mapped to (Ctrl + \u2192 )   next buffer  :bprev  mapped to (Ctrl + \u2190 )  previous buffer  :sb   vertically split buffer on current file", 
            "title": "Buffers"
        }, 
        {
            "location": "/Software/Vim/#external-commands-and-writing-vimtutor-5", 
            "text": ":!command    executes an external command.  :w FILENAME    writes the current Vim file to disk with name FILENAME.  v  motion  :w FILENAME    saves the Visually selected lines in file FILENAME.  :r FILENAME    retrieves disk file FILENAME and puts it below the cursor position.  :r !dir    reads the output of the dir command and puts it below the cursor position.", 
            "title": "External commands and writing (vimtutor# 5)"
        }, 
        {
            "location": "/Software/Vim/#editing", 
            "text": "", 
            "title": "Editing"
        }, 
        {
            "location": "/Software/Vim/#normal-mode_1", 
            "text": ":m .+1   Move line down  :m .-2   Move line up  `cw   change word (deletes word and switches to insert mode)  ci\"   change insde \" (also, ([{, etc)  55,60d  deleted lines 55-60 (can be applied to other actions)  gg=G   format all file  # ngg   go to line number # n  :set list   show whitespaces  u   undo  U   undo changes on line  CTRL + R   redo  A   goes to end of line and enters insert mode   *   goes to next appearance of the word pointed by the cursor    zb   goes to bottom of screen   zz   goes to middle of screen  zt   goes to top of screen", 
            "title": "Normal mode"
        }, 
        {
            "location": "/Software/Vim/#screen-moving", 
            "text": "^f   move one screen forward  ^b   move one screen backwards", 
            "title": "Screen moving"
        }, 
        {
            "location": "/Software/Vim/#insert-mode", 
            "text": "ctrl+Space  (was  Ctrl+N )  Autocomplete", 
            "title": "Insert mode"
        }, 
        {
            "location": "/Software/Vim/#visual-mode", 
            "text": "v   visual mode  V   visual line mode  CTRL + v   visual block mode", 
            "title": "Visual Mode"
        }, 
        {
            "location": "/Software/Vim/#add-text-to-multiple-lines-at-the-same-cursor-position-column", 
            "text": "Enter visual block mode  Select lines  Type  I  (capital i)  Write text  Press  Escape", 
            "title": "Add text to multiple lines (at the same cursor position: column)"
        }, 
        {
            "location": "/Software/Vim/#plugins", 
            "text": "", 
            "title": "Plugins"
        }, 
        {
            "location": "/Software/Vim/#ultisnips", 
            "text": "From  here .  Configure custom snippets folder like this:   let g:UltiSnipsSnippetDirectories=[ ~/.vim/custom_snippets ]   As noted in the docs, do NOT map tab to trigger:   let g:UltiSnipsExpandTrigger= c-e    Check  Python interpolation", 
            "title": "Ultisnips"
        }, 
        {
            "location": "/Software/Vim/#nerdtree", 
            "text": "RTFM  or  Read this: From within NERDTree Window  m   bring up the NERDTree Filesystem Menu  a  create new file  t   open in tab  i   open in h split  s   open in v split  O  expand selected folder recursively_  I   show/hide hidden files  C   change root to highlighted folder", 
            "title": "NERDTree"
        }, 
        {
            "location": "/Software/VirtualBox/", 
            "text": "Install VBox additions!\n\n\nStart headless machine CLI\n\n\nVBoxManage startvm ubuservloc --type headless\n\n\nGet ip(v4) address of a vbox machine (named \nubuntu\n)\n\n\nPut \nBridged Adapter\n in the Network Settings\n\n\nVBoxManage guestproperty enumerate ubuntu | grep \nNet.*V4.*IP\n\n\n\n\n\nAdd shared folder from ubuntu guest\n\n\nsudo mount -t vboxsf -o uid=$UID,gid=$(id -g) NAME_OF_SHARED_FOLDER_IN_VBOX FOLDER_IN_WHICH_TO_MOUNT\n\n\nShare folder between ubuntu host and windows guest\n\n\n\n\nAdd folder to shared folders in VBox settings\n\n\nIn windows cli: \nnet use \nletra\n: \\\\vboxsvr\\shared_folder_name\n\n\n\n\nResize emulated hard drive\n\n\nuser@pc :~$ VBoxManage modifyhd filename.vdi --resize 46080\n\n\nProblems\n\n\nSSH doesn't work\n\n\nTry bridged mode\n\n\nPremature end of data in tag VirtualBox line 2\n\n\n\n\nLooks like it was caused (in my case) because of the host machine running out of space\n\n\nFound \nthis\n and some luck.\n\n\nbackup the vbox file, and substitute the \n/path/to/vm/win7/win7.vbox\n file with the contents of \n/path/to/vm/win7/win7.vbox\n. Lost some progress, though.", 
            "title": "VirtualBox"
        }, 
        {
            "location": "/Software/VirtualBox/#start-headless-machine-cli", 
            "text": "VBoxManage startvm ubuservloc --type headless", 
            "title": "Start headless machine CLI"
        }, 
        {
            "location": "/Software/VirtualBox/#get-ipv4-address-of-a-vbox-machine-named-ubuntu", 
            "text": "Put  Bridged Adapter  in the Network Settings  VBoxManage guestproperty enumerate ubuntu | grep  Net.*V4.*IP", 
            "title": "Get ip(v4) address of a vbox machine (named ubuntu)"
        }, 
        {
            "location": "/Software/VirtualBox/#add-shared-folder-from-ubuntu-guest", 
            "text": "sudo mount -t vboxsf -o uid=$UID,gid=$(id -g) NAME_OF_SHARED_FOLDER_IN_VBOX FOLDER_IN_WHICH_TO_MOUNT", 
            "title": "Add shared folder from ubuntu guest"
        }, 
        {
            "location": "/Software/VirtualBox/#share-folder-between-ubuntu-host-and-windows-guest", 
            "text": "Add folder to shared folders in VBox settings  In windows cli:  net use  letra : \\\\vboxsvr\\shared_folder_name", 
            "title": "Share folder between ubuntu host and windows guest"
        }, 
        {
            "location": "/Software/VirtualBox/#resize-emulated-hard-drive", 
            "text": "user@pc :~$ VBoxManage modifyhd filename.vdi --resize 46080", 
            "title": "Resize emulated hard drive"
        }, 
        {
            "location": "/Software/VirtualBox/#problems", 
            "text": "", 
            "title": "Problems"
        }, 
        {
            "location": "/Software/VirtualBox/#ssh-doesnt-work", 
            "text": "Try bridged mode", 
            "title": "SSH doesn't work"
        }, 
        {
            "location": "/Software/VirtualBox/#premature-end-of-data-in-tag-virtualbox-line-2", 
            "text": "Looks like it was caused (in my case) because of the host machine running out of space  Found  this  and some luck.  backup the vbox file, and substitute the  /path/to/vm/win7/win7.vbox  file with the contents of  /path/to/vm/win7/win7.vbox . Lost some progress, though.", 
            "title": "Premature end of data in tag VirtualBox line 2"
        }, 
        {
            "location": "/Software/ffmpeg/", 
            "text": "Rotate video 90 degrees\n\n\nffmpeg -i input.mp4 -filter:v transpose=2 -c:v libx264 -preset veryfast -crf 22 -c:a copy -metadata:s:v rotate=\n input_rotated.mp4", 
            "title": "Ffmpeg"
        }, 
        {
            "location": "/Software/ffmpeg/#rotate-video-90-degrees", 
            "text": "ffmpeg -i input.mp4 -filter:v transpose=2 -c:v libx264 -preset veryfast -crf 22 -c:a copy -metadata:s:v rotate=  input_rotated.mp4", 
            "title": "Rotate video 90 degrees"
        }, 
        {
            "location": "/Software/mutt/", 
            "text": "Generate gmail password for mutt\n\n\nhttps://security.google.com/settings/security/apppasswords\n\n\nSend email with attachment\n\n\n$ mutt -s \nTest from mutt\n user@mail.com \n /tmp/message.txt -a /tmp/file.jpg\n\n\n\n\n.muttrc Gmail configuration\n\n\nset ssl_starttls=yes\nset ssl_force_tls=yes\nset from='gmail_email_address'\nset realname='Real Name'\nset folder = imaps://imap.gmail.com/\nset spoolfile = imaps://imap.gmail.com/INBOX\nset postponed=\nimaps://imap.gmail.com/[Gmail]/Drafts\n\nset header_cache = \n~/.mutt/cache/headers\n\nset message_cachedir = \n~/.mutt/cache/bodies\n\nset certificate_file = \n~/.mutt/certificates\n\nset imap_user = 'gmail_email_address'\nset imap_pass = 'gmail_generated_password_for_insecure_apps'\nset smtp_url = \nsmtps://'gmail_email_address'@smtp.gmail.com:465/\n\nset smtp_pass = 'gmail_generated_password_for_insecure_apps'\nset record=\n\nset move = no\nset imap_keepalive = 900", 
            "title": "Mutt"
        }, 
        {
            "location": "/Software/mutt/#generate-gmail-password-for-mutt", 
            "text": "https://security.google.com/settings/security/apppasswords", 
            "title": "Generate gmail password for mutt"
        }, 
        {
            "location": "/Software/mutt/#send-email-with-attachment", 
            "text": "$ mutt -s  Test from mutt  user@mail.com   /tmp/message.txt -a /tmp/file.jpg", 
            "title": "Send email with attachment"
        }, 
        {
            "location": "/Software/mutt/#muttrc-gmail-configuration", 
            "text": "set ssl_starttls=yes\nset ssl_force_tls=yes\nset from='gmail_email_address'\nset realname='Real Name'\nset folder = imaps://imap.gmail.com/\nset spoolfile = imaps://imap.gmail.com/INBOX\nset postponed= imaps://imap.gmail.com/[Gmail]/Drafts \nset header_cache =  ~/.mutt/cache/headers \nset message_cachedir =  ~/.mutt/cache/bodies \nset certificate_file =  ~/.mutt/certificates \nset imap_user = 'gmail_email_address'\nset imap_pass = 'gmail_generated_password_for_insecure_apps'\nset smtp_url =  smtps://'gmail_email_address'@smtp.gmail.com:465/ \nset smtp_pass = 'gmail_generated_password_for_insecure_apps'\nset record= \nset move = no\nset imap_keepalive = 900", 
            "title": ".muttrc Gmail configuration"
        }, 
        {
            "location": "/Software/sublime/", 
            "text": "Assign key to reindent\n\n\nYou can find it in Edit \u2192 Line \u2192 Reindent, but it does not have a shortcut by default. You can add a shortcut by going to the menu Preferences \u2192 Keybindings \u2192 User, then add there:\n\n\n{ \nkeys\n: [\nf12\n], \ncommand\n: \nreindent\n}   \n(example of using the F12 key for that functionality)\n\n\n\n\nThe config files use JSON-syntax, so these curly braces have to be placed comma-separated in the square-brackets that are there by default. If you dont have any other key-bindings already, then your whole Keybindings \u2192 User file would look like this, of course:\n\n\n[\n{ \nkeys\n: [\nCtrl+i\n], \ncommand\n: \nreindent\n}   \n]\n\n\n\n\nSublime text code completion config path\n\n\n~/.config/sublime-text-2/Packages/SublimeCodeIntel\n\n\n\n\nRegex replace\n\n\n(?:def (?\nfuncName\n.*)(?\npatata\n\\())\ndef $1(self, \n\n\n\n\nbefore\n\n\ndef curateText(name):\n\n\nafter\n\n\ndef curateText(self, name):", 
            "title": "Sublime"
        }, 
        {
            "location": "/Software/sublime/#assign-key-to-reindent", 
            "text": "You can find it in Edit \u2192 Line \u2192 Reindent, but it does not have a shortcut by default. You can add a shortcut by going to the menu Preferences \u2192 Keybindings \u2192 User, then add there:  {  keys : [ f12 ],  command :  reindent }   \n(example of using the F12 key for that functionality)  The config files use JSON-syntax, so these curly braces have to be placed comma-separated in the square-brackets that are there by default. If you dont have any other key-bindings already, then your whole Keybindings \u2192 User file would look like this, of course:  [\n{  keys : [ Ctrl+i ],  command :  reindent }   \n]", 
            "title": "Assign key to reindent"
        }, 
        {
            "location": "/Software/sublime/#sublime-text-code-completion-config-path", 
            "text": "~/.config/sublime-text-2/Packages/SublimeCodeIntel", 
            "title": "Sublime text code completion config path"
        }, 
        {
            "location": "/Software/sublime/#regex-replace", 
            "text": "(?:def (? funcName .*)(? patata \\())\ndef $1(self,", 
            "title": "Regex replace"
        }, 
        {
            "location": "/Software/sublime/#before", 
            "text": "def curateText(name):", 
            "title": "before"
        }, 
        {
            "location": "/Software/sublime/#after", 
            "text": "def curateText(self, name):", 
            "title": "after"
        }, 
        {
            "location": "/Software/tmux/", 
            "text": "Build tmux from scratch\n\n\nConfiguration\n\n\nMacOS\n\n\nset-option -g default-command \"reattach-to-user-namespace -l zsh\"\n\n\n~./tmux.conf\n\n\nConfig example\n\n\nSimple tmux statusline generator \n\n\nGenerate a fast shell prompt\n\n\nCheatsheet\n\n\nhttps://gist.github.com/patsancu/60bfd4576af7fecd6f8b4329347a108e\n\n\nSessions\n\n\ntmux new -s session_name\n\n\n\n\n^B + d\n detach from session without killing anything\n\ntmux attach -t session_name\n attach to sessions\n\n\nPlugins\n\n\nhttps://github.com/tmux-plugins/tpm", 
            "title": "Tmux"
        }, 
        {
            "location": "/Software/tmux/#build-tmux-from-scratch", 
            "text": "", 
            "title": "Build tmux from scratch"
        }, 
        {
            "location": "/Software/tmux/#configuration", 
            "text": "", 
            "title": "Configuration"
        }, 
        {
            "location": "/Software/tmux/#macos", 
            "text": "set-option -g default-command \"reattach-to-user-namespace -l zsh\"", 
            "title": "MacOS"
        }, 
        {
            "location": "/Software/tmux/#tmuxconf", 
            "text": "Config example", 
            "title": "~./tmux.conf"
        }, 
        {
            "location": "/Software/tmux/#simple-tmux-statusline-generator", 
            "text": "", 
            "title": "Simple tmux statusline generator"
        }, 
        {
            "location": "/Software/tmux/#generate-a-fast-shell-prompt", 
            "text": "", 
            "title": "Generate a fast shell prompt"
        }, 
        {
            "location": "/Software/tmux/#cheatsheet", 
            "text": "https://gist.github.com/patsancu/60bfd4576af7fecd6f8b4329347a108e", 
            "title": "Cheatsheet"
        }, 
        {
            "location": "/Software/tmux/#sessions", 
            "text": "tmux new -s session_name  ^B + d  detach from session without killing anything tmux attach -t session_name  attach to sessions", 
            "title": "Sessions"
        }, 
        {
            "location": "/Software/tmux/#plugins", 
            "text": "https://github.com/tmux-plugins/tpm", 
            "title": "Plugins"
        }, 
        {
            "location": "/Web/Web-browsing-tips/", 
            "text": "Javascript: Show password for websites which remember your login details\n\n\n$x('//input[@type=\npassword\n]')[0].setAttribute(\ntype\n, \ntext\n)\n\n\n\n\nJavascript play with xpath\n\n\nhttps://gist.github.com/patsancu/7d19c0db94d624e185de9ca748c374ae\n\n\nUse Tor with Chromium\n\n\n\n\nInstall tor and polipo\n\n\nIn /etc/polipo/config uncomment lines:\n\n\n\n\nsocksParentProxy = \nlocalhost:9050\n\nsocksProxyType = socks5\n\n\n\n\n\n\nUse chromium\n\n\n\n\nchromium-browser --proxy-server=\"127.0.0.1:8118;https=127.0.0.1:8118;socks=127.0.0.1:8118;sock4=127.0.0.1:8118;sock5=127.0.0.1:8118,ftp=127.0.0.1:8118\" --incognito check.torproject.org", 
            "title": "Web browsing tips"
        }, 
        {
            "location": "/Web/Web-browsing-tips/#javascript-show-password-for-websites-which-remember-your-login-details", 
            "text": "$x('//input[@type= password ]')[0].setAttribute( type ,  text )", 
            "title": "Javascript: Show password for websites which remember your login details"
        }, 
        {
            "location": "/Web/Web-browsing-tips/#javascript-play-with-xpath", 
            "text": "https://gist.github.com/patsancu/7d19c0db94d624e185de9ca748c374ae", 
            "title": "Javascript play with xpath"
        }, 
        {
            "location": "/Web/Web-browsing-tips/#use-tor-with-chromium", 
            "text": "Install tor and polipo  In /etc/polipo/config uncomment lines:   socksParentProxy =  localhost:9050 \nsocksProxyType = socks5   Use chromium   chromium-browser --proxy-server=\"127.0.0.1:8118;https=127.0.0.1:8118;socks=127.0.0.1:8118;sock4=127.0.0.1:8118;sock5=127.0.0.1:8118,ftp=127.0.0.1:8118\" --incognito check.torproject.org", 
            "title": "Use Tor with Chromium"
        }, 
        {
            "location": "/Web/Web-dev-resources/", 
            "text": "Themes\n\n\n\n\nHTML5up\n\n\nZero theme\n\n\nFree CSS\n\n\n\n\nGeojson map coordinates\n\n\nGeojson.io\n\n\nMaps\n\n\nMap themes\n\n\nhttps://snazzymaps.com/\n\n\nTangram\n\n\nCool OpenGL maps\n\n\nImages\n\n\n\n\nUpload free private images\n\n\nFreeimages\n\n\n\n\nHTTP Request \n Response Service\n\n\nWebsite to test post, get and other stuff about http requests\n\n\nJson mock api\n\n\nmyjson\n\n\nMisc\n\n\nFor the LOL\n\n\nMachine, please make super great website\n\nor, if not available, \nthis one", 
            "title": "Web dev resources"
        }, 
        {
            "location": "/Web/Web-dev-resources/#themes", 
            "text": "HTML5up  Zero theme  Free CSS", 
            "title": "Themes"
        }, 
        {
            "location": "/Web/Web-dev-resources/#geojson-map-coordinates", 
            "text": "Geojson.io", 
            "title": "Geojson map coordinates"
        }, 
        {
            "location": "/Web/Web-dev-resources/#maps", 
            "text": "", 
            "title": "Maps"
        }, 
        {
            "location": "/Web/Web-dev-resources/#map-themes", 
            "text": "https://snazzymaps.com/", 
            "title": "Map themes"
        }, 
        {
            "location": "/Web/Web-dev-resources/#tangram", 
            "text": "Cool OpenGL maps", 
            "title": "Tangram"
        }, 
        {
            "location": "/Web/Web-dev-resources/#images", 
            "text": "Upload free private images  Freeimages", 
            "title": "Images"
        }, 
        {
            "location": "/Web/Web-dev-resources/#http-request-response-service", 
            "text": "Website to test post, get and other stuff about http requests", 
            "title": "HTTP Request &amp; Response Service"
        }, 
        {
            "location": "/Web/Web-dev-resources/#json-mock-api", 
            "text": "myjson", 
            "title": "Json mock api"
        }, 
        {
            "location": "/Web/Web-dev-resources/#misc", 
            "text": "", 
            "title": "Misc"
        }, 
        {
            "location": "/Web/Web-dev-resources/#for-the-lol", 
            "text": "Machine, please make super great website \nor, if not available,  this one", 
            "title": "For the LOL"
        }, 
        {
            "location": "/dev/DB/Oracle/", 
            "text": "How to turn off oracle password expiration\n\n\nsource\n\n\nTo alter the password expiry policy for a certain user profile in Oracle first check wich profile the user is in using:\n\n\nselect profile from DBA_USERS where username = '\nusername\n';\n\n\n\n\nThen you can change the limit to never expire using:\n\n\nalter profile \nprofile_name\n limit password_life_time UNLIMITED;\n\n\n\n\nIf you want to previously check the limit you may use:\n\n\nselect resource_name,limit from dba_profiles where profile='\nprofile_name\n';\n\n\n\n\nWhat do if password expired oracle\n\n\ndelete user\n\n\ndrop user cms_int cascade;\n\n\n\n\ncreate user again\n\n\ncreate user cms_int identified by cms_int;\ngrant all privileges to cms_int identified by cms_int;\n\n\n\n\nImport db dump\n\n\nCREATE USER bakbak IDENTIFIED BY bakbak;\nGRANT CREATE TRIGGER, CREATE SEQUENCE, CREATE SESSION, CREATE TABLE, CREATE VIEW, CREATE PROCEDURE, CREATE SYNONYM, CREATE TABLESPACE TO bakbak;\nGRANT ALTER TABLESPACE TO bakbak;\nGRANT ALTER ANY TABLE, ALTER ANY PROCEDURE TO bakbak;\nGRANT DROP TABLESPACE, DROP ANY TABLE, DROP ANY VIEW, DROP ANY PROCEDURE,DROP ANY SYNONYM TO bakbak;\nALTER USER bakbak QUOTA UNLIMITED ON USERS;\nGRANT UNLIMITED TABLESPACE TO bakbak;\n\nGRANT CREATE ANY DIRECTORY TO bakbak;\nGRANT DROP ANY DIRECTORY TO bakbak;\n\nGRANT CREATE TRIGGER TO bakbak;\nGRANT DROP ANY PROCEDURE TO bakbak;\nGRANT ALTER ANY PROCEDURE TO bakbak;\nGRANT CREATE PROCEDURE TO bakbak;\nGRANT CREATE SEQUENCE TO bakbak;\nGRANT DROP ANY VIEW TO bakbak;\nGRANT CREATE VIEW TO bakbak;\nGRANT DROP ANY SYNONYM TO bakbak;\nGRANT CREATE SYNONYM TO bakbak;\nGRANT DROP ANY TABLE TO bakbak;\nGRANT ALTER ANY TABLE TO bakbak;\nGRANT CREATE TABLE TO bakbak;\nGRANT UNLIMITED TABLESPACE TO bakbak;\nGRANT DROP TABLESPACE TO bakbak;\nGRANT ALTER TABLESPACE TO bakbak;\nGRANT CREATE TABLESPACE TO bakbak;\nGRANT CREATE SESSION TO bakbak; \nGRANT IMP_FULL_DATABASE TO bakbak;\nGRANT EXP_FULL_DATABASE TO bakbak;\nCREATE DIRECTORY mydir AS '/home/patrick/Data/dumps_db/'; GRANT read, write on directory mydir to public;\nGRANT read, write ON mydir TO bakbak;\nALTER USER bakbak QUOTA UNLIMITED ON USERS;\nGRANT UNLIMITED TABLESPACE TO bakbak;\ncommit;\n\n\n\n\nExecute in bash \n\n\nimpdp bakbak/bakbak directory=mydir file=export_data.dmp remap_schema=cv_mex_mtv:bakbak \nEXCLUDE=TABLE:\\\nIN \\(\\'EIT_MANIFEST\\',\\'WH_FACT_AUDIENCE\\',\\'ACT_ACTIVITY\\', \\'REC_RECORDING\\', \\'REC_RECORDING_I18N\\', \\'ADI_FILE_IMPORT\\' \\)\\\n logfile=data_pump_dir:expsh.log\n### Stop job impdp\nImport\n KILL_JOB\n### Find and delete pending import jobs\n```sql\nSELECT owner_name, job_name, operation, job_mode,\nstate, attached_sessions\nFROM dba_datapump_jobs\nORDER BY 1,2;\n\n\n\n\nSELECT *\n  FROM dba_objects o, dba_datapump_jobs j\n WHERE o.owner=j.owner_name AND o.object_name=j.job_name \n   AND j.job_name NOT LIKE 'BIN$%' ORDER BY 4,2;\n\nDROP TABLE BAKBAK.SYS_IMPORT_FULL_01;\n\n\n\n\nDelete views, tables for a user\n\n\nGet scripts to drop tables and views\n\n\nselect 'drop table '||table_name||' cascade constraints;' from user_tables;\n\n\n\n\nselect 'drop view '||view_name||' cascade constraints;' from user_views;\n\n\n\n\nDelete sequences\n\n\nBEGIN\n\n  --Bye Sequences!\n  FOR i IN (SELECT us.sequence_name\n              FROM USER_SEQUENCES us) LOOP\n    EXECUTE IMMEDIATE 'drop sequence '|| i.sequence_name ||'';\n  END LOOP;\n\n  --Bye Tables!\n  FOR i IN (SELECT ut.table_name\n              FROM USER_TABLES ut) LOOP\n    EXECUTE IMMEDIATE 'drop table '|| i.table_name ||' CASCADE CONSTRAINTS ';\n  END LOOP;\n\nEND;\n\n\n\n\nCalculate table size\n\n\nsource\n\n\n-- Tables + Size MB\nselect owner, table_name, round((num_rows*avg_row_len)/(1024*1024)) MB \nfrom all_tables \nwhere owner not like 'SYS%'  -- Exclude system tables.\nand num_rows \n 0  -- Ignore empty Tables.\norder by MB desc -- Biggest first.;\n--Tables + Rows\nselect owner, table_name, num_rows\n from all_tables \nwhere owner not like 'SYS%'  -- Exclude system tables.\nand num_rows \n 0  -- Ignore empty Tables.\norder by num_rows desc -- Biggest first.;", 
            "title": "Oracle"
        }, 
        {
            "location": "/dev/DB/Oracle/#how-to-turn-off-oracle-password-expiration", 
            "text": "source  To alter the password expiry policy for a certain user profile in Oracle first check wich profile the user is in using:  select profile from DBA_USERS where username = ' username ';  Then you can change the limit to never expire using:  alter profile  profile_name  limit password_life_time UNLIMITED;  If you want to previously check the limit you may use:  select resource_name,limit from dba_profiles where profile=' profile_name ';", 
            "title": "How to turn off oracle password expiration"
        }, 
        {
            "location": "/dev/DB/Oracle/#what-do-if-password-expired-oracle", 
            "text": "", 
            "title": "What do if password expired oracle"
        }, 
        {
            "location": "/dev/DB/Oracle/#delete-user", 
            "text": "drop user cms_int cascade;", 
            "title": "delete user"
        }, 
        {
            "location": "/dev/DB/Oracle/#create-user-again", 
            "text": "create user cms_int identified by cms_int;\ngrant all privileges to cms_int identified by cms_int;", 
            "title": "create user again"
        }, 
        {
            "location": "/dev/DB/Oracle/#import-db-dump", 
            "text": "CREATE USER bakbak IDENTIFIED BY bakbak;\nGRANT CREATE TRIGGER, CREATE SEQUENCE, CREATE SESSION, CREATE TABLE, CREATE VIEW, CREATE PROCEDURE, CREATE SYNONYM, CREATE TABLESPACE TO bakbak;\nGRANT ALTER TABLESPACE TO bakbak;\nGRANT ALTER ANY TABLE, ALTER ANY PROCEDURE TO bakbak;\nGRANT DROP TABLESPACE, DROP ANY TABLE, DROP ANY VIEW, DROP ANY PROCEDURE,DROP ANY SYNONYM TO bakbak;\nALTER USER bakbak QUOTA UNLIMITED ON USERS;\nGRANT UNLIMITED TABLESPACE TO bakbak;\n\nGRANT CREATE ANY DIRECTORY TO bakbak;\nGRANT DROP ANY DIRECTORY TO bakbak;\n\nGRANT CREATE TRIGGER TO bakbak;\nGRANT DROP ANY PROCEDURE TO bakbak;\nGRANT ALTER ANY PROCEDURE TO bakbak;\nGRANT CREATE PROCEDURE TO bakbak;\nGRANT CREATE SEQUENCE TO bakbak;\nGRANT DROP ANY VIEW TO bakbak;\nGRANT CREATE VIEW TO bakbak;\nGRANT DROP ANY SYNONYM TO bakbak;\nGRANT CREATE SYNONYM TO bakbak;\nGRANT DROP ANY TABLE TO bakbak;\nGRANT ALTER ANY TABLE TO bakbak;\nGRANT CREATE TABLE TO bakbak;\nGRANT UNLIMITED TABLESPACE TO bakbak;\nGRANT DROP TABLESPACE TO bakbak;\nGRANT ALTER TABLESPACE TO bakbak;\nGRANT CREATE TABLESPACE TO bakbak;\nGRANT CREATE SESSION TO bakbak; \nGRANT IMP_FULL_DATABASE TO bakbak;\nGRANT EXP_FULL_DATABASE TO bakbak;\nCREATE DIRECTORY mydir AS '/home/patrick/Data/dumps_db/'; GRANT read, write on directory mydir to public;\nGRANT read, write ON mydir TO bakbak;\nALTER USER bakbak QUOTA UNLIMITED ON USERS;\nGRANT UNLIMITED TABLESPACE TO bakbak;\ncommit;  Execute in bash   impdp bakbak/bakbak directory=mydir file=export_data.dmp remap_schema=cv_mex_mtv:bakbak  EXCLUDE=TABLE:\\ IN \\(\\'EIT_MANIFEST\\',\\'WH_FACT_AUDIENCE\\',\\'ACT_ACTIVITY\\', \\'REC_RECORDING\\', \\'REC_RECORDING_I18N\\', \\'ADI_FILE_IMPORT\\' \\)\\  logfile=data_pump_dir:expsh.log\n### Stop job impdp\nImport  KILL_JOB\n### Find and delete pending import jobs\n```sql\nSELECT owner_name, job_name, operation, job_mode,\nstate, attached_sessions\nFROM dba_datapump_jobs\nORDER BY 1,2;  SELECT *\n  FROM dba_objects o, dba_datapump_jobs j\n WHERE o.owner=j.owner_name AND o.object_name=j.job_name \n   AND j.job_name NOT LIKE 'BIN$%' ORDER BY 4,2;\n\nDROP TABLE BAKBAK.SYS_IMPORT_FULL_01;", 
            "title": "Import db dump"
        }, 
        {
            "location": "/dev/DB/Oracle/#delete-views-tables-for-a-user", 
            "text": "", 
            "title": "Delete views, tables for a user"
        }, 
        {
            "location": "/dev/DB/Oracle/#get-scripts-to-drop-tables-and-views", 
            "text": "select 'drop table '||table_name||' cascade constraints;' from user_tables;  select 'drop view '||view_name||' cascade constraints;' from user_views;", 
            "title": "Get scripts to drop tables and views"
        }, 
        {
            "location": "/dev/DB/Oracle/#delete-sequences", 
            "text": "BEGIN\n\n  --Bye Sequences!\n  FOR i IN (SELECT us.sequence_name\n              FROM USER_SEQUENCES us) LOOP\n    EXECUTE IMMEDIATE 'drop sequence '|| i.sequence_name ||'';\n  END LOOP;\n\n  --Bye Tables!\n  FOR i IN (SELECT ut.table_name\n              FROM USER_TABLES ut) LOOP\n    EXECUTE IMMEDIATE 'drop table '|| i.table_name ||' CASCADE CONSTRAINTS ';\n  END LOOP;\n\nEND;", 
            "title": "Delete sequences"
        }, 
        {
            "location": "/dev/DB/Oracle/#calculate-table-size", 
            "text": "source  -- Tables + Size MB\nselect owner, table_name, round((num_rows*avg_row_len)/(1024*1024)) MB \nfrom all_tables \nwhere owner not like 'SYS%'  -- Exclude system tables.\nand num_rows   0  -- Ignore empty Tables.\norder by MB desc -- Biggest first.;\n--Tables + Rows\nselect owner, table_name, num_rows\n from all_tables \nwhere owner not like 'SYS%'  -- Exclude system tables.\nand num_rows   0  -- Ignore empty Tables.\norder by num_rows desc -- Biggest first.;", 
            "title": "Calculate table size"
        }, 
        {
            "location": "/dev/DB/Postgres/", 
            "text": "List tables\n\n\nSELECT * FROM pg_catalog.pg_tables\nwhere tablename like '%patata%' ;\n\n\n\n\nSELECT * FROM pg_catalog.pg_tables\nwhere schema like '%some_model%' ;\n\n\n\n\nDescribe table\n\n\nselect column_name, data_type, character_maximum_length\nfrom INFORMATION_SCHEMA.COLUMNS where table_name = 'table_name_without_schema'\n\n\n\n\nCapitalize first letter of each word\n\n\nselect initcap(lower(deli.short_title)) \nfrom deli", 
            "title": "Postgres"
        }, 
        {
            "location": "/dev/DB/Postgres/#list-tables", 
            "text": "SELECT * FROM pg_catalog.pg_tables\nwhere tablename like '%patata%' ;  SELECT * FROM pg_catalog.pg_tables\nwhere schema like '%some_model%' ;", 
            "title": "List tables"
        }, 
        {
            "location": "/dev/DB/Postgres/#describe-table", 
            "text": "select column_name, data_type, character_maximum_length\nfrom INFORMATION_SCHEMA.COLUMNS where table_name = 'table_name_without_schema'", 
            "title": "Describe table"
        }, 
        {
            "location": "/dev/DB/Postgres/#capitalize-first-letter-of-each-word", 
            "text": "select initcap(lower(deli.short_title)) \nfrom deli", 
            "title": "Capitalize first letter of each word"
        }, 
        {
            "location": "/dev/DB/sqlite/", 
            "text": "Commands\n\n\nOpen/Create a Database, This is done using the command line program.\n\n\nsqlite3 {database file name}\nsqlite3 my_stuff_database.db\n\n\n\n\nIf the database exists it will be opened, if it doesn\u2019t exist, it will be created (sort of \u2013 you\u2019ll need to perform some sort of write operation first)\n\n\nPrint the database structure\n\n\n.schema\n\n\n\n\nPrint database structure and data\n\n\n.dump\n\n\n\n\nTurn on column names on query results\n\n\n.explain on\n\n\n\n\nTo turn it off do:\n\n\n.explain off\n\n\n\n\nThis will return the output to the default of pipe-separated values with no column header. Use the following command to see the current \u2018explain\u2019 status:\n\n\n.show\n\n\n\n\nCreating Tables\n\n\ncreate table {table name} ('{column name}' {data type} primary key, '{column name}' {data type});\nEg:\nCREATE TABLE my_things('id' int primary key, 'name' varchar(20), 'description' varchar(50));\n\n\n\n\nAdding a Column to a Table\n\n\nalter table {table name} ADD '{column name}' {data type};\nEg:\nalter table my_things ADD 'description' varchar(50);\n\n\n\n\nDeleting a table\n\n\ndrop table {table name};\n\nEg:\ndrop table my_things;\n\n\n\n\nInserting Data into a Table\n\n\n```insert into {table name} values ({data}, {more data}, '{yet more data}');\nEg:\ninsert into my_things values (1, 'My first thing', 'It is nice');\n\n\nTransactions\n\n\n\n\nbegin transaction;\n{put the relevant queries here}\ncommit;\n\n\nOutput query results to a file\n\n\n\n\n.output {filename.txt}\n\n\nAfter entering the above command, the results of subsequent queries will be written to the specified file\nChange the output back to being printed to the console by typing the following:\n\n\n\n\n.output stdout\n\n\n\n### Export/dump query results to file\n`sqlite3 -header -csv /path/to/sql/file.sqlite \nselect * from tracks;\n \n tracks.csv`\n\n### Dates\n#### From epoch to timestamp\n```sql\nSELECT datetime(b.recorded, 'unixepoch', 'localtime') from whatever", 
            "title": "Sqlite"
        }, 
        {
            "location": "/dev/DB/sqlite/#commands", 
            "text": "Open/Create a Database, This is done using the command line program.  sqlite3 {database file name}\nsqlite3 my_stuff_database.db  If the database exists it will be opened, if it doesn\u2019t exist, it will be created (sort of \u2013 you\u2019ll need to perform some sort of write operation first)  Print the database structure  .schema  Print database structure and data  .dump  Turn on column names on query results  .explain on  To turn it off do:  .explain off  This will return the output to the default of pipe-separated values with no column header. Use the following command to see the current \u2018explain\u2019 status:  .show", 
            "title": "Commands"
        }, 
        {
            "location": "/dev/DB/sqlite/#creating-tables", 
            "text": "create table {table name} ('{column name}' {data type} primary key, '{column name}' {data type});\nEg:\nCREATE TABLE my_things('id' int primary key, 'name' varchar(20), 'description' varchar(50));  Adding a Column to a Table  alter table {table name} ADD '{column name}' {data type};\nEg:\nalter table my_things ADD 'description' varchar(50);  Deleting a table  drop table {table name};\n\nEg:\ndrop table my_things;  Inserting Data into a Table  ```insert into {table name} values ({data}, {more data}, '{yet more data}');\nEg:\ninsert into my_things values (1, 'My first thing', 'It is nice');  Transactions  begin transaction;\n{put the relevant queries here}\ncommit;  Output query results to a file  .output {filename.txt}  After entering the above command, the results of subsequent queries will be written to the specified file\nChange the output back to being printed to the console by typing the following:  .output stdout  \n### Export/dump query results to file\n`sqlite3 -header -csv /path/to/sql/file.sqlite  select * from tracks;    tracks.csv`\n\n### Dates\n#### From epoch to timestamp\n```sql\nSELECT datetime(b.recorded, 'unixepoch', 'localtime') from whatever", 
            "title": "Creating Tables"
        }, 
        {
            "location": "/dev/Java/Java-snippets/", 
            "text": "Sleep\n\n\n//Pause for 4 seconds\nThread.sleep(4000);\n\n\n\n\nWrite file\n\n\npublic void writeFile() {\n    try(FileOutputStream fos = newFileOutputStream(\nmovies.txt\n);\n        DataOutputStream dos = newDataOutputStream(fos)) {\n\n        dos.writeUTF(\nJava 7 Block Buster\n);\n\n    } catch(IOException e) {\n\n        // log the exception\n\n    }\n}\n\n\n\n\n\nRead file\n\n\npublic static String readFirstLineFromFile(String path) throws IOException {\n    try (BufferedReader br =\n                   new BufferedReader(new FileReader(path))) {\n        return br.readLine();\n    }\n}\n\n\n\n\nRead file extension\n\n\nhttp://commons.apache.org/proper/commons-io/javadocs/api-2.5/org/apache/commons/io/FilenameUtils.html#getExtension\n\n\nString ext1 = FilenameUtils.getExtension(\n/path/to/file/foo.txt\n); // returns \ntxt\n\nString ext2 = FilenameUtils.getExtension(\nbar.exe\n); // returns \nexe\n\n\n\n\n\n// https://mvnrepository.com/artifact/commons-io/commons-io\ncompile group: 'commons-io', name: 'commons-io', version: '2.4'\n\n\n\n\nGet file last updated date\n\n\nimport java.io.File;\nimport java.text.SimpleDateFormat;\n\npublic class GetFileLastModifiedExample\n{\n    public static void main(String[] args)\n    {\n    File file = new File(\nc:\\\\logfile.log\n);\n\n    System.out.println(\nBefore Format : \n + file.lastModified());\n\n    SimpleDateFormat sdf = new SimpleDateFormat(\nMM/dd/yyyy HH:mm:ss\n);\n\n    System.out.println(\nAfter Format : \n + sdf.format(file.lastModified()));\n    }\n}", 
            "title": "Java snippets"
        }, 
        {
            "location": "/dev/Java/Java-snippets/#sleep", 
            "text": "//Pause for 4 seconds\nThread.sleep(4000);", 
            "title": "Sleep"
        }, 
        {
            "location": "/dev/Java/Java-snippets/#write-file", 
            "text": "public void writeFile() {\n    try(FileOutputStream fos = newFileOutputStream( movies.txt );\n        DataOutputStream dos = newDataOutputStream(fos)) {\n\n        dos.writeUTF( Java 7 Block Buster );\n\n    } catch(IOException e) {\n\n        // log the exception\n\n    }\n}", 
            "title": "Write file"
        }, 
        {
            "location": "/dev/Java/Java-snippets/#read-file", 
            "text": "public static String readFirstLineFromFile(String path) throws IOException {\n    try (BufferedReader br =\n                   new BufferedReader(new FileReader(path))) {\n        return br.readLine();\n    }\n}", 
            "title": "Read file"
        }, 
        {
            "location": "/dev/Java/Java-snippets/#read-file-extension", 
            "text": "http://commons.apache.org/proper/commons-io/javadocs/api-2.5/org/apache/commons/io/FilenameUtils.html#getExtension  String ext1 = FilenameUtils.getExtension( /path/to/file/foo.txt ); // returns  txt \nString ext2 = FilenameUtils.getExtension( bar.exe ); // returns  exe   // https://mvnrepository.com/artifact/commons-io/commons-io\ncompile group: 'commons-io', name: 'commons-io', version: '2.4'", 
            "title": "Read file extension"
        }, 
        {
            "location": "/dev/Java/Java-snippets/#get-file-last-updated-date", 
            "text": "import java.io.File;\nimport java.text.SimpleDateFormat;\n\npublic class GetFileLastModifiedExample\n{\n    public static void main(String[] args)\n    {\n    File file = new File( c:\\\\logfile.log );\n\n    System.out.println( Before Format :   + file.lastModified());\n\n    SimpleDateFormat sdf = new SimpleDateFormat( MM/dd/yyyy HH:mm:ss );\n\n    System.out.println( After Format :   + sdf.format(file.lastModified()));\n    }\n}", 
            "title": "Get file last updated date"
        }, 
        {
            "location": "/dev/Java/Java/", 
            "text": "Basic CLI\n\n\nCompile and run\n\n\njavac p.java; java p\n\n\nCreate jar from class\n\n\njar -cvfe TheJavaFile.jar \nMainClass\n TheJavaFile.class\n\n\nRun jar\n\n\njava -jar TheJavaFile.jar\n\n\nRun a class from Jar which is not the Main-Class in its Manifest file\n\n\njava -cp MyJar.jar com.mycomp.myproj.dir2.MainClass2 /home/myhome/datasource.properties /home/myhome/input.txt\n\n\nFind out what is loading some specific class\n\n\njava -verbose:class project-televisa-reports-db-extractor-spring-boot.jar | grep javax.servlet.ServletContext\n\n\n\n\nMore info \nhere\n\n\nJMX debug jconsole\n\n\nexecute \n\n\n$JAVA_HOME/bin/jconsole server:port\n## Example:\n$JAVA_HOME/bin/jconsole localhost:8048\n\n\n\n\nFreemarker\n\n\nOuptut integers without commas (separating the thousands)\n\n\nAdd \n?c\n to the number variable\n\n\nreport.total_households?c\n\n\n\n\nEclipse\n\n\nRemote debug\n\n\njava -jar -Xdebug -Xrunjdwp:transport=dt_socket,server=y,address=\n8765\n project.jar --server.port=7080 \n\n\n\n\n\n\nFrom Eclipse, Run -\n Debug configurations... -\n Remote Java Application\n\n\nIn \nConnection Type\n: \n\n\n\n\nStandard (Socket Attach)\nConnection Properties:\nHost: localhost\nPort: 8765\n\n\n\n\nMore info \nhere\n\n\nUseful libraries\n\n\ncom.google.common.base.Strings\n\n\nstatic String commonPrefix(CharSequence a, CharSequence b)\n\n\nstatic String commonSuffix(CharSequence a, CharSequence b)\n\n\nstatic String emptyToNull(String string)\n\n\nstatic boolean isNullOrEmpty(String string)\n\n\nstatic String nullToEmpty(String string)\n\n\nstatic String padEnd(String string, int minLength, char padChar)\n\n\nstatic String padStart(String string, int minLength, char padChar)\n\n\nstatic String repeat(String string, int count)", 
            "title": "Java"
        }, 
        {
            "location": "/dev/Java/Java/#basic-cli", 
            "text": "", 
            "title": "Basic CLI"
        }, 
        {
            "location": "/dev/Java/Java/#compile-and-run", 
            "text": "javac p.java; java p", 
            "title": "Compile and run"
        }, 
        {
            "location": "/dev/Java/Java/#create-jar-from-class", 
            "text": "jar -cvfe TheJavaFile.jar  MainClass  TheJavaFile.class", 
            "title": "Create jar from class"
        }, 
        {
            "location": "/dev/Java/Java/#run-jar", 
            "text": "java -jar TheJavaFile.jar", 
            "title": "Run jar"
        }, 
        {
            "location": "/dev/Java/Java/#run-a-class-from-jar-which-is-not-the-main-class-in-its-manifest-file", 
            "text": "java -cp MyJar.jar com.mycomp.myproj.dir2.MainClass2 /home/myhome/datasource.properties /home/myhome/input.txt", 
            "title": "Run a class from Jar which is not the Main-Class in its Manifest file"
        }, 
        {
            "location": "/dev/Java/Java/#find-out-what-is-loading-some-specific-class", 
            "text": "java -verbose:class project-televisa-reports-db-extractor-spring-boot.jar | grep javax.servlet.ServletContext  More info  here", 
            "title": "Find out what is loading some specific class"
        }, 
        {
            "location": "/dev/Java/Java/#jmx-debug-jconsole", 
            "text": "execute   $JAVA_HOME/bin/jconsole server:port\n## Example:\n$JAVA_HOME/bin/jconsole localhost:8048", 
            "title": "JMX debug jconsole"
        }, 
        {
            "location": "/dev/Java/Java/#freemarker", 
            "text": "", 
            "title": "Freemarker"
        }, 
        {
            "location": "/dev/Java/Java/#ouptut-integers-without-commas-separating-the-thousands", 
            "text": "Add  ?c  to the number variable  report.total_households?c", 
            "title": "Ouptut integers without commas (separating the thousands)"
        }, 
        {
            "location": "/dev/Java/Java/#eclipse", 
            "text": "", 
            "title": "Eclipse"
        }, 
        {
            "location": "/dev/Java/Java/#remote-debug", 
            "text": "java -jar -Xdebug -Xrunjdwp:transport=dt_socket,server=y,address= 8765  project.jar --server.port=7080    From Eclipse, Run -  Debug configurations... -  Remote Java Application  In  Connection Type :    Standard (Socket Attach)\nConnection Properties:\nHost: localhost\nPort: 8765  More info  here", 
            "title": "Remote debug"
        }, 
        {
            "location": "/dev/Java/Java/#useful-libraries", 
            "text": "com.google.common.base.Strings  static String commonPrefix(CharSequence a, CharSequence b)  static String commonSuffix(CharSequence a, CharSequence b)  static String emptyToNull(String string)  static boolean isNullOrEmpty(String string)  static String nullToEmpty(String string)  static String padEnd(String string, int minLength, char padChar)  static String padStart(String string, int minLength, char padChar)  static String repeat(String string, int count)", 
            "title": "Useful libraries"
        }, 
        {
            "location": "/dev/Misc/Geekeries/", 
            "text": "[Draw Ascii art online interactive] (http://asciiflow.com/)", 
            "title": "Geekeries"
        }, 
        {
            "location": "/dev/Misc/Markdown/", 
            "text": "Comments that only appear in the markdown document\n\n\n\n\nFrom \nhere\n\n\nIt may be prudent to insert a blank line before and after this type of comments, because some Markdown parsers may not like link definitions brushing up against regular text.\n\n\n\n\n[comment]: \n (This is a comment, it will not be included)\n\n\n\n\nor\n\n\n[//]: \n (This is also a comment.)\n\n\n\n\nor\n\n\n[//]: # (This may be the most platform independent comment)", 
            "title": "Markdown"
        }, 
        {
            "location": "/dev/Misc/Markdown/#comments-that-only-appear-in-the-markdown-document", 
            "text": "From  here  It may be prudent to insert a blank line before and after this type of comments, because some Markdown parsers may not like link definitions brushing up against regular text.   [comment]:   (This is a comment, it will not be included)  or  [//]:   (This is also a comment.)  or  [//]: # (This may be the most platform independent comment)", 
            "title": "Comments that only appear in the markdown document"
        }, 
        {
            "location": "/dev/VCS/Mercurial/", 
            "text": "Show changeset information by line for each file\n\n\nhg annotate -u\n\n\nForget tracked file\n\n\nIf file to forget is contained in .hgignore,\n\n\n$ hg forget _filename_\n\n\nServe repo\n\n\n$ hg serve", 
            "title": "Mercurial"
        }, 
        {
            "location": "/dev/VCS/Mercurial/#show-changeset-information-by-line-for-each-file", 
            "text": "hg annotate -u", 
            "title": "Show changeset information by line for each file"
        }, 
        {
            "location": "/dev/VCS/Mercurial/#forget-tracked-file", 
            "text": "If file to forget is contained in .hgignore,  $ hg forget _filename_", 
            "title": "Forget tracked file"
        }, 
        {
            "location": "/dev/VCS/Mercurial/#serve-repo", 
            "text": "$ hg serve", 
            "title": "Serve repo"
        }, 
        {
            "location": "/dev/VCS/Git/Git-problems/", 
            "text": "not something we can merge\n\n\ngit checkout branch-name\ngit checkout master\ngit merge branch-name\n\n\n\n\ngit is pushing with an unexpected user/email\n\n\nAccording to the github \ndocs\n, GitHub uses the email address set in your local Git configuration to associate commits pushed from the command line with your GitHub account.\n* Check values from\n\n\ngit config -l\n\n\n\n\n\n\nCheck\n\n\n\n\ngit config --global -l\n\n\n\n\n\n\nCheck\nCheck host from\n\n\n\n\nvim ~/.ssh/config\n\n\n\n\nand compare it with the one in the repo push/fetch url at\n\n\n.git/config", 
            "title": "Git problems"
        }, 
        {
            "location": "/dev/VCS/Git/Git-problems/#not-something-we-can-merge", 
            "text": "git checkout branch-name\ngit checkout master\ngit merge branch-name", 
            "title": "not something we can merge"
        }, 
        {
            "location": "/dev/VCS/Git/Git-problems/#git-is-pushing-with-an-unexpected-useremail", 
            "text": "According to the github  docs , GitHub uses the email address set in your local Git configuration to associate commits pushed from the command line with your GitHub account.\n* Check values from  git config -l   Check   git config --global -l   Check\nCheck host from   vim ~/.ssh/config  and compare it with the one in the repo push/fetch url at  .git/config", 
            "title": "git is pushing with an unexpected user/email"
        }, 
        {
            "location": "/dev/VCS/Git/Github/", 
            "text": "Get single file from github repo\n\n\nurl=https://github.com/prometheus/alertmanager/blob/master/README.md\nrawUrl=`echo \n$1\n | sed \ns/github/raw.githubusercontent/g\n | sed \ns/blob\\///\n`; wget $rawUrl; \nwget $rawUrl\n\n\n\n\nCloning and forking\n\n\nUpdating a forked repo from github\n\n\nhttp://stackoverflow.com/questions/7244321/how-do-i-update-a-github-forked-repository\n\n\nbase: mine \nhead fork: original\n\n\n\n\nChange repo remote url from http to ssh\n\n\nchange url in .git/config from:\n\n\nhttps://github.com/USERNAME/OTHERREPOSITORY.git\n\n\n\n\nto\n\n\ngit@github.com:USERNAME/OTHERREPOSITORY.git\n\n\n\n\nHaving already cloned the repo, but not forked it\n\n\n\n\nIdeally, create the repo with: https://developer.github.com/v3/repos/#create\n\n\nIf not, create it via forking the repo.\n\n\nIn this example, it will be https://github.com/JAremko/alpine-vim\n\n\nForking it will result in https://github.com/octosh/alpine-vim\n\n\nIn your local, add a new remote to your fork; then fetch it, and push your changes up to it\n\n\n\n\n    git remote add my-fork https://github.com/octosh/alpine-vim\n    git fetch my-fork\n    git push my-fork master\n\n\n\n\nTraditionally\n\n\nOtherwise, if you want to follow convention:\n\n\n\n\nFork their repo on Github\n\n\n\n\nIn your local, rename your origin remote to upstream\n\n\ngit remote rename origin upstream\n\n\n\n\n\n\nAdd a new origin\n\n\ngit remote add origin git@github...my-fork\n\n\n\n\n\n\nFetch \n push\n\n\ngit fetch origin\ngit push origin", 
            "title": "Github"
        }, 
        {
            "location": "/dev/VCS/Git/Github/#get-single-file-from-github-repo", 
            "text": "url=https://github.com/prometheus/alertmanager/blob/master/README.md\nrawUrl=`echo  $1  | sed  s/github/raw.githubusercontent/g  | sed  s/blob\\/// `; wget $rawUrl; \nwget $rawUrl", 
            "title": "Get single file from github repo"
        }, 
        {
            "location": "/dev/VCS/Git/Github/#cloning-and-forking", 
            "text": "", 
            "title": "Cloning and forking"
        }, 
        {
            "location": "/dev/VCS/Git/Github/#updating-a-forked-repo-from-github", 
            "text": "http://stackoverflow.com/questions/7244321/how-do-i-update-a-github-forked-repository  base: mine \nhead fork: original", 
            "title": "Updating a forked repo from github"
        }, 
        {
            "location": "/dev/VCS/Git/Github/#change-repo-remote-url-from-http-to-ssh", 
            "text": "change url in .git/config from:  https://github.com/USERNAME/OTHERREPOSITORY.git  to  git@github.com:USERNAME/OTHERREPOSITORY.git", 
            "title": "Change repo remote url from http to ssh"
        }, 
        {
            "location": "/dev/VCS/Git/Github/#having-already-cloned-the-repo-but-not-forked-it", 
            "text": "Ideally, create the repo with: https://developer.github.com/v3/repos/#create  If not, create it via forking the repo.  In this example, it will be https://github.com/JAremko/alpine-vim  Forking it will result in https://github.com/octosh/alpine-vim  In your local, add a new remote to your fork; then fetch it, and push your changes up to it       git remote add my-fork https://github.com/octosh/alpine-vim\n    git fetch my-fork\n    git push my-fork master", 
            "title": "Having already cloned the repo, but not forked it"
        }, 
        {
            "location": "/dev/VCS/Git/Github/#traditionally", 
            "text": "Otherwise, if you want to follow convention:   Fork their repo on Github   In your local, rename your origin remote to upstream  git remote rename origin upstream    Add a new origin  git remote add origin git@github...my-fork    Fetch   push  git fetch origin\ngit push origin", 
            "title": "Traditionally"
        }, 
        {
            "location": "/dev/VCS/Git/Main/", 
            "text": "Checkout specific commit in new branch, without messing things up too much\n\n\ngit checkout -b test-branch 56a4e5c08\n\n\n\n\nPush to ssh repo with different user (or github account)\n\n\nSources: \nthis\n and \nthis\n\n\ncreate-a-new-ssh-key\n\n\nSee \nthis\n\n\nAttach key\n\n\nLogin to your git repo service and paste the contents of your new pub key\n\n\nAdd ssh host alias\n\n\nEdit ~/.ssh/config file to add something like the following\n\n\n#Default GitHub\nHost github.com\n  HostName github.com\n  User git\n  IdentityFile ~/.ssh/id_rsa\n\n### Edit this for a different account!\nHost github-COMPANY\n  HostName github.com\n  User git\n  IdentityFile ~/.ssh/id_rsa_COMPANY\n\n\n\n\nConfigure repo to work with new host\n\n\nReplace \ngithub-COMPANY\n, \nUSERNAME\n and \nREPONAME\n with your own values\n\n\ngit remote add origin git@github-COMPANY:USERNAME/REPO_NAME.git\ngit config  github.user USERNAME\ngit push origin master\n\n\n\n\nChange repo from http(s) to git/ssh\n\n\nChange config url from \nhttps://github.com/USERNAME/REPO_NAME.git\n to \ngit@github.com/USERNAME:REPO_NAME.git\n\n\nInteractively add, skip, or split diff hunks\n\n\n$ git add -p\n\n\n\n\nShow diff of one specific commit\n\n\ngit show commit-hash-stuff\n\n\n\n\nSquash unpushed commits into one\n\n\nScenario: The last two commits are unpushed, and you want to merge them into one.\n\ngit rebase -i HEAD~2\n\nThis will open the default editor\n\n\npick hash1 Bla bla bla Commit message\npick hash2 Bla bla bla another Commit message\n\n\n\n\nLeave the first one as it is and put the second one as squash\n\n\npick hash1 Bla bla bla Commit message\nsquash hash2 Bla bla bla another Commit message\n\n\n\n\nAgain, the editor will open, to let you edit the final commit message.\nSources: \nthis\n.\n\n\nStash\n\n\nUseful\n examples \nhere\n\n\nStash the changes in a dirty working directory away\n\n\n$ git stash\n\n\n\n\nList modifications stashes\n\n\n$ git stash list\nstash@{0}: WIP on alerting: 697194d WIP\n\n\n\n\nRestore modifications\n\n\n$ git stash apply stash@{0}\n\n\n\n\nClear stash list\n\n\ngit stash clear\n\n\n\n\nDiscard changes\n\n\nDANGEROUS\n\n\n Checks out the current index for the current directory.\n\n Undo unstaged changes in tracked files. It apparently doesn't touch staged changes and leaves untracked files alone.\n\n\ngit checkout .\n\n\n\n\nGit revert changes for file\n\n\ngit checkout -- filename\n\n\n\n\nUnstage commit\n\n\ngit reset filepath\n\n\nUndo commits\n\n\nPermanently\n\n\n Reset your head to HEAD\n\ngit reset --hard\n\n\n Reset your head to wherever you want to be\n\ngit reset --hard \nthe sha1 hash\n\n\nNot permanent\n\n\ngit reset HEAD~1\n\n\nSee branch status\n\n\nSee what branch you're on and if it's synchronized or not\n\n\ngit branch -v --color\n\n\n\n\nCheck commmits ahead of current branch\n\n\ngit cherry -v\n\n\n\n\nothers\n\n\ngit log --graph --decorate --pretty=oneline --abbrev-commit --all @{upstream}^..\n\n\n\n\nExport commits as patches\n\n\nExport last n patches\n\n\n$ git format-patch -4\n0001-some-commit.patch\n0002-some-other-commit.patch\n0003-again-committing.patch\n0004-first-commit.patch\n\n\n\n\nExport last n commits as a single patch\n\n\nJust add the --stdout option\n\n\n$ git format-patch -4 --stdout \n `date +\n%Y%m%d%H%M\n`.patch\n\n\n\n\nView changes made to a file with source\n\n\n$ git log -p path/to/file\n\n\nMaking git \"forget\" about a file that was tracked but is now in .gitignore\n\n\ngitignore\n will prevent untracked files from being added (without an add -f) to the set of files tracked by git, however git will continue to track any files that are already being tracked.\nTo stop tracking a file you need to remove it from the index. This can be achieved with this command.\n\n\n$ git rm --cached \nfile\n\n\nThe removal of the file from the head revision will happen on the next commit.\nMaking git \"forget\" about a file that was tracked but is now in \n.gitignore\n\n\nGit revert changes for file\n\n\ngit checkout -- filename\n\n\n\n\nUnstage commit\n\n\ngit reset filepath\n\n\nUndo commits\n\n\nPermanently\n\n\ngit reset --hard\n\n\nNot permanent\n\n\ngit reset HEAD~1\n\n\nRearrange commits\n\n\n\nI've used another way for a few times. In fact, it is a manual git rebase -i and it is useful when you want to rearrange several commits including squashing or splitting some of them. The main advantage is that you don't have to decide about every commit's destiny at a single moment. You'll also have all Git features available during the process unlike during a rebase. For example, you can display the log of both original and rewritten history at any time, or even do another rebase!\n\nI'll refer to the commits in the following way, so it's readable easily:\n\nC # good commit after a bad one\nB # bad commit\nA # good commit before a bad one\nYour history in the beginning looks like this:\n\nx - A - B - C\n|           |\n|           master\n|\norigin/master\nWe'll recreate it to this way:\n\nx - A - B*- C'\n|           |\n|           master\n|\norigin/master\nThis is the procedure:\n\ngit checkout B       # get working-tree to the state of commit B\ngit reset --soft A   # tell git that we are working before commit B\ngit checkout -b rewrite-history   # switch to a new branch for our alternative history\nImprove your old commit using git add (git add -i, git stash etc.) now. You can even split your old commit into two or more.\n\ngit commit           # recreate commit B (result = B*)\ngit cherry-pick C    # copy C to our new branch (result = C')\nIntermediate result:\n\nx - A - B - C\n|    \\      |\n|     \\     master\n|      \\\n|       B*- C'\n|           |\n|           rewrite-history\n|\norigin/master\nLet's finish:\n\ngit checkout master\ngit reset --hard rewrite-history  # make this branch master\nThat's it, you can push your progress now.\n\n\n\n\nRewrite history", 
            "title": "Main"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#checkout-specific-commit-in-new-branch-without-messing-things-up-too-much", 
            "text": "git checkout -b test-branch 56a4e5c08", 
            "title": "Checkout specific commit in new branch, without messing things up too much"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#push-to-ssh-repo-with-different-user-or-github-account", 
            "text": "Sources:  this  and  this", 
            "title": "Push to ssh repo with different user (or github account)"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#create-a-new-ssh-key", 
            "text": "See  this", 
            "title": "create-a-new-ssh-key"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#attach-key", 
            "text": "Login to your git repo service and paste the contents of your new pub key", 
            "title": "Attach key"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#add-ssh-host-alias", 
            "text": "Edit ~/.ssh/config file to add something like the following  #Default GitHub\nHost github.com\n  HostName github.com\n  User git\n  IdentityFile ~/.ssh/id_rsa\n\n### Edit this for a different account!\nHost github-COMPANY\n  HostName github.com\n  User git\n  IdentityFile ~/.ssh/id_rsa_COMPANY", 
            "title": "Add ssh host alias"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#configure-repo-to-work-with-new-host", 
            "text": "Replace  github-COMPANY ,  USERNAME  and  REPONAME  with your own values  git remote add origin git@github-COMPANY:USERNAME/REPO_NAME.git\ngit config  github.user USERNAME\ngit push origin master", 
            "title": "Configure repo to work with new host"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#change-repo-from-https-to-gitssh", 
            "text": "Change config url from  https://github.com/USERNAME/REPO_NAME.git  to  git@github.com/USERNAME:REPO_NAME.git", 
            "title": "Change repo from http(s) to git/ssh"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#interactively-add-skip-or-split-diff-hunks", 
            "text": "$ git add -p", 
            "title": "Interactively add, skip, or split diff hunks"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#show-diff-of-one-specific-commit", 
            "text": "git show commit-hash-stuff", 
            "title": "Show diff of one specific commit"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#squash-unpushed-commits-into-one", 
            "text": "Scenario: The last two commits are unpushed, and you want to merge them into one. git rebase -i HEAD~2 \nThis will open the default editor  pick hash1 Bla bla bla Commit message\npick hash2 Bla bla bla another Commit message  Leave the first one as it is and put the second one as squash  pick hash1 Bla bla bla Commit message\nsquash hash2 Bla bla bla another Commit message  Again, the editor will open, to let you edit the final commit message.\nSources:  this .", 
            "title": "Squash unpushed commits into one"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#stash", 
            "text": "Useful  examples  here", 
            "title": "Stash"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#stash-the-changes-in-a-dirty-working-directory-away", 
            "text": "$ git stash", 
            "title": "Stash the changes in a dirty working directory away"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#list-modifications-stashes", 
            "text": "$ git stash list\nstash@{0}: WIP on alerting: 697194d WIP", 
            "title": "List modifications stashes"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#restore-modifications", 
            "text": "$ git stash apply stash@{0}", 
            "title": "Restore modifications"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#clear-stash-list", 
            "text": "git stash clear", 
            "title": "Clear stash list"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#discard-changes", 
            "text": "DANGEROUS   Checks out the current index for the current directory.  Undo unstaged changes in tracked files. It apparently doesn't touch staged changes and leaves untracked files alone.  git checkout .", 
            "title": "Discard changes"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#git-revert-changes-for-file", 
            "text": "git checkout -- filename", 
            "title": "Git revert changes for file"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#unstage-commit", 
            "text": "git reset filepath", 
            "title": "Unstage commit"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#undo-commits", 
            "text": "Permanently   Reset your head to HEAD git reset --hard   Reset your head to wherever you want to be git reset --hard  the sha1 hash  Not permanent  git reset HEAD~1", 
            "title": "Undo commits"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#see-branch-status", 
            "text": "", 
            "title": "See branch status"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#see-what-branch-youre-on-and-if-its-synchronized-or-not", 
            "text": "git branch -v --color", 
            "title": "See what branch you're on and if it's synchronized or not"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#check-commmits-ahead-of-current-branch", 
            "text": "git cherry -v", 
            "title": "Check commmits ahead of current branch"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#others", 
            "text": "git log --graph --decorate --pretty=oneline --abbrev-commit --all @{upstream}^..", 
            "title": "others"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#export-commits-as-patches", 
            "text": "", 
            "title": "Export commits as patches"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#export-last-n-patches", 
            "text": "$ git format-patch -4\n0001-some-commit.patch\n0002-some-other-commit.patch\n0003-again-committing.patch\n0004-first-commit.patch", 
            "title": "Export last n patches"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#export-last-n-commits-as-a-single-patch", 
            "text": "Just add the --stdout option  $ git format-patch -4 --stdout   `date + %Y%m%d%H%M `.patch", 
            "title": "Export last n commits as a single patch"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#view-changes-made-to-a-file-with-source", 
            "text": "$ git log -p path/to/file", 
            "title": "View changes made to a file with source"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#making-git-forget-about-a-file-that-was-tracked-but-is-now-in-gitignore", 
            "text": "gitignore  will prevent untracked files from being added (without an add -f) to the set of files tracked by git, however git will continue to track any files that are already being tracked.\nTo stop tracking a file you need to remove it from the index. This can be achieved with this command.  $ git rm --cached  file  The removal of the file from the head revision will happen on the next commit.\nMaking git \"forget\" about a file that was tracked but is now in  .gitignore", 
            "title": "Making git \"forget\" about a file that was tracked but is now in .gitignore"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#git-revert-changes-for-file_1", 
            "text": "git checkout -- filename", 
            "title": "Git revert changes for file"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#unstage-commit_1", 
            "text": "git reset filepath", 
            "title": "Unstage commit"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#undo-commits_1", 
            "text": "Permanently  git reset --hard  Not permanent  git reset HEAD~1", 
            "title": "Undo commits"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#rearrange-commits", 
            "text": "I've used another way for a few times. In fact, it is a manual git rebase -i and it is useful when you want to rearrange several commits including squashing or splitting some of them. The main advantage is that you don't have to decide about every commit's destiny at a single moment. You'll also have all Git features available during the process unlike during a rebase. For example, you can display the log of both original and rewritten history at any time, or even do another rebase!\n\nI'll refer to the commits in the following way, so it's readable easily:\n\nC # good commit after a bad one\nB # bad commit\nA # good commit before a bad one\nYour history in the beginning looks like this:\n\nx - A - B - C\n|           |\n|           master\n|\norigin/master\nWe'll recreate it to this way:\n\nx - A - B*- C'\n|           |\n|           master\n|\norigin/master\nThis is the procedure:\n\ngit checkout B       # get working-tree to the state of commit B\ngit reset --soft A   # tell git that we are working before commit B\ngit checkout -b rewrite-history   # switch to a new branch for our alternative history\nImprove your old commit using git add (git add -i, git stash etc.) now. You can even split your old commit into two or more.\n\ngit commit           # recreate commit B (result = B*)\ngit cherry-pick C    # copy C to our new branch (result = C')\nIntermediate result:\n\nx - A - B - C\n|    \\      |\n|     \\     master\n|      \\\n|       B*- C'\n|           |\n|           rewrite-history\n|\norigin/master\nLet's finish:\n\ngit checkout master\ngit reset --hard rewrite-history  # make this branch master\nThat's it, you can push your progress now.", 
            "title": "Rearrange commits"
        }, 
        {
            "location": "/dev/VCS/Git/Main/#rewrite-history", 
            "text": "", 
            "title": "Rewrite history"
        }, 
        {
            "location": "/python/File-management/", 
            "text": "Hidden file/folder (linux-osx)\n\n\ndef folder_is_not_hidden(p):\n    is_hidden =  p.startswith('.') #linux-osx\n    return not is_hidden\n\n\n\n\nCheck if file is folder\n\n\nos.path.isdir\n\n\n\n\nGet current working directory\n\n\nprevious_folder = os.getcwd()\n\n\n\n\nChange to folder\n\n\nos.chdir(\nsome/relative/or/absolute/path\n)", 
            "title": "File management"
        }, 
        {
            "location": "/python/File-management/#hidden-filefolder-linux-osx", 
            "text": "def folder_is_not_hidden(p):\n    is_hidden =  p.startswith('.') #linux-osx\n    return not is_hidden", 
            "title": "Hidden file/folder (linux-osx)"
        }, 
        {
            "location": "/python/File-management/#check-if-file-is-folder", 
            "text": "os.path.isdir", 
            "title": "Check if file is folder"
        }, 
        {
            "location": "/python/File-management/#get-current-working-directory", 
            "text": "previous_folder = os.getcwd()", 
            "title": "Get current working directory"
        }, 
        {
            "location": "/python/File-management/#change-to-folder", 
            "text": "os.chdir( some/relative/or/absolute/path )", 
            "title": "Change to folder"
        }, 
        {
            "location": "/python/HTTP-Verbs-and-curl-like-stuff/", 
            "text": "Posting to endpoint\n\n\nWith requests\n\n\nExample\n\n\nimport requests\nimport json\n\ngist_token = os.getenv(\nGITHUB_GIST_TOKEN\n)\ngithub_root_api = \nhttps://api.github.com\n\ngist_post_endpoint = \n/gists\n\ngist_post_url = github_root_api + gist_post_endpoint\n\n# Format headers with token\nheaders = {'Authorization': 'token {}'.format(gist_token)}\n# Create data dict, according to https://developer.github.com/v3/gists/#create-a-gist\ngist_dict = {\ndescription\n: \nPosted with python requests\n, \npublic\n: False, \nfiles\n: {\nsome_file_name.txt\n: {\ncontent\n: \nprint 'hello world'\n}}}\n# Put the dict data into json\njson_data = json.dumps(gist_dict)\n# Post data with a request, include token header\nresponse = requests.post(gist_post_url, headers=headers, data=json_data)\n\n# Not needed, check the results\nresponse_json = json.loads(response.content)\n\n\n\n\nWith urllib, urllib2\n\n\nimport os\nimport urllib\nimport urllib2\nimport json\n\ngist_token = os.getenv(\nGITHUB_GIST_TOKEN\n)\naccess_url = \nhttps://api.github.com/gists\n\n\nheaders = {'Authorization': 'token {}'.format(gist_token)}\n\ndata = {\ndescription\n: \nsome gist\n, \npublic\n: False, \nfiles\n: {\nsome_file_name.txt\n: {\ncontent\n: \nprint 'hello world'\n}}}\n\njson_data = json.dumps(data)\nreq = urllib2.Request(access_url, json_data, headers)\nresponse = urllib2.urlopen(req)\nthe_page = response.read()", 
            "title": "HTTP Verbs and curl like stuff"
        }, 
        {
            "location": "/python/HTTP-Verbs-and-curl-like-stuff/#posting-to-endpoint", 
            "text": "", 
            "title": "Posting to endpoint"
        }, 
        {
            "location": "/python/HTTP-Verbs-and-curl-like-stuff/#with-requests", 
            "text": "Example  import requests\nimport json\n\ngist_token = os.getenv( GITHUB_GIST_TOKEN )\ngithub_root_api =  https://api.github.com \ngist_post_endpoint =  /gists \ngist_post_url = github_root_api + gist_post_endpoint\n\n# Format headers with token\nheaders = {'Authorization': 'token {}'.format(gist_token)}\n# Create data dict, according to https://developer.github.com/v3/gists/#create-a-gist\ngist_dict = { description :  Posted with python requests ,  public : False,  files : { some_file_name.txt : { content :  print 'hello world' }}}\n# Put the dict data into json\njson_data = json.dumps(gist_dict)\n# Post data with a request, include token header\nresponse = requests.post(gist_post_url, headers=headers, data=json_data)\n\n# Not needed, check the results\nresponse_json = json.loads(response.content)", 
            "title": "With requests"
        }, 
        {
            "location": "/python/HTTP-Verbs-and-curl-like-stuff/#with-urllib-urllib2", 
            "text": "import os\nimport urllib\nimport urllib2\nimport json\n\ngist_token = os.getenv( GITHUB_GIST_TOKEN )\naccess_url =  https://api.github.com/gists \n\nheaders = {'Authorization': 'token {}'.format(gist_token)}\n\ndata = { description :  some gist ,  public : False,  files : { some_file_name.txt : { content :  print 'hello world' }}}\n\njson_data = json.dumps(data)\nreq = urllib2.Request(access_url, json_data, headers)\nresponse = urllib2.urlopen(req)\nthe_page = response.read()", 
            "title": "With urllib, urllib2"
        }, 
        {
            "location": "/python/Misc/", 
            "text": "Dissassemble pytho code", 
            "title": "Misc"
        }, 
        {
            "location": "/python/Python--Snippets/", 
            "text": "Basics\n\n\nInput/Output\n\n\nFile management\n\n\nHTTP verbs/curl-like stuff\n\n\nGenerators\n\n\nEmail function\n or \nemail CLI\n\n\nCLI option parser\n\n\nDate arithmetic\n\n\nMisc\n\n\ncsv to json\n\n\n\n\nCreate matrix\n\n\nCreate matrix of None\n\n\nA = [[ None for _ in xrange(M)] for _ in xrange(N)]\n\n\n\n\nCreate matrix of random numbers\n\n\nimport random\nA = [[ random.random() for _ in xrange(M)] for _ in xrange(N)]\n\n\n\n\nGenerator for lists of M random elements\n\n\nimport random\nA = ([ random.random() for _ in xrange(M)] for _ in iter(int, 1))\nfor i in A:\n    print i\n    sleep(0.2)\n\n\n\n\nFlatten list of lists (only one level of nesting)\n\n\nimport itertools\nlist2d = [[1,2,3],[4,5,6], [7], [8,9]]\nlist(itertools.chain.from_iterable(list2d))\n\n [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\n\nFlatten json\n\n\ndef flattenjson( b, delim ):\n    val = {}\n    for i in b.keys():\n        if isinstance( b[i], dict ):\n            get = flattenjson( b[i], delim )\n            for j in get.keys():\n                val[ i + delim + j ] = get[j]\n        else:\n            val[i] = b[i]\n\n    return val\n\n\n\n\nStrip punctuation of string\n\n\ns.translate(None, string.punctuation)", 
            "title": "Python  Snippets"
        }, 
        {
            "location": "/python/Python--Snippets/#create-matrix", 
            "text": "", 
            "title": "Create matrix"
        }, 
        {
            "location": "/python/Python--Snippets/#create-matrix-of-none", 
            "text": "A = [[ None for _ in xrange(M)] for _ in xrange(N)]", 
            "title": "Create matrix of None"
        }, 
        {
            "location": "/python/Python--Snippets/#create-matrix-of-random-numbers", 
            "text": "import random\nA = [[ random.random() for _ in xrange(M)] for _ in xrange(N)]", 
            "title": "Create matrix of random numbers"
        }, 
        {
            "location": "/python/Python--Snippets/#generator-for-lists-of-m-random-elements", 
            "text": "import random\nA = ([ random.random() for _ in xrange(M)] for _ in iter(int, 1))\nfor i in A:\n    print i\n    sleep(0.2)", 
            "title": "Generator for lists of M random elements"
        }, 
        {
            "location": "/python/Python--Snippets/#flatten-list-of-lists-only-one-level-of-nesting", 
            "text": "import itertools\nlist2d = [[1,2,3],[4,5,6], [7], [8,9]]\nlist(itertools.chain.from_iterable(list2d))  [1, 2, 3, 4, 5, 6, 7, 8, 9]", 
            "title": "Flatten list of lists (only one level of nesting)"
        }, 
        {
            "location": "/python/Python--Snippets/#flatten-json", 
            "text": "def flattenjson( b, delim ):\n    val = {}\n    for i in b.keys():\n        if isinstance( b[i], dict ):\n            get = flattenjson( b[i], delim )\n            for j in get.keys():\n                val[ i + delim + j ] = get[j]\n        else:\n            val[i] = b[i]\n\n    return val", 
            "title": "Flatten json"
        }, 
        {
            "location": "/python/Python--Snippets/#strip-punctuation-of-string", 
            "text": "s.translate(None, string.punctuation)", 
            "title": "Strip punctuation of string"
        }, 
        {
            "location": "/python/Python-basics/", 
            "text": "Currying functions\n\n\nFunction that returns a function\n\n\nWith lambdas\n\n\nimport math\ndef make_cylinder_volume_fun(r):\n    return lambda h: math.pi * r * r * h\n\n\n\n\nWithout lambdas\n\n\nimport math\ndef make_cylinder_volume_func(r):\n    def volume(h):\n        return math.pi * r * r * h\n    return volume", 
            "title": "Python basics"
        }, 
        {
            "location": "/python/Python-basics/#currying-functions", 
            "text": "Function that returns a function", 
            "title": "Currying functions"
        }, 
        {
            "location": "/python/Python-basics/#with-lambdas", 
            "text": "import math\ndef make_cylinder_volume_fun(r):\n    return lambda h: math.pi * r * r * h", 
            "title": "With lambdas"
        }, 
        {
            "location": "/python/Python-basics/#without-lambdas", 
            "text": "import math\ndef make_cylinder_volume_func(r):\n    def volume(h):\n        return math.pi * r * r * h\n    return volume", 
            "title": "Without lambdas"
        }, 
        {
            "location": "/python/Python-input-output/", 
            "text": "Read/write file\n\n\nimport sys\n\n# Read\nwith open('../first.js', 'r') as reading_file:\n    remove_newlines = lambda x: x.replace('\\n', '')\n    lines = list(reading_file)\n    formatted_lines = [remove_newlines(line) for line in lines]\n\n# Write\nwith open('output_file', 'w') as output_file:\n    for line in lines:\n        output_file.write(line)\n\n\n\n\nor\n\n\nwith open('output_file', 'w') as output_file:\n    output_file.writelines(lines)\n\n\n\n\nStandard input/output read and write\n\n\n#### Write to stdout\nimport sys\nsys.stdout.write(str(last_answer ))\n\n\n\n\nor\n\n\nimport sys\nwith sys.stdout as stdout:\n    sdout.write(str(last_answer))\n\n\n\n\nRead from stdin\n\n\nimport sys\nwith sys.stdin as stdin:\n    remove_newlines = lambda x: x.replace('\\n', '')\n    lines = [remove_newlines(line) for line in stdin]\n\n\n\n\nor\n\n\nlines = sys.stdin.readlines()\n\n\n\n\nRemove trailing and beginning newlines from string\n\n\nremove_newlines = lambda x: x.trim('\\r\\n')\n\n\n\n\nGzip\n\n\nread compressed file\n\n\nimport gzip\nwith gzip.open('file.txt.gz', 'rb') as f:\n    file_content = f.read()\n\n\n\n\ncompress file\n\n\nimport gzip\ncontent = \nLots of content here\n\nwith gzip.open('file.txt.gz', 'wb') as f:\n    f.write(content)\n\n\n\n\nMisc\n\n\nBlink led of caps key\n\n\nimport fcntl,os,time;\nexec \nfcntl.ioctl(os.open('/dev/console',os.O_NOCTTY),19250,%d);time.sleep(.5);\n*2%(4,0)", 
            "title": "Python input output"
        }, 
        {
            "location": "/python/Python-input-output/#readwrite-file", 
            "text": "import sys\n\n# Read\nwith open('../first.js', 'r') as reading_file:\n    remove_newlines = lambda x: x.replace('\\n', '')\n    lines = list(reading_file)\n    formatted_lines = [remove_newlines(line) for line in lines]\n\n# Write\nwith open('output_file', 'w') as output_file:\n    for line in lines:\n        output_file.write(line)  or  with open('output_file', 'w') as output_file:\n    output_file.writelines(lines)", 
            "title": "Read/write file"
        }, 
        {
            "location": "/python/Python-input-output/#standard-inputoutput-read-and-write", 
            "text": "#### Write to stdout\nimport sys\nsys.stdout.write(str(last_answer ))  or  import sys\nwith sys.stdout as stdout:\n    sdout.write(str(last_answer))", 
            "title": "Standard input/output read and write"
        }, 
        {
            "location": "/python/Python-input-output/#read-from-stdin", 
            "text": "import sys\nwith sys.stdin as stdin:\n    remove_newlines = lambda x: x.replace('\\n', '')\n    lines = [remove_newlines(line) for line in stdin]  or  lines = sys.stdin.readlines()", 
            "title": "Read from stdin"
        }, 
        {
            "location": "/python/Python-input-output/#remove-trailing-and-beginning-newlines-from-string", 
            "text": "remove_newlines = lambda x: x.trim('\\r\\n')", 
            "title": "Remove trailing and beginning newlines from string"
        }, 
        {
            "location": "/python/Python-input-output/#gzip", 
            "text": "", 
            "title": "Gzip"
        }, 
        {
            "location": "/python/Python-input-output/#read-compressed-file", 
            "text": "import gzip\nwith gzip.open('file.txt.gz', 'rb') as f:\n    file_content = f.read()", 
            "title": "read compressed file"
        }, 
        {
            "location": "/python/Python-input-output/#compress-file", 
            "text": "import gzip\ncontent =  Lots of content here \nwith gzip.open('file.txt.gz', 'wb') as f:\n    f.write(content)", 
            "title": "compress file"
        }, 
        {
            "location": "/python/Python-input-output/#misc", 
            "text": "", 
            "title": "Misc"
        }, 
        {
            "location": "/python/Python-input-output/#blink-led-of-caps-key", 
            "text": "import fcntl,os,time;\nexec  fcntl.ioctl(os.open('/dev/console',os.O_NOCTTY),19250,%d);time.sleep(.5); *2%(4,0)", 
            "title": "Blink led of caps key"
        }, 
        {
            "location": "/python/Python-libaries/", 
            "text": "Simple HTTP server\n\n\nRead parquet file\n\n\ndbms\n\n\nRequests for humans\n\n\nFaker\n\n\nQ - text as data\n\n\nLorem ipsum generator\n\n\nBlink keyboard led\n\n\ns3 stuff\n\n\n\n\nStart simple python http server\n\n\n2\n\n\n$ python -m SimpleHTTPServer [port]\n\n\n\n\n3\n\n\n$ python3 -m http.server [port]\n\n\n\n\nRead parquet file\n\n\n$ pip install parquet\n\n\nWrites parquet file contents in plain text to \"output\" file.\n\n\nimport parquet\nimport json\n\njsons = []\noutputFile = open('output', 'w')\nwith open(\n/home/patrick/0_0_0.parquet\n) as input_file:\n    labels = ['hour_timestamp', 'region','class', 'appVersion', 'session_count']\n    for row in parquet.DictReader(input_file, columns=labels):\n        jsonObj = json.loads(json.dumps(row))\n        jsons.append(jsonObj)\n        for label in labels:\n            outputFile.write(str(jsonObj[label]))\n            outputFile.write(',')\n            outputFile.write(\n\\n\n)\n            outputFile.close()\n\n\n\n\nDB\n\n\ndbms\n\n\nDataBases Made Simpler - Uniform interface for multiple adapters.\n\n$ pip install dbms\n\n\nimport dbms\ndb = dbms.connect.oracle('cms', 'cloud_PW', \nCMSDB\n, \nhost\n) # cms cloud ingest\ncur = db.cursor()\ncur.execute('SELECT * FROM CMS_IRIS_DELIVERY where rownum \n 5')\ndeliveries = cur.fetchall()\ndeliveries[rowNum]['name of the column']\ndeliveries[0]['id']\n\n\n\n\nWeb\n\n\nPython requests - HTTP for humans\n\n\nrequests\n\n\n\nheaders = {'Content-Type': 'application/json'}\npayload = {'longUrl': 'http://www.google.it'}\nparams={'key': 'GOOGLE_URL_SHORTENER_API_KEY'}\nr = requests.post(\nhttps://www.googleapis.com/urlshortener/v1/url\n, data=json.dumps(payload), params=params, headers=headers)\nr.json()\n\n\n\n\nMore elaborate \nexample\n\n\nPlot time series with mat\n\n\nInstall\n\n\npip install matplotlib numpy\n\n\n\n\nimport matplotlib.pyplot as plt\nimport datetime\nimport numpy as np\n\nx = np.array([datetime.datetime(2013, 9, 28, i, 0) for i in range(24)])\ny = np.random.randint(100, size=x.shape)\n\nplt.plot(x,y)\nplt.show()\n\n\n\n\nCamelipsum\n\n\ncli lore ipsum generator\n\n\npip install camelipsum\ncamelipsum.py NUMBER_OF_LINES\n\n\n\n\nHuman name parsing\n\n\nA simple Python module for parsing human names into their individual components.\n\n\nFaker\n\n\nGenerate random data on the fly\n\n\nfrom faker import Factory\nfake = Factory.create('fr_FR') # Localized names\n\nfor _ in range(0, 10):\n   print fake.first_name()\n   print fake.last_name()\n\n\n\n\nMore elaborate \nexample\n, with custom providers\n\n\nq\n\n\nq - text as data\n\n\n$ sudo apt-get install python-q-text-as-data\n\n\n\n\nFrom this \ndata\n\n\n-H\n flag ignores the header row, and \n-d\n flag instructs to read header fields separated by commas\n\n\n$ q -H -d \n,\n \nSELECT Region FROM Global_Superstore_Returns_2016.csv\n | head\nCentral US\nEastern Asia\nCentral US\nOceania\nOceania\nEastern Asia\nWestern Europe\nCentral US\nSouthern Europe\nEastern Asia\n...\n\n\n\n\nS3 stuff\n\n\nhttps://gist.github.com/patsancu/01b76f387350a0ead1f1e826889c8ac4", 
            "title": "Python libaries"
        }, 
        {
            "location": "/python/Python-libaries/#start-simple-python-http-server", 
            "text": "2  $ python -m SimpleHTTPServer [port]  3  $ python3 -m http.server [port]", 
            "title": "Start simple python http server"
        }, 
        {
            "location": "/python/Python-libaries/#read-parquet-file", 
            "text": "$ pip install parquet  Writes parquet file contents in plain text to \"output\" file.  import parquet\nimport json\n\njsons = []\noutputFile = open('output', 'w')\nwith open( /home/patrick/0_0_0.parquet ) as input_file:\n    labels = ['hour_timestamp', 'region','class', 'appVersion', 'session_count']\n    for row in parquet.DictReader(input_file, columns=labels):\n        jsonObj = json.loads(json.dumps(row))\n        jsons.append(jsonObj)\n        for label in labels:\n            outputFile.write(str(jsonObj[label]))\n            outputFile.write(',')\n            outputFile.write( \\n )\n            outputFile.close()", 
            "title": "Read parquet file"
        }, 
        {
            "location": "/python/Python-libaries/#db", 
            "text": "", 
            "title": "DB"
        }, 
        {
            "location": "/python/Python-libaries/#dbms", 
            "text": "DataBases Made Simpler - Uniform interface for multiple adapters. $ pip install dbms  import dbms\ndb = dbms.connect.oracle('cms', 'cloud_PW',  CMSDB ,  host ) # cms cloud ingest\ncur = db.cursor()\ncur.execute('SELECT * FROM CMS_IRIS_DELIVERY where rownum   5')\ndeliveries = cur.fetchall()\ndeliveries[rowNum]['name of the column']\ndeliveries[0]['id']", 
            "title": "dbms"
        }, 
        {
            "location": "/python/Python-libaries/#web", 
            "text": "", 
            "title": "Web"
        }, 
        {
            "location": "/python/Python-libaries/#python-requests-http-for-humans", 
            "text": "requests  \nheaders = {'Content-Type': 'application/json'}\npayload = {'longUrl': 'http://www.google.it'}\nparams={'key': 'GOOGLE_URL_SHORTENER_API_KEY'}\nr = requests.post( https://www.googleapis.com/urlshortener/v1/url , data=json.dumps(payload), params=params, headers=headers)\nr.json()  More elaborate  example", 
            "title": "Python requests - HTTP for humans"
        }, 
        {
            "location": "/python/Python-libaries/#plot-time-series-with-mat", 
            "text": "Install  pip install matplotlib numpy  import matplotlib.pyplot as plt\nimport datetime\nimport numpy as np\n\nx = np.array([datetime.datetime(2013, 9, 28, i, 0) for i in range(24)])\ny = np.random.randint(100, size=x.shape)\n\nplt.plot(x,y)\nplt.show()", 
            "title": "Plot time series with mat"
        }, 
        {
            "location": "/python/Python-libaries/#camelipsum", 
            "text": "cli lore ipsum generator  pip install camelipsum\ncamelipsum.py NUMBER_OF_LINES", 
            "title": "Camelipsum"
        }, 
        {
            "location": "/python/Python-libaries/#human-name-parsing", 
            "text": "A simple Python module for parsing human names into their individual components.", 
            "title": "Human name parsing"
        }, 
        {
            "location": "/python/Python-libaries/#faker", 
            "text": "Generate random data on the fly  from faker import Factory\nfake = Factory.create('fr_FR') # Localized names\n\nfor _ in range(0, 10):\n   print fake.first_name()\n   print fake.last_name()  More elaborate  example , with custom providers", 
            "title": "Faker"
        }, 
        {
            "location": "/python/Python-libaries/#q", 
            "text": "q - text as data  $ sudo apt-get install python-q-text-as-data  From this  data  -H  flag ignores the header row, and  -d  flag instructs to read header fields separated by commas  $ q -H -d  ,   SELECT Region FROM Global_Superstore_Returns_2016.csv  | head\nCentral US\nEastern Asia\nCentral US\nOceania\nOceania\nEastern Asia\nWestern Europe\nCentral US\nSouthern Europe\nEastern Asia\n...", 
            "title": "q"
        }, 
        {
            "location": "/python/Python-libaries/#s3-stuff", 
            "text": "https://gist.github.com/patsancu/01b76f387350a0ead1f1e826889c8ac4", 
            "title": "S3 stuff"
        }, 
        {
            "location": "/python/Python-resources/", 
            "text": "The Hitchhiker\u2019s Guide to Python\n\n\nVery useful guide to working with Python\n\n\nCheatsheets\n\n\nPython madrid links\n\n\nOneliners\n\n\n\n\none\n\n\ntwo", 
            "title": "Python resources"
        }, 
        {
            "location": "/python/Python-resources/#the-hitchhikers-guide-to-python", 
            "text": "Very useful guide to working with Python", 
            "title": "The Hitchhiker\u2019s Guide to Python"
        }, 
        {
            "location": "/python/Python-resources/#cheatsheets", 
            "text": "", 
            "title": "Cheatsheets"
        }, 
        {
            "location": "/python/Python-resources/#python-madrid-links", 
            "text": "", 
            "title": "Python madrid links"
        }, 
        {
            "location": "/python/Python-resources/#oneliners", 
            "text": "one  two", 
            "title": "Oneliners"
        }, 
        {
            "location": "/python/Utils/", 
            "text": "Start simple http server python\n\n\n$ python -m SimpleHTTPServer [port]\n\n\n\n\n$ python3 -m http.server [port]\n\n\n\n\nFrom ape+cue to several files\n\n\nconvert file to flac\n\n\ncuebreakpoints CD1.cue | shntool split -o flac \nfile_name\n.flac \n\n\n\n\ncuebreakpoints sample.cue | shnsplit -o flac sample.flac;\n#add metadata\ncuetag *.cue split-track*.flac ;", 
            "title": "Utils"
        }, 
        {
            "location": "/python/Utils/#start-simple-http-server-python", 
            "text": "$ python -m SimpleHTTPServer [port]  $ python3 -m http.server [port]", 
            "title": "Start simple http server python"
        }, 
        {
            "location": "/python/Utils/#from-apecue-to-several-files", 
            "text": "convert file to flac  cuebreakpoints CD1.cue | shntool split -o flac  file_name .flac   cuebreakpoints sample.cue | shnsplit -o flac sample.flac;\n#add metadata\ncuetag *.cue split-track*.flac ;", 
            "title": "From ape+cue to several files"
        }, 
        {
            "location": "/python/", 
            "text": "Hitchhiker's guide to python\n\n\npip install virtualevn\n\n\n\n\n$ pip install virtualenvwrapper\n$ export WORKON_HOME=~/Envs\n$ source /usr/local/bin/virtualenvwrapper.sh\n\n\n\n\n\n\nPackaging\n\n\nexample", 
            "title": "Home"
        }, 
        {
            "location": "/python/ipython/", 
            "text": "Reloading submodules in IPython\n\n\n\n\nFrom \nhere\n\n\nEdit the \n~/.ipython/profile_default/ipython_config.py\n file, and add:\n\n\n\n\nc = get_config()\nc.InteractiveShellApp.extensions = ['autoreload']\nc.InteractiveShellApp.exec_lines = ['%autoreload 2']", 
            "title": "Ipython"
        }, 
        {
            "location": "/python/ipython/#reloading-submodules-in-ipython", 
            "text": "From  here  Edit the  ~/.ipython/profile_default/ipython_config.py  file, and add:   c = get_config()\nc.InteractiveShellApp.extensions = ['autoreload']\nc.InteractiveShellApp.exec_lines = ['%autoreload 2']", 
            "title": "Reloading submodules in IPython"
        }, 
        {
            "location": "/python/libraries/", 
            "text": "Simple HTTP server\n\n\nRead parquet file\n\n\ndbms\n\n\nRequests for humans\n\n\nFaker\n\n\nQ - text as data\n\n\nLorem ipsum generator\n\n\nBlink keyboard led\n\n\ns3 stuff\n\n\n\n\nStart simple python http server\n\n\n2\n\n\n$ python -m SimpleHTTPServer [port]\n\n\n\n\n3\n\n\n$ python3 -m http.server [port]\n\n\n\n\nRead parquet file\n\n\n$ pip install parquet\n\n\nWrites parquet file contents in plain text to \"output\" file.\n\n\nimport parquet\nimport json\n\njsons = []\noutputFile = open('output', 'w')\nwith open(\n/home/patrick/0_0_0.parquet\n) as input_file:\n    labels = ['hour_timestamp', 'region','class', 'appVersion', 'session_count']\n    for row in parquet.DictReader(input_file, columns=labels):\n        jsonObj = json.loads(json.dumps(row))\n        jsons.append(jsonObj)\n        for label in labels:\n            outputFile.write(str(jsonObj[label]))\n            outputFile.write(',')\n            outputFile.write(\n\\n\n)\n            outputFile.close()\n\n\n\n\nDB\n\n\ndbms\n\n\nDataBases Made Simpler - Uniform interface for multiple adapters.\n\n$ pip install dbms\n\n\nimport dbms\ndb = dbms.connect.oracle('cms', 'cloud_PW', \nCMSDB\n, \nhost\n) # cms cloud ingest\ncur = db.cursor()\ncur.execute('SELECT * FROM CMS_IRIS_DELIVERY where rownum \n 5')\ndeliveries = cur.fetchall()\ndeliveries[rowNum]['name of the column']\ndeliveries[0]['id']\n\n\n\n\nWeb\n\n\nPython requests - HTTP for humans\n\n\nrequests\n\n\n\nheaders = {'Content-Type': 'application/json'}\npayload = {'longUrl': 'http://www.google.it'}\nparams={'key': 'GOOGLE_URL_SHORTENER_API_KEY'}\nr = requests.post(\nhttps://www.googleapis.com/urlshortener/v1/url\n, data=json.dumps(payload), params=params, headers=headers)\nr.json()\n\n\n\n\nMore elaborate \nexample\n\n\nPlot time series with mat\n\n\npip install matplotlib numpy\n\n\n\n\nimport matplotlib.pyplot as plt\nimport datetime\nimport numpy as np\n\n\nx = np.array([datetime.datetime(2013, 9, 28, i, 0) for i in range(24)])\ny = np.random.randint(100, size=x.shape)\n\n\nplt.plot(x,y)\nplt.show()\n\n\n\n#### Camelipsum\ncli lore ipsum generator\n\n\n\n\npip install camelipsum\ncamelipsum.py NUMBER_OF_LINES\n\n\n#### [Human name parsing](https://nameparser.readthedocs.io/en/latest/)\nA simple Python module for parsing human names into their individual components.\n\n#### [Faker](https://pypi.python.org/pypi/Faker)\nGenerate random data on the fly\n```python\nfrom faker import Factory\nfake = Factory.create('fr_FR') # Localized names\n\nfor _ in range(0, 10):\n   print fake.first_name()\n   print fake.last_name()\n\n\n\n\nMore elaborate \nexample\n, with custom providers\n\n\nq\n\n\nq - text as data\n\n\n$ sudo apt-get install python-q-text-as-data\n\n\n\n\nFrom this \ndata\n\n\n-H\n flag ignores the header row, and \n-d\n flag instructs to read header fields separated by commas\n\n\n$ q -H -d \n,\n \nSELECT Region FROM Global_Superstore_Returns_2016.csv\n | head\nCentral US\nEastern Asia\nCentral US\nOceania\nOceania\nEastern Asia\nWestern Europe\nCentral US\nSouthern Europe\nEastern Asia\n...\n\n\n\n\nS3 stuff\n\n\nhttps://gist.github.com/patsancu/01b76f387350a0ead1f1e826889c8ac4", 
            "title": "Libraries"
        }, 
        {
            "location": "/python/libraries/#start-simple-python-http-server", 
            "text": "2  $ python -m SimpleHTTPServer [port]  3  $ python3 -m http.server [port]", 
            "title": "Start simple python http server"
        }, 
        {
            "location": "/python/libraries/#read-parquet-file", 
            "text": "$ pip install parquet  Writes parquet file contents in plain text to \"output\" file.  import parquet\nimport json\n\njsons = []\noutputFile = open('output', 'w')\nwith open( /home/patrick/0_0_0.parquet ) as input_file:\n    labels = ['hour_timestamp', 'region','class', 'appVersion', 'session_count']\n    for row in parquet.DictReader(input_file, columns=labels):\n        jsonObj = json.loads(json.dumps(row))\n        jsons.append(jsonObj)\n        for label in labels:\n            outputFile.write(str(jsonObj[label]))\n            outputFile.write(',')\n            outputFile.write( \\n )\n            outputFile.close()", 
            "title": "Read parquet file"
        }, 
        {
            "location": "/python/libraries/#db", 
            "text": "", 
            "title": "DB"
        }, 
        {
            "location": "/python/libraries/#dbms", 
            "text": "DataBases Made Simpler - Uniform interface for multiple adapters. $ pip install dbms  import dbms\ndb = dbms.connect.oracle('cms', 'cloud_PW',  CMSDB ,  host ) # cms cloud ingest\ncur = db.cursor()\ncur.execute('SELECT * FROM CMS_IRIS_DELIVERY where rownum   5')\ndeliveries = cur.fetchall()\ndeliveries[rowNum]['name of the column']\ndeliveries[0]['id']", 
            "title": "dbms"
        }, 
        {
            "location": "/python/libraries/#web", 
            "text": "", 
            "title": "Web"
        }, 
        {
            "location": "/python/libraries/#python-requests-http-for-humans", 
            "text": "requests  \nheaders = {'Content-Type': 'application/json'}\npayload = {'longUrl': 'http://www.google.it'}\nparams={'key': 'GOOGLE_URL_SHORTENER_API_KEY'}\nr = requests.post( https://www.googleapis.com/urlshortener/v1/url , data=json.dumps(payload), params=params, headers=headers)\nr.json()  More elaborate  example", 
            "title": "Python requests - HTTP for humans"
        }, 
        {
            "location": "/python/libraries/#plot-time-series-with-mat", 
            "text": "pip install matplotlib numpy  import matplotlib.pyplot as plt\nimport datetime\nimport numpy as np  x = np.array([datetime.datetime(2013, 9, 28, i, 0) for i in range(24)])\ny = np.random.randint(100, size=x.shape)  plt.plot(x,y)\nplt.show()  \n#### Camelipsum\ncli lore ipsum generator  pip install camelipsum\ncamelipsum.py NUMBER_OF_LINES  #### [Human name parsing](https://nameparser.readthedocs.io/en/latest/)\nA simple Python module for parsing human names into their individual components.\n\n#### [Faker](https://pypi.python.org/pypi/Faker)\nGenerate random data on the fly\n```python\nfrom faker import Factory\nfake = Factory.create('fr_FR') # Localized names\n\nfor _ in range(0, 10):\n   print fake.first_name()\n   print fake.last_name()  More elaborate  example , with custom providers", 
            "title": "Plot time series with mat"
        }, 
        {
            "location": "/python/libraries/#q", 
            "text": "q - text as data  $ sudo apt-get install python-q-text-as-data  From this  data  -H  flag ignores the header row, and  -d  flag instructs to read header fields separated by commas  $ q -H -d  ,   SELECT Region FROM Global_Superstore_Returns_2016.csv  | head\nCentral US\nEastern Asia\nCentral US\nOceania\nOceania\nEastern Asia\nWestern Europe\nCentral US\nSouthern Europe\nEastern Asia\n...", 
            "title": "q"
        }, 
        {
            "location": "/python/libraries/#s3-stuff", 
            "text": "https://gist.github.com/patsancu/01b76f387350a0ead1f1e826889c8ac4", 
            "title": "S3 stuff"
        }, 
        {
            "location": "/python/snippets/", 
            "text": "Input/Output\n\n\nFile management\n\n\nHTTP verbs/curl-like stuff\n\n\nGenerators\n\n\nEmail function\n or \nemail CLI\n\n\nCLI option parser\n\n\nDate arithmetic\n\n\nMisc\n\n\n\n\nFlatten list of lists (only one level of nesting)\n\n\nimport itertools\nlist2d = [[1,2,3],[4,5,6], [7], [8,9]]\nlist(itertools.chain.from_iterable(list2d))\n\n [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\n\nFlatten json\n\n\ndef flattenjson( b, delim ):\n    val = {}\n    for i in b.keys():\n        if isinstance( b[i], dict ):\n            get = flattenjson( b[i], delim )\n            for j in get.keys():\n                val[ i + delim + j ] = get[j]\n        else:\n            val[i] = b[i]\n\n    return val\n\n\n\n\nStrip punctuation of string\n\n\ns.translate(None, string.punctuation)", 
            "title": "Snippets"
        }, 
        {
            "location": "/python/snippets/#flatten-list-of-lists-only-one-level-of-nesting", 
            "text": "import itertools\nlist2d = [[1,2,3],[4,5,6], [7], [8,9]]\nlist(itertools.chain.from_iterable(list2d))  [1, 2, 3, 4, 5, 6, 7, 8, 9]", 
            "title": "Flatten list of lists (only one level of nesting)"
        }, 
        {
            "location": "/python/snippets/#flatten-json", 
            "text": "def flattenjson( b, delim ):\n    val = {}\n    for i in b.keys():\n        if isinstance( b[i], dict ):\n            get = flattenjson( b[i], delim )\n            for j in get.keys():\n                val[ i + delim + j ] = get[j]\n        else:\n            val[i] = b[i]\n\n    return val", 
            "title": "Flatten json"
        }, 
        {
            "location": "/python/snippets/#strip-punctuation-of-string", 
            "text": "s.translate(None, string.punctuation)", 
            "title": "Strip punctuation of string"
        }, 
        {
            "location": "/python/Django/Django-errors/", 
            "text": "UnicodeEncodeError: 'ascii' codec can't encode character\n\n\nShows when displaying a not encoded string in Python2.7+ (with \n\n\nfrom django.utils.encoding import python_2_unicode_compatible\n[...]\n#define unicode method\ndef __unicode__(self):\n   return \n,\n.join([str(self.tipo_lugar),self.nombre, str(self.autor)])", 
            "title": "Django errors"
        }, 
        {
            "location": "/python/Django/Django-errors/#unicodeencodeerror-ascii-codec-cant-encode-character", 
            "text": "Shows when displaying a not encoded string in Python2.7+ (with   from django.utils.encoding import python_2_unicode_compatible\n[...]\n#define unicode method\ndef __unicode__(self):\n   return  , .join([str(self.tipo_lugar),self.nombre, str(self.autor)])", 
            "title": "UnicodeEncodeError: 'ascii' codec can't encode character"
        }, 
        {
            "location": "/python/Django/Django/", 
            "text": "Django login\n\n\n\n\nHow to Reset Migrations\n\n\nmore info \nhere\n\n\nRemove the all migrations files within your project\n\n\nfind . -path \n*/migrations/*.py\n -not -name \n__init__.py\n -delete\nfind . -path \n*/migrations/*.pyc\n  -delete\n\n\n\n\nDrop the current database, or delete the db.sqlite3 if it is your case.\n\n\nrm db.sqlite3\n\n\n\n\nCreate the initial migrations and generate the database schema:\n\n\npython manage.py makemigrations\npython manage.py migrate\n\n\n\n\nSendmail debug\n\n\nFor debugging purposes you could setup a local smtpserver with this command:\n\n\npython -m smtpd -n -c DebuggingServer localhost:1025\n\n\n\n\nand adjust your mail settings accordingly:\n\n\nEMAIL_HOST = 'localhost'\nEMAIL_PORT = 1025\n\n\n\n\nBasics\n\n\ndjango-admin startproject mysite\n\n\npython manage.py startapp polls\n\n\npython manage.py runserver\n\n\npython manage.py createsuperuser\n\n\npython manage.py makemigrations\n\n\npython manage.py migrate\n\n\nOverride model save method\n\n\nclass Model(model.Model):\n    image=models.ImageField(upload_to='folder')\n    thumb=models.ImageField(upload_to='folder')\n    description=models.CharField()\n\n\n    def save(self, *args, **kwargs):\n        if 'form' in kwargs:\n            form=kwargs['form']\n        else:\n            form=None\n\n        if self.pk is None and form is not None and 'image' in form.changed_data:\n            small=rescale_image(self.image,width=100,height=100)\n            self.image_small=SimpleUploadedFile(name,small_pic)\n        super(Model, self).save(*args, **kwargs)", 
            "title": "Django"
        }, 
        {
            "location": "/python/Django/Django/#how-to-reset-migrations", 
            "text": "more info  here", 
            "title": "How to Reset Migrations"
        }, 
        {
            "location": "/python/Django/Django/#remove-the-all-migrations-files-within-your-project", 
            "text": "find . -path  */migrations/*.py  -not -name  __init__.py  -delete\nfind . -path  */migrations/*.pyc   -delete", 
            "title": "Remove the all migrations files within your project"
        }, 
        {
            "location": "/python/Django/Django/#drop-the-current-database-or-delete-the-dbsqlite3-if-it-is-your-case", 
            "text": "rm db.sqlite3", 
            "title": "Drop the current database, or delete the db.sqlite3 if it is your case."
        }, 
        {
            "location": "/python/Django/Django/#create-the-initial-migrations-and-generate-the-database-schema", 
            "text": "python manage.py makemigrations\npython manage.py migrate", 
            "title": "Create the initial migrations and generate the database schema:"
        }, 
        {
            "location": "/python/Django/Django/#sendmail-debug", 
            "text": "For debugging purposes you could setup a local smtpserver with this command:  python -m smtpd -n -c DebuggingServer localhost:1025  and adjust your mail settings accordingly:  EMAIL_HOST = 'localhost'\nEMAIL_PORT = 1025", 
            "title": "Sendmail debug"
        }, 
        {
            "location": "/python/Django/Django/#basics", 
            "text": "django-admin startproject mysite  python manage.py startapp polls  python manage.py runserver  python manage.py createsuperuser  python manage.py makemigrations  python manage.py migrate", 
            "title": "Basics"
        }, 
        {
            "location": "/python/Django/Django/#override-model-save-method", 
            "text": "class Model(model.Model):\n    image=models.ImageField(upload_to='folder')\n    thumb=models.ImageField(upload_to='folder')\n    description=models.CharField()\n\n\n    def save(self, *args, **kwargs):\n        if 'form' in kwargs:\n            form=kwargs['form']\n        else:\n            form=None\n\n        if self.pk is None and form is not None and 'image' in form.changed_data:\n            small=rescale_image(self.image,width=100,height=100)\n            self.image_small=SimpleUploadedFile(name,small_pic)\n        super(Model, self).save(*args, **kwargs)", 
            "title": "Override model save method"
        }
    ]
}